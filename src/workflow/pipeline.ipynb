{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4432e892",
   "metadata": {},
   "source": [
    "# OCR-mLLM Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd231b04",
   "metadata": {},
   "source": [
    "Before running this code you will need to set up your OpenAI & Gemini API keys. Here's how I did it:\n",
    "\n",
    "1. Create a new file in your root directory called `.env` (no prefix)\n",
    "2. Store your API keys with the following names: OPENAI_API_KEY, ANTHROPIC_API_KEY, and GOOGLE_API_KEY\n",
    "3. Create a virtual environment by typing the following commands into your terminal:\n",
    "    - ```python3 -m venv .venv```\n",
    "    - ```source .venv/bin/activate```\n",
    "    - ```pip install -r requirements.txt```\n",
    "4. After running the pipeline, type ```deactivate``` in your terminal to make everything go back to normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadd7cf4",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002663b1",
   "metadata": {},
   "source": [
    "### a. Run this cell to ensure you have all the necessary directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd3540d",
   "metadata": {},
   "source": [
    "Before running the cell make sure you have an images folder in your root directory to feed the images into the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549ec682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Get the root directory of the project\n",
    "root_dir = Path.cwd().parent.parent\n",
    "\n",
    "# Get the user's path for the images folder assuming all images are stored here in .png format\n",
    "source_dir = root_dir / \"data\" / \"pngs\"\n",
    "\n",
    "# Get the user's path for the output folder, create one if it doesn't exist\n",
    "txt_output_dir = root_dir / \"results\"\n",
    "txt_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# bm_output_dir = root_dir / \"benchmarking-results\"/ \"txt-accuracy\"\n",
    "# bm_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# llm_array = [\"gpt-4o\", \"gemini-2.5-flash\", \"claude-4-sonnet\"]\n",
    "llm_array = [\"gpt-4o\", \"gemini-2.0-flash\"]\n",
    "\n",
    "def make_llm_dirs(llm_array, target_dir):\n",
    "    for llm in llm_array:\n",
    "        dir = target_dir / \"ocr-img2txt\"\n",
    "        dir.mkdir(parents=True, exist_ok=True)\n",
    "        dir = target_dir / \"llm-img2txt\" / llm\n",
    "        dir.mkdir(parents=True, exist_ok=True)\n",
    "        dir = target_dir / \"ocr-llm-img2txt\" / llm\n",
    "        dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "make_llm_dirs(llm_array, txt_output_dir)\n",
    "# make_llm_dirs(llm_array, bm_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859c660",
   "metadata": {},
   "source": [
    "### b. Setup API keys & image encoding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ae833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from google import genai\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "gpt_client = OpenAI(api_key=openai_api_key)\n",
    "gemini_client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "claude_client = Anthropic(api_key=anthropic_api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3a5773",
   "metadata": {},
   "source": [
    "### c. Get image file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed71bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all filenames in images directory into the `filenames` array with the ENTIRE filepath\n",
    "img_filepaths = []\n",
    "for path in source_dir.iterdir():\n",
    "  if path.suffix.lower() == \".png\" and path.is_file():\n",
    "    img_filepaths.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5702eec5-e52d-4b51-8907-f593204a1b76",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 2. Run pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95e34ea1-f6ae-4de7-9887-764da7178f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files from ocr-benchmarking/images folder & write to results folder\n",
    "for path in img_filepaths:\n",
    "    file_name = txt_output_dir / \"ocr-img2txt\" / path.stem\n",
    "    file_name = str(file_name) + \".txt\"\n",
    "    \n",
    "    with open(file_name, 'w') as file:\n",
    "        file.write(pytesseract.image_to_string(Image.open(str(path)))) # TODO: Change config as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df39757",
   "metadata": {},
   "source": [
    "## 3. Prepare the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045337cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_ocr_llm = \"\"\"\n",
    "You are a text correction assistant. Your task is to clean up and correct errors from raw OCR output.\n",
    "The text may contain misrecognized characters, broken words, or incorrect formatting.\n",
    "Carefully read the provided OCR output and produce a corrected version that is grammatically accurate \n",
    "and as faithful to the original content as possible. Because this is a historical document, try to \n",
    "preserve archaic spelling or formatting where clearly intended. Only correct obvious OCR errors.\n",
    "Put the dates associated with each entry at the end of the line.\n",
    "\n",
    "Input (Raw OCR Text):\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "prompt_llm = \"\"\"\n",
    "You are an expert historian. Your task is to transcribe the provided image into text. The image\n",
    "is a 20th century bibliographic entry. Because this is a historical document, try to preserve \n",
    "archaic spelling or formatting where clearly intended. Put the dates associated with each entry at the end of the line.\n",
    "Return the text only, nothing else.\n",
    "\"\"\"\n",
    "\n",
    "# prompt = \"\"\"\n",
    "# From the provided image, give me the first word and nothing else\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d58cb0c-aeb8-47cc-9528-26bc3a802984",
   "metadata": {},
   "source": [
    "## 4. Send to OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06535758",
   "metadata": {},
   "source": [
    "### a. OCR-LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "163080e4-5134-407c-9cdd-7a89141e1632",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in img_filepaths:\n",
    "    input = \"\"\n",
    "    base64_image = encode_image(path)\n",
    "    ocr_text_path = str(txt_output_dir / \"ocr-img2txt\" / path.stem) + \".txt\"\n",
    "    with open(ocr_text_path, 'r') as file:\n",
    "        input += file.read()\n",
    "    prompt_ocr_llm = prompt_template_ocr_llm.format(input=input).strip()\n",
    "\n",
    "    response = gpt_client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt_ocr_llm\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            ]\n",
    "    )\n",
    "\n",
    "    with open(txt_output_dir / \"ocr-llm-img2txt\" / \"gpt-4o\" / Path(path.stem + \".txt\"), 'w') as file:\n",
    "        file.write(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cafe77",
   "metadata": {},
   "source": [
    "### b. LLM call (without OCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c2eedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-06-23 18:05:08 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "for path in img_filepaths:\n",
    "    base64_image = encode_image(path)\n",
    "\n",
    "    response = gpt_client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt_llm\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            ]\n",
    "    )\n",
    "\n",
    "    with open(txt_output_dir / \"llm-img2txt\" / \"gpt-4o\" / Path(path.stem + \".txt\"), 'w') as file:\n",
    "        file.write(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25ecae5",
   "metadata": {},
   "source": [
    "## 5. Send to Gemini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f10c212",
   "metadata": {},
   "source": [
    "### a. OCR-LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e5d357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-06-23 18:05:08 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-06-23 18:05:08 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH89bHeN0-vA-xzs2K_EGUYmGBXEGUqZ-TzID8lIRuuIZ5uv_yAciVJ4QlyDuV6hzZ8cjQZLSwSf8qPnMUXfMtLoxSxcspz6tzUhrZBAqjyo&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-06-23 18:05:12 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH89bHeN0-vA-xzs2K_EGUYmGBXEGUqZ-TzID8lIRuuIZ5uv_yAciVJ4QlyDuV6hzZ8cjQZLSwSf8qPnMUXfMtLoxSxcspz6tzUhrZBAqjyo&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-06-23 18:05:12 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-06-23 18:05:22 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-06-23 18:05:22 [INFO] AFC remote call 1 is done.\n"
     ]
    }
   ],
   "source": [
    "for path in img_filepaths:\n",
    "    my_file = gemini_client.files.upload(file=path)\n",
    "    input = \"\"\n",
    "    ocr_text_path = str(txt_output_dir / \"ocr-img2txt\" / path.stem) + \".txt\"\n",
    "    with open(ocr_text_path, 'r') as file:\n",
    "        input += file.read()\n",
    "    prompt_ocr_llm = prompt_template_ocr_llm.format(input=input).strip()\n",
    "\n",
    "    response = gemini_client.models.generate_content(\n",
    "        model='gemini-2.0-flash',\n",
    "        contents=[\n",
    "            prompt_ocr_llm,\n",
    "            my_file\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    with open(txt_output_dir / \"ocr-llm-img2txt\" / \"gemini-2.0-flash\" / Path(path.stem + \".txt\"), 'w') as file:\n",
    "        file.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d3100",
   "metadata": {},
   "source": [
    "### b. LLM call (without OCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d3d2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-06-23 18:09:12 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-06-23 18:09:12 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8-3KU37dFDba1mFKIvOfc5RYRqFx9d62ZmHwTuLZYDqHsclMmASOT5Yrxi_PKCGIThqeKhARRBqdZIO2RFRET1a82VvUpf2BZRgTsaFYHE&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-06-23 18:09:15 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8-3KU37dFDba1mFKIvOfc5RYRqFx9d62ZmHwTuLZYDqHsclMmASOT5Yrxi_PKCGIThqeKhARRBqdZIO2RFRET1a82VvUpf2BZRgTsaFYHE&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-06-23 18:09:15 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-06-23 18:09:24 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-06-23 18:09:24 [INFO] AFC remote call 1 is done.\n"
     ]
    }
   ],
   "source": [
    "for path in img_filepaths:\n",
    "    my_file = gemini_client.files.upload(file=path)\n",
    "\n",
    "    response = gemini_client.models.generate_content(\n",
    "        model='gemini-2.0-flash',\n",
    "        contents=[\n",
    "            prompt_llm,\n",
    "            my_file\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    with open(txt_output_dir / \"llm-img2txt\" / \"gemini-2.0-flash\" / Path(path.stem + \".txt\"), 'w') as file:\n",
    "        file.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d06c34",
   "metadata": {},
   "source": [
    "## 6. Send to Claude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0869c81",
   "metadata": {},
   "source": [
    "### a. OCR-LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651e17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in img_filepaths:\n",
    "#     base64_image = encode_image(path)\n",
    "\n",
    "#     response = claude_client.messages.create(\n",
    "#         model='claude-opus-4-20250514',\n",
    "#         temperature=0,\n",
    "#         max_tokens=10,\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"user\", \n",
    "#                 \"content\": [\n",
    "#                     {\n",
    "#                         \"type\": \"text\",\n",
    "#                         \"text\": prompt_ocr_llm\n",
    "#                     },\n",
    "#                     {\n",
    "#                         \"type\": \"image\",\n",
    "#                         \"source\": {\n",
    "#                             \"type\": \"base64\",\n",
    "#                             \"media_type\": \"image/png\",\n",
    "#                             \"data\": base64_image\n",
    "#                         }\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#             ]\n",
    "#     )\n",
    "#     print(response)\n",
    "\n",
    "#     with open(txt_output_dir / \"ocr-llm-img2txt\" / \"claude-4-sonnet\" / Path(path.stem + \".txt\"), 'w') as file:\n",
    "#         file.write(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b610ccd9",
   "metadata": {},
   "source": [
    "### b. LLM call (without OCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497c3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in img_filepaths:\n",
    "#     base64_image = encode_image(path)\n",
    "\n",
    "#     response = claude_client.messages.create(\n",
    "#         model='claude-opus-4-20250514',\n",
    "#         temperature=0,\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"user\", \n",
    "#                 \"content\": [\n",
    "#                     {\n",
    "#                         \"type\": \"text\",\n",
    "#                         \"text\": prompt_llm\n",
    "#                     },\n",
    "#                     {\n",
    "#                         \"type\": \"image\",\n",
    "#                         \"source\": {\n",
    "#                             \"type\": \"base64\",\n",
    "#                             \"media_type\": \"image/png\",\n",
    "#                             \"data\": base64_image\n",
    "#                         }\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#             ]\n",
    "#     )\n",
    "\n",
    "#     with open(txt_output_dir / \"llm-img2txt\" / \"claude-4-sonnet\" / Path(path.stem + \".txt\"), 'w') as file:\n",
    "#         file.write(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e20262",
   "metadata": {},
   "source": [
    "## 7. Benchmark results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77c21953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-06-26 11:16:59 [INFO] Script directory: /Users/muhammadkhalid/Desktop/map2025/ocr-benchmarking/src/workflow\n",
      "[file retrieval] 2025-06-26 11:16:59 [INFO] Project root: /Users/muhammadkhalid/Desktop/map2025/ocr-benchmarking\n",
      "[file retrieval] 2025-06-26 11:16:59 [INFO] Found ground-truth txt files: ['/Users/muhammadkhalid/Desktop/map2025/ocr-benchmarking/data/ground-truth/txt/gt_kbaa-p096.txt']\n",
      "[file retrieval] 2025-06-26 11:16:59 [INFO] Found file names: ['gt_kbaa-p096']\n",
      "[file retrieval] 2025-06-26 11:16:59 [INFO] Models found: [('llm_img2txt', 'gemini-2.0-flash'), ('ocr_llm_img2txt', 'gemini-2.0-flash'), ('llm_img2txt', 'gpt-4o'), ('ocr_llm_img2txt', 'gpt-4o')]\n",
      "[file retrieval] 2025-06-26 11:16:59 [INFO] Collecting results for model: gemini-2.0-flash\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc Names: ['kbaa-p096']\n",
      "Doc Pattern *kbaa-p096.txt\n",
      "/Users/muhammadkhalid/Desktop/map2025/ocr-benchmarking/data/ground-truth/txt\n",
      "['/Users/muhammadkhalid/Desktop/map2025/ocr-benchmarking/data/ground-truth/txt/gt_kbaa-p096.txt']\n",
      "Found paths: %s ['/Users/muhammadkhalid/Desktop/map2025/ocr-benchmarking/data/ground-truth/txt/gt_kbaa-p096.txt']\n",
      "{'kbaa-p096': 'ENTRIES 1846–1862\\nEvans, Robley—Fairchild \\nEvans, Robley Dunglison, 1846–1912. A sailor’s log; recollections of forty years of naval life. N.Y.: D. Appleton, 1901. 467 p. WHi. Naval officer who saw action in the Civil War and Spanish-American War. [1846] \\nEvans, Robley Dunglison, 1846–1912. An admiral’s log; being continued recollections of naval life. N.Y.: D. Appleton, 1911. 467 p. NN. The author’s career from the close of the Spanish-American War until his retirement in 1909. [1847] \\nEvans, Warren F. Autobiography of a Shaker...Mount Lebanon, N.Y.: the author, 1869? 162 p. MBAt. The story of his conversion. [1848] \\nEvarts, John W., b. 1837. Light of life...Oklahoma City: the author, 1909. 485 p. OkHi. Itinerant printer and apostle of “scientific religion”. [1849] \\nEverett, Syble (Byrd). Adventures with life; an autobiography of a distinguished Negro citizen. Boston: Meador, 1945. 182 p. WHi. School teacher and director of physical education, in Kansas and Oklahoma. [1850] \\nEverton, Walter Marion, b. 1876. “Autobiography”. (In his: Everton Knowles book. Logan: 1942.) p. 1–47. USIC. Utah teacher and merchant, including his missions for Mormons to North Carolina and Georgia. [1851] \\nEvstifeef, Alexander. The traitor. N.p.: 1938. 112 p. WaS. An account of his efforts to combat Communism in the twenties by a man who fled Russia. [1852] \\nEwell, Samuel Holbrook, 1819–1908. Original poems. Romeo, Mich: 1901. 146 p. Auto., p. i–iv. MiU-C. Michigan farmer and businessman. [1853] \\nEyland, Seth (pseud.), b. 1839. The evolution of a life. N.Y.: S.W. Green, 1884. 336 p. WHi. Includes his experiences as a soldier in the Union army. The remainder deals with journalism in New England and business in Texas. The Library of Congress assigns the authorship to David E. Cronin. Halkett names Silas E. Reynolds as the author. [1854] \\nEytinge, Rose, 1838–1911. The memories of Rose Eytinge, being recollections and observations of men, women, and events, during half a century. N.Y.: Frederick A. Stokes co., 1905. 311 p. NN. Theatrical reminiscences and memories of her years in Egypt as the wife of the American consul-general. [1855] \\nEzzell, Samuel R., 1834–1910. “Autobiographic sketch”. (In his: Great legacy. Cinc.: Central book concern, 1883.) p. 292–311. CSmH. Clergyman of the Disciples of Christ church in Missouri, Texas and Arkansas. [1856] \\n \\nF \\nF., M.T. My Chinese marriage. N.Y.: Duffield, 1922. 169 p. MtBu. The life in China of an American girl, who tells of her family life, farming, etc. [1857] \\nFackler, Samuel A. Ups and downs of a country editor, mostly downs. N.p.: Collins job print, n.d. 103 p. DLC. In Georgia, Alabama and Florida. [1858] \\nFagan, James Octavius, b. 1859. The autobiography of an individualist. Boston & N.Y.: Houghton Mifflin, 1912. 290 p. NN. Author of Confessions of a railroad signalman. Youthful adventures in Brazil and South Africa; telegraph operator and tower signalman on New England railroads; intellectual development and opinions on railroad and labor problems. [1859] \\nFagots from the camp fire. See Depre, Louis J. \\nFairback, Henry, b. 1839. A wanderer...St. Louis: Commercial prntg. co., 1912. 63 p. MoKu. German-born building contractor and banker in Missouri tells also of his early days as a carpenter in Illinois and a deck hand on the Mississippi. During the Civil War he served with an Illinois outfit. [1860] \\nFairbank, Calvin, b. 1816. Rev. Calvin Fairbank during slavery times...Chicago: R. R. McCabe, 1890. 207 p. ViHal. By a Methodist clergyman who lived in New England and in the South. Abolitionist. [1861] \\nFairchild, David Grandison, b. 1869. The world was my garden. N.Y.: Scribner’s, 1938. 494 p. WU. [1862] '}\n",
      "Doc Pattern kbaa-p096.txt\n",
      "/Users/muhammadkhalid/Desktop/map2025/ocr-benchmarking/results/llm_img2txt/gemini-2.0-flash\n",
      "[]\n",
      "Found paths: %s []\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 156\u001b[39m\n\u001b[32m    152\u001b[39m         nonorm_df.to_csv(os.path.join(\u001b[38;5;28mstr\u001b[39m(results_dir), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnonorm_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     73\u001b[39m model_path = os.path.join(project_root, \u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m, model_type, model)\n\u001b[32m     74\u001b[39m results[model_type] = results.get(model_type, {})\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m results[model_type][model], results[model_type][model][\u001b[33m\"\u001b[39m\u001b[33m__ALL__\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mget_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_has_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# logger.info(\"Collected results for model: %s\", list(results[model].keys()))\u001b[39;00m\n\u001b[32m     78\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mCollected results for model_type: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m, model: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, model_type, model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/map2025/ocr-benchmarking/src/tools/file_retrieval.py:116\u001b[39m, in \u001b[36mget_docs\u001b[39m\u001b[34m(dir, doc_names, name_has_prefix)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28mprint\u001b[39m(paths)\n\u001b[32m    114\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFound paths: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, paths)\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    117\u001b[39m     txt = f.read()\n\u001b[32m    118\u001b[39m docs[doc] = txt\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from benchmarking.txt_accuracy import clean_text_normalized, clean_text_nonorm, compute_metrics, build_dataframe, get_all_models\n",
    "from tools.file_retrieval import get_doc_names, get_docs\n",
    "from venv import logger\n",
    "from datetime import datetime\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Prerequisites:\n",
    "    - Ground truth text files located at `project_root/ground-truth/txt/kbaa-p#xyz.txt`\n",
    "    - LLM/OCR transcribed files located at:\n",
    "        - for LLM transcriptions: `project_root/results/llm_img2txt/<MODEL-NAME>/kbaa-p#xyz.txt`\n",
    "        - for OCR transcriptions: `project_root/results/ocr_img2txt/<MODEL-NAME>/kbaa-p#xyz.txt`\n",
    "\n",
    "    The main function will:\n",
    "    - Gather all ground truth text files\n",
    "    - For each ground truth text file and for each LLM/OCR model, gather the corresponding transcription\n",
    "    - Clean all the text files (normalized and not normalized)\n",
    "    - Compute metrics for each file and model\n",
    "    - Save results in two CSV files (one for normalized, one for non-normalized)\n",
    "        - Results are saved in `project_root/benchmarking-results/txt-accuracy`\n",
    "    \"\"\"\n",
    "\n",
    "    # =============\n",
    "    # Preliminaries\n",
    "    # =============\n",
    "\n",
    "    # args = parse_arguments()\n",
    "\n",
    "    script_dir = str(Path.cwd())\n",
    "    project_root = str(root_dir)\n",
    "    logger.info(\"Script directory: %s\", script_dir)\n",
    "    logger.info(\"Project root: %s\", project_root)\n",
    "\n",
    "    # Ground truth\n",
    "    ground_truth_dir = root_dir / \"data\" / \"ground-truth\" / \"txt\"\n",
    "    doc_names = get_doc_names(ground_truth_dir, keep_prefix=False)\n",
    "\n",
    "    # results/ paths\n",
    "    all_models = get_all_models(\n",
    "        os.path.join(project_root, \"results\", \"llm-img2txt\"),\n",
    "        os.path.join(project_root, \"results\", \"ocr-img2txt\"),\n",
    "        os.path.join(project_root, \"results\", \"ocr-llm-img2txt\"),\n",
    "    )\n",
    "    logger.info(f\"Models found: {all_models}\")\n",
    "\n",
    "    # ===========\n",
    "    # Gather files\n",
    "    # ===========\n",
    "\n",
    "    # -> Gather ground truths and put into dict:\n",
    "    ground_truths, all_texts = get_docs(ground_truth_dir, doc_names, name_has_prefix=True)\n",
    "    ground_truths[\"__ALL__\"] = all_texts\n",
    "    # ground_truths, ground_truths[\"__ALL__\"] = get_docs(ground_truth_dir, doc_names, name_has_prefix=False)\n",
    "    doc_lengths_normalized = {\n",
    "        doc: len(clean_text_normalized(text)) for doc, text in ground_truths.items()\n",
    "    }\n",
    "    doc_lengths_nonorm = {\n",
    "        doc: len(clean_text_nonorm(text)) for doc, text in ground_truths.items()\n",
    "    }\n",
    "    total_doc_len_normalized = len(clean_text_normalized(ground_truths[\"__ALL__\"]))\n",
    "    total_doc_len_nonorm = len(clean_text_nonorm(ground_truths[\"__ALL__\"]))\n",
    "\n",
    "    # -> Gather each transcribed document and put into dict:\n",
    "\n",
    "    # Structure: results[model][doc]\n",
    "    results = {}\n",
    "    \n",
    "\n",
    "    for model_type, model in all_models:\n",
    "        logger.info(\"Collecting results for model: %s\", model)\n",
    "        model_path = os.path.join(project_root, \"results\", model_type, model)\n",
    "        results[model_type] = results.get(model_type, {})\n",
    "        results[model_type][model], results[model_type][model][\"__ALL__\"] = get_docs(model_path, doc_names, name_has_prefix=False)\n",
    "            \n",
    "        # logger.info(\"Collected results for model: %s\", list(results[model].keys()))\n",
    "        logger.info(\"Collected results for model_type: %s, model: %s\", model_type, model)\n",
    "\n",
    "    # ===============\n",
    "    # Compute metrics\n",
    "    # ===============\n",
    "\n",
    "    normalized_results_data = {}\n",
    "    nonorm_results_data = {}\n",
    "\n",
    "    for model_type, model in all_models:\n",
    "        normalized_results_data[model_type] = normalized_results_data.get(model_type, {})\n",
    "        normalized_results_data[model_type][model] = normalized_results_data[model_type].get(model, {})\n",
    "        nonorm_results_data[model_type] = nonorm_results_data.get(model_type, {})\n",
    "        nonorm_results_data[model_type][model] = nonorm_results_data[model_type].get(model, {})\n",
    "\n",
    "        logger.info(\"Computing metrics for model_type: %s, model: %s\", model_type, model)\n",
    "        for doc in doc_names:\n",
    "            logger.info(\"Computing metrics for document: %s\", doc)\n",
    "            print(\"Hello: \", doc)\n",
    "            normalized_results_data[model_type][model][doc] = compute_metrics(\n",
    "                ground_truths[doc], results[model_type][model][doc], normalized=True\n",
    "            )\n",
    "            nonorm_results_data[model_type][model][doc] = compute_metrics(\n",
    "                ground_truths[doc], results[model_type][model][doc], normalized=False\n",
    "            )\n",
    "            print(normalized_results_data[model_type][model][doc])\n",
    "            print(nonorm_results_data[model_type][model][doc])\n",
    "\n",
    "        normalized_results_data[model_type][model][\"__ALL__\"] = compute_metrics(\n",
    "            ground_truths[\"__ALL__\"], results[model_type][model][\"__ALL__\"], normalized=True\n",
    "        )\n",
    "        nonorm_results_data[model_type][model][\"__ALL__\"] = compute_metrics(\n",
    "            ground_truths[\"__ALL__\"], results[model_type][model][\"__ALL__\"], normalized=False\n",
    "        )\n",
    "\n",
    "    # Compute metrics separately for __ALL__]\n",
    "\n",
    "    # ====================\n",
    "    # Put metrics in table\n",
    "    # ====================\n",
    "\n",
    "    time = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "    results_base_dir = root_dir / \"benchmarking-results\" / \"txt-accuracy\"\n",
    "\n",
    "    # Create different results directory for each model type\n",
    "    for model_type, _ in all_models:\n",
    "        results_dir = results_base_dir / model_type\n",
    "        results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        normalized_df = build_dataframe(\n",
    "            f\"normalized_{time}\",\n",
    "            doc_names,\n",
    "            normalized_results_data[model_type],\n",
    "            doc_lengths_normalized,\n",
    "            total_doc_len_normalized,\n",
    "        )\n",
    "        nonorm_df = build_dataframe(\n",
    "            f\"nonorm_{time}\",\n",
    "            doc_names,\n",
    "            nonorm_results_data[model_type],\n",
    "            doc_lengths_nonorm,\n",
    "            total_doc_len_nonorm,\n",
    "        )\n",
    "\n",
    "        # ============\n",
    "        # Save results\n",
    "        # ============\n",
    "\n",
    "        # # Default save to project_root/benchmarking-results/txt-accuracy\n",
    "        # results_path = os.path.join(project_root, \"benchmarking-results\", \"txt-accuracy\")\n",
    "        # if not os.path.exists(results_path):\n",
    "        #     os.makedirs(results_path)\n",
    "        normalized_df.to_csv(os.path.join(str(results_dir), f\"normalized_{time}.csv\"))\n",
    "        nonorm_df.to_csv(os.path.join(str(results_dir), f\"nonorm_{time}.csv\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
