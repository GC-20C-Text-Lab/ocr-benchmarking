{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4432e892",
   "metadata": {},
   "source": [
    "# OCR-mLLM Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5702eec5-e52d-4b51-8907-f593204a1b76",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 1. Run pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5839f516-258f-49aa-8b0f-aa4a6966d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "DEBUG = True\n",
    "\n",
    "# Get the user's path for the images folder assuming all images are stored here in .png format\n",
    "source_dir = Path.cwd().parent.parent / \"images\"\n",
    "\n",
    "# Get the user's path for the output folder, create one if it doesn't exist\n",
    "target_dir = Path.cwd().parent.parent / \"output\"\n",
    "target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Add all filenames in images directory into the `filenames` array with the ENTIRE filepath\n",
    "img_filepaths = []\n",
    "for path in source_dir.iterdir():\n",
    "  if path.is_file():\n",
    "    img_filepaths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e34ea1-f6ae-4de7-9887-764da7178f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files from ocr-benchmarking/images folder & write to output folder\n",
    "for path in img_filepaths:\n",
    "    file_name = target_dir / path.stem\n",
    "    file_name = str(file_name) + \".txt\"\n",
    "    \n",
    "    with open(file_name, 'w') as file:\n",
    "        file.write(pytesseract.image_to_string(Image.open(str(path)))) # TODO: Change config as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d58cb0c-aeb8-47cc-9528-26bc3a802984",
   "metadata": {},
   "source": [
    "# 2. Send to OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df39757",
   "metadata": {},
   "source": [
    "## (i) Prepare the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045337cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author Ent\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a text correction assistant. Your task is to clean up and correct errors from raw OCR output.\n",
    "The text may contain misrecognized characters, broken words, or incorrect formatting.\n",
    "Carefully read the provided OCR output and produce a corrected version that is grammatically accurate \n",
    "and as faithful to the original content as possible. Because this is a historical document, try to \n",
    "preserve archaic spelling or formatting where clearly intended. Only correct obvious OCR errors.\n",
    "\n",
    "Input (Raw OCR Text):\n",
    "{input}\n",
    "\"\"\"\n",
    "input = \"\"\n",
    "with open(\"/Users/muhammadkhalid/Desktop/map2025/ocr-benchmarking/output/kbaa-p 096.txt\", 'r') as file:\n",
    "    input += file.read()\n",
    "\n",
    "prompt = prompt_template.format(input=input).strip()\n",
    "\n",
    "# prompt = \"\"\"\n",
    "# From the provided image, give me the first word and nothing else\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73744527",
   "metadata": {},
   "source": [
    "## (ii) API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163080e4-5134-407c-9cdd-7a89141e1632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A-No.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "base64_image = encode_image(source_dir / \"kbaa-p 096.png\")\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        ]\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e20262",
   "metadata": {},
   "source": [
    "# 3. Benchmark results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9ab0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
