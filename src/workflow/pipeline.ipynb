{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4432e892",
   "metadata": {},
   "source": [
    "# OCR-mLLM Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5702eec5-e52d-4b51-8907-f593204a1b76",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 1. Run pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5839f516-258f-49aa-8b0f-aa4a6966d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "DEBUG = True\n",
    "\n",
    "root_dir = Path.cwd().parent.parent\n",
    "# Get the user's path for the images folder assuming all images are stored here in .png format\n",
    "source_dir = root_dir / \"images\"\n",
    "\n",
    "# Get the user's path for the output folder, create one if it doesn't exist\n",
    "target_dir = root_dir / \"results\"\n",
    "target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Add all filenames in images directory into the `filenames` array with the ENTIRE filepath\n",
    "img_filepaths = []\n",
    "for path in source_dir.iterdir():\n",
    "  if path.is_file():\n",
    "    img_filepaths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95e34ea1-f6ae-4de7-9887-764da7178f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files from ocr-benchmarking/images folder & write to results folder\n",
    "for path in img_filepaths:\n",
    "    file_name = target_dir / \"ocr_img2txt\" / path.stem\n",
    "    file_name = str(file_name) + \".txt\"\n",
    "    \n",
    "    with open(file_name, 'w') as file:\n",
    "        file.write(pytesseract.image_to_string(Image.open(str(path)))) # TODO: Change config as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d58cb0c-aeb8-47cc-9528-26bc3a802984",
   "metadata": {},
   "source": [
    "# 2. Send to OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df39757",
   "metadata": {},
   "source": [
    "## (i) Prepare the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "045337cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_ocr_llm = \"\"\"\n",
    "You are a text correction assistant. Your task is to clean up and correct errors from raw OCR output.\n",
    "The text may contain misrecognized characters, broken words, or incorrect formatting.\n",
    "Carefully read the provided OCR output and produce a corrected version that is grammatically accurate \n",
    "and as faithful to the original content as possible. Because this is a historical document, try to \n",
    "preserve archaic spelling or formatting where clearly intended. Only correct obvious OCR errors.\n",
    "Put the dates associated with each entry at the end of the line.\n",
    "\n",
    "Input (Raw OCR Text):\n",
    "{input}\n",
    "\"\"\"\n",
    "input = \"\"\n",
    "with open(\"/Users/muhammadkhalid/Desktop/map2025/ocr-benchmarking/results/ocr_img2txt/kbaa-p 096.txt\", 'r') as file:\n",
    "    input += file.read()\n",
    "\n",
    "prompt_ocr_llm = prompt_template_ocr_llm.format(input=input).strip()\n",
    "\n",
    "prompt_llm = \"\"\"\n",
    "You are an expert historian. Your task is to transcribe the provided image into text. The image\n",
    "is a 20th century bibliographic entry. Because this is a historical document, try to preserve \n",
    "archaic spelling or formatting where clearly intended. Put the dates associated with each entry at the end of the line.\n",
    "Return the text only, nothing else.\n",
    "\"\"\"\n",
    "\n",
    "# prompt = \"\"\"\n",
    "# From the provided image, give me the first word and nothing else\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73744527",
   "metadata": {},
   "source": [
    "## (ii) API Call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06535758",
   "metadata": {},
   "source": [
    "### a. OCR-LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "163080e4-5134-407c-9cdd-7a89141e1632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "base64_image = encode_image(source_dir / \"kbaa-p096.png\")\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt_ocr_llm\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        ]\n",
    ")\n",
    "\n",
    "with open(target_dir / \"ocr_llm_img2txt\" / \"gpt-4o\" / \"kbaa-p096.txt\", 'w') as file:\n",
    "    file.write(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cafe77",
   "metadata": {},
   "source": [
    "### b. LLM call (without OCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18c2eedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "base64_image = encode_image(source_dir / \"kbaa-p096.png\")\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt_llm\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        ]\n",
    ")\n",
    "\n",
    "with open(target_dir / \"llm_img2txt\" / \"gpt-4o\" / \"kbaa-p096.txt\", 'w') as file:\n",
    "    file.write(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e20262",
   "metadata": {},
   "source": [
    "# 3. Benchmark results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c21953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 10:19:01 [INFO] Script directory: /Users/muhammadkhalid/Desktop/map2025/ocr-benchmarking/src/workflow\n",
      "2025-06-20 10:19:01 [INFO] Project root: /Users/muhammadkhalid/Desktop/map2025/ocr-benchmarking\n",
      "2025-06-20 10:19:01 [INFO] Found ground-truth txt files: ['/Users/muhammadkhalid/Desktop/map2025/ocr-benchmarking/ground-truth/kbaa-p096.txt']\n",
      "2025-06-20 10:19:01 [INFO] Found file names: ['kbaa-p096']\n",
      "2025-06-20 10:19:01 [INFO] Models found: [('llm_img2txt', 'gpt-4o'), ('ocr_llm_img2txt', 'gpt-4o')]\n",
      "2025-06-20 10:19:01 [INFO] Collecting results for model: gpt-4o\n",
      "2025-06-20 10:19:01 [INFO] Collected results for model_type: llm_img2txt, model: gpt-4o\n",
      "2025-06-20 10:19:01 [INFO] Collecting results for model: gpt-4o\n",
      "2025-06-20 10:19:01 [INFO] Collected results for model_type: ocr_llm_img2txt, model: gpt-4o\n",
      "2025-06-20 10:19:01 [INFO] Computing metrics for model_type: llm_img2txt, model: gpt-4o\n",
      "2025-06-20 10:19:01 [INFO] Computing metrics for document: kbaa-p096\n",
      "2025-06-20 10:19:01 [INFO] Computing metrics for model_type: ocr_llm_img2txt, model: gpt-4o\n",
      "2025-06-20 10:19:01 [INFO] Computing metrics for document: kbaa-p096\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from benchmarking.txt_accuracy import clean_text_normalized, clean_text_nonorm, compute_metrics, build_dataframe, get_doc_names, get_all_models, get_docs\n",
    "from venv import logger\n",
    "from datetime import datetime\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Prerequisites:\n",
    "    - Ground truth text files located at `project_root/ground-truth/txt/kbaa-p#xyz.txt`\n",
    "    - LLM/OCR transcribed files located at:\n",
    "        - for LLM transcriptions: `project_root/results/llm_img2txt/<MODEL-NAME>/kbaa-p#xyz.txt`\n",
    "        - for OCR transcriptions: `project_root/results/ocr_img2txt/<MODEL-NAME>/kbaa-p#xyz.txt`\n",
    "\n",
    "    The main function will:\n",
    "    - Gather all ground truth text files\n",
    "    - For each ground truth text file and for each LLM/OCR model, gather the corresponding transcription\n",
    "    - Clean all the text files (normalized and not normalized)\n",
    "    - Compute metrics for each file and model\n",
    "    - Save results in two CSV files (one for normalized, one for non-normalized)\n",
    "        - Results are saved in `project_root/benchmarking-results/txt-accuracy`\n",
    "    \"\"\"\n",
    "\n",
    "    # =============\n",
    "    # Preliminaries\n",
    "    # =============\n",
    "\n",
    "    # args = parse_arguments()\n",
    "\n",
    "    script_dir = str(Path.cwd())\n",
    "    project_root = str(root_dir)\n",
    "    logger.info(\"Script directory: %s\", script_dir)\n",
    "    logger.info(\"Project root: %s\", project_root)\n",
    "\n",
    "    # Ground truth\n",
    "    ground_truth_dir = root_dir / \"ground-truth\"\n",
    "    doc_names = get_doc_names(ground_truth_dir)\n",
    "\n",
    "    # results/ paths\n",
    "    all_models = get_all_models(\n",
    "        os.path.join(project_root, \"results\", \"llm_img2txt\"),\n",
    "        os.path.join(project_root, \"results\", \"ocr_img2txt\"),\n",
    "        os.path.join(project_root, \"results\", \"ocr_llm_img2txt\"),\n",
    "    )\n",
    "    logger.info(f\"Models found: {all_models}\")\n",
    "\n",
    "    # ===========\n",
    "    # Gather files\n",
    "    # ===========\n",
    "\n",
    "    # -> Gather ground truths and put into dict:\n",
    "\n",
    "    ground_truths, ground_truths[\"__ALL__\"] = get_docs(ground_truth_dir, doc_names)\n",
    "    doc_lengths_normalized = {\n",
    "        doc: len(clean_text_normalized(text)) for doc, text in ground_truths.items()\n",
    "    }\n",
    "    doc_lengths_nonorm = {\n",
    "        doc: len(clean_text_nonorm(text)) for doc, text in ground_truths.items()\n",
    "    }\n",
    "    total_doc_len_normalized = len(clean_text_normalized(ground_truths[\"__ALL__\"]))\n",
    "    total_doc_len_nonorm = len(clean_text_nonorm(ground_truths[\"__ALL__\"]))\n",
    "\n",
    "    # -> Gather each transcribed document and put into dict:\n",
    "\n",
    "    # Structure: results[model][doc]\n",
    "    results = {}\n",
    "\n",
    "    for model_type, model in all_models:\n",
    "        logger.info(\"Collecting results for model: %s\", model)\n",
    "        model_path = os.path.join(project_root, \"results\", model_type, model)\n",
    "        results[model_type] = results.get(model_type, {})\n",
    "        results[model_type][model], results[model_type][model][\"__ALL__\"] = get_docs(model_path, doc_names)\n",
    "            \n",
    "        # logger.info(\"Collected results for model: %s\", list(results[model].keys()))\n",
    "        logger.info(\"Collected results for model_type: %s, model: %s\", model_type, model)\n",
    "\n",
    "    # ===============\n",
    "    # Compute metrics\n",
    "    # ===============\n",
    "\n",
    "    normalized_results_data = {}\n",
    "    nonorm_results_data = {}\n",
    "\n",
    "    for model_type, model in all_models:\n",
    "        normalized_results_data[model_type] = normalized_results_data.get(model_type, {})\n",
    "        normalized_results_data[model_type][model] = normalized_results_data[model_type].get(model, {})\n",
    "        nonorm_results_data[model_type] = nonorm_results_data.get(model_type, {})\n",
    "        nonorm_results_data[model_type][model] = nonorm_results_data[model_type].get(model, {})\n",
    "\n",
    "        logger.info(\"Computing metrics for model_type: %s, model: %s\", model_type, model)\n",
    "        for doc in doc_names:\n",
    "            logger.info(\"Computing metrics for document: %s\", doc)\n",
    "            normalized_results_data[model_type][model][doc] = compute_metrics(\n",
    "                ground_truths[doc], results[model_type][model][doc], normalized=True\n",
    "            )\n",
    "            nonorm_results_data[model_type][model][doc] = compute_metrics(\n",
    "                ground_truths[doc], results[model_type][model][doc], normalized=False\n",
    "            )\n",
    "\n",
    "        normalized_results_data[model_type][model][\"__ALL__\"] = compute_metrics(\n",
    "            ground_truths[\"__ALL__\"], results[model_type][model][\"__ALL__\"], normalized=True\n",
    "        )\n",
    "        nonorm_results_data[model_type][model][\"__ALL__\"] = compute_metrics(\n",
    "            ground_truths[\"__ALL__\"], results[model_type][model][\"__ALL__\"], normalized=False\n",
    "        )\n",
    "\n",
    "    # Compute metrics separately for __ALL__]\n",
    "\n",
    "    # ====================\n",
    "    # Put metrics in table\n",
    "    # ====================\n",
    "\n",
    "    time = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "    results_base_dir = root_dir / \"benchmarking-results\" / \"txt-accuracy\"\n",
    "\n",
    "    # Create different results directory for each model type\n",
    "    for model_type, _ in all_models:\n",
    "        results_dir = results_base_dir / model_type\n",
    "        results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        normalized_df = build_dataframe(\n",
    "            f\"normalized_{time}\",\n",
    "            doc_names,\n",
    "            normalized_results_data[model_type],\n",
    "            doc_lengths_normalized,\n",
    "            total_doc_len_normalized,\n",
    "        )\n",
    "        nonorm_df = build_dataframe(\n",
    "            f\"nonorm_{time}\",\n",
    "            doc_names,\n",
    "            nonorm_results_data[model_type],\n",
    "            doc_lengths_nonorm,\n",
    "            total_doc_len_nonorm,\n",
    "        )\n",
    "\n",
    "        # ============\n",
    "        # Save results\n",
    "        # ============\n",
    "\n",
    "        # # Default save to project_root/benchmarking-results/txt-accuracy\n",
    "        # results_path = os.path.join(project_root, \"benchmarking-results\", \"txt-accuracy\")\n",
    "        # if not os.path.exists(results_path):\n",
    "        #     os.makedirs(results_path)\n",
    "        normalized_df.to_csv(os.path.join(str(results_dir), f\"normalized_{time}.csv\"))\n",
    "        nonorm_df.to_csv(os.path.join(str(results_dir), f\"nonorm_{time}.csv\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad9ab0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evans robley dunglison 18461912 a sailors log recollections of forty years of naval life ny d appleton 1901 467 p whi naval officer who saw action in the civil war and spanishamerican war 1846 evans robley dunglison 18461912 an admirals log being continued recollections of naval life ny d appleton 1911 467 p nn the authors career from the close of the spanishamerican war until his retirement in 1909 1847 evans warren f autobiography of a shakermount lebanon ny the author 1869 162 p mbat the story of his conversion 1848 evarts john w b 1837 light of lifeoklahoma city the author 1909 485 p okhi itinerant printer and apostle of scientific religion 1849 everett syble byrd adventures with life an autobiography of a distinguished negro citizen boston meador 1945 182 p whi school teacher and director of physical education in kansas and oklahoma 1850 everton walter marion b 1876 autobiography in his everton knowles book logan 1942 p 147 usic utah teacher and merchant including his missions for mormons to north carolina and georgia 1851 evstifeef alexander the traitor np 1938 112 p was an account of his efforts to combat communism in the twenties by a man who fled russia 1852 ewell samuel holbrook 18191908 original poems romeo mich 1901 146 p auto p iiv miuc michigan farmer and businessman 1853 eyland seth pseud b 1839 the evolution of a life ny sw green 1884 336 p whi includes his experiences as a soldier in the union army the remainder deals with journalism in new england and business in texas the library of congress assigns the authorship to david e cronin halkett names silas e reynolds as the author 1854 eytinge rose 18381911 the memories of rose eytinge being recollections and observations of men women and events during half a century ny frederick a stokes co 1905 311 p nn theatrical reminiscences and memories of her years in egypt as the wife of the american consulgeneral 1855 ezzell samuel r 18341910 autobiographic sketch in his great legacy cinc central book concern 1883 p 292311 csmh clergyman of the disciples of christ church in missouri texas and arkansas 1856 f mt my chinese marriage ny duffield 1922 169 p mtbu the life in china of an american girl who tells of her family life farming etc 1857 fackler samuel a ups and downs of a country editor mostly downs np collins job print nd 103 p dlc in georgia alabama and florida 1858 fagan james octavius b 1859 the autobiography of an individualist boston ny houghton mifflin 1912 290 p nn author of confessions of a railroad signalman youthful adventures in brazil and south africa telegraph operator and tower signalman on new england railroads intellectual development and opinions on railroad and labor problems 1859 fairback henry b 1839 a wanderer st louis commercial prntg co 1912 63 p moku german born building contractor and banker in missouri tells also of his early days as a carpenter in illinois and a deck hand on the mississippi during the civil war he served with an illinois outfit 1860 fairbank calvin b 1816 rev calvin fairbank during slavery timeschicago r r mccabe 1890 207 p vihal by a methodist clergyman who lived in new england in his youth abolitionist 1861 fairchild david grandison b 1869 the world was my garden ny scribners 1938 494 p wu 1862\n",
      "entries 18461862 evans robley dunglison 18461912 a sailors log recollections of forty years of naval life ny d appleton 1901 467 p whi naval officer who saw action in the civil war and spanishamerican war 1846 evans robley dunglison 18461912 an admirals log being continued recollections of naval life ny d appleton 1911 467 p nn the authors career from the close of the spanishamerican war until his retirement in 1909 1847 evans warren f autobiography of a shakermount lebanon ny the author 1869 162 p mbat the story of his conversion 1848 evarts john w b 1837 light of lifeoklahoma city the author 1909 485 p okhi itinerant printer and apostle of scientific religion 1849 everett syble byrd adventures with life an autobiography of a distinguished negro citizen boston meador 1945 182 p whi school teacher and director of physical education in kansas and oklahoma 1850 everton walter marion b 1876 autobiography in his everton knowles book logan 1942 p 147 usic utah teacher and merchant including his missions for mormons to north carolina and georgia 1851 evstifeef alexander the traitor np 1938 112 p was an account of his efforts to combat communism in the twenties by a man who fled russia 1852 ewell samuel holbrook 18191908 original poems romeo mich 1901 146 p auto p iiv miuc michigan farmer and businessman 1853 eyland seth pseud b 1839 the evolution of a life ny sw green 1884 336 p whi includes his experiences as a soldier in the union army the remainder deals with journalism in new england and business in texas the library of congress assigns the authorship to david e cronin halkett names silas e reynolds as the author 1854 eytinge rose 18381911 the memories of rose eytinge being recollections and observations of men women and events during half a century ny frederick a stokes co 1905 311 p nn theatrical reminiscences and memories of her years in egypt as the wife of the american consulgeneral 1855 ezzell samuel r 18341910 autobiographic sketch in his great legacy cinc central book concern 1883 p 292311 csmh clergyman of the disciples of christ church in missouri texas and arkansas 1856 f mt my chinese marriage ny duffield 1922 169 p mtbu the life in china of an american girl who tells of her family life farming etc 1857 fackler samuel a ups and downs of a country editor mostly downs np collins job print nd 103 p dlc in georgia alabama and florida 1858 fagan james octavius b 1859 the autobiography of an individualist boston ny houghton mifflin 1912 290 p nn author of confessions of a railroad signalman youthful adventures in brazil and south africa telegraph operator and tower signalman on new england railroads intellectual development and opinions on railroad and labor problems 1859 fagots from the camp fire see depre louis j fairback henry b 1839 a wandererst louis commercial prntg co 1912 63 p moku germanborn building contractor and banker in missouri tells also of his early days as a carpenter in illinois and a deck hand on the mississippi during the civil war he served with an illinois outfit 1860 fairbank calvin b 1816 rev calvin fairbank during slavery timeschicago r r mccabe 1890 207 p vihal by a methodist clergyman who lived in new england and in the south abolitionist 1861 fairchild david grandison b 1869 the world was my garden ny scribners 1938 494 p wu 1862\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from benchmarking.txt_accuracy import clean_text_normalized\n",
    "\n",
    "gt_dir = root_dir / \"ground-truth\"\n",
    "ocr_dir = root_dir / \"results\" / \"ocr_img2txt\"\n",
    "llm_dir = root_dir / \"results\" / \"llm_img2txt\" / \"gpt-4o\"\n",
    "ocr_llm_dir = root_dir / \"results\" / \"ocr_llm_img2txt\" / \"gpt-4o\"\n",
    "\n",
    "ocr_llm_filepaths = []\n",
    "for path in ocr_llm_dir.iterdir():\n",
    "  if path.is_file():\n",
    "    if \"3\" in path.stem:\n",
    "        continue\n",
    "    ocr_llm_filepaths.append(path)\n",
    "\n",
    "ocr_filepaths = []\n",
    "for path in ocr_dir.iterdir():\n",
    "  if path.is_file():\n",
    "    if \"3\" in path.stem:\n",
    "        continue\n",
    "    ocr_filepaths.append(path)\n",
    "\n",
    "llm_filepaths = []\n",
    "for path in llm_dir.iterdir():\n",
    "  if path.is_file():\n",
    "    if \"3\" in path.stem:\n",
    "        continue\n",
    "    llm_filepaths.append(path)\n",
    "\n",
    "gt_filepaths = []\n",
    "for path in gt_dir.iterdir():\n",
    "  if path.is_file():\n",
    "    gt_filepaths.append(path)\n",
    "\n",
    "# if len(ocr_filepaths) != len(gt_filepaths):\n",
    "#     raise ValueError(\"Number of OCR files and GT files do not match\")\n",
    "\n",
    "for ocr_llm_path, llm_path, gt_path in zip(ocr_llm_filepaths, llm_filepaths, gt_filepaths):\n",
    "    with open(ocr_llm_path, 'r') as file:\n",
    "        ocr_llm_text = clean_text_normalized(file.read())\n",
    "    with open(llm_path, 'r') as file:\n",
    "        llm_text = clean_text_normalized(file.read())\n",
    "    with open(gt_path, 'r') as file:\n",
    "        gt_text = clean_text_normalized(file.read())\n",
    "print(llm_text)\n",
    "print(gt_text)\n",
    "\n",
    "for i in range(len(ocr_llm_text)):\n",
    "    if ocr_llm_text[i] != gt_text[i]:\n",
    "        print(f\"Mismatch at index {i}\")\n",
    "        print(f\"OCR: {ocr_llm_text[i]}\")\n",
    "        print(f\"GT: {gt_text[i]}\")\n",
    "        break\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
