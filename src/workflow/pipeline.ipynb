{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4432e892",
   "metadata": {},
   "source": [
    "# OCR-mLLM Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadd7cf4",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002663b1",
   "metadata": {},
   "source": [
    "### a. Run this cell to ensure you have all the necessary directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd3540d",
   "metadata": {},
   "source": [
    "Before running the cell make sure you have an images folder in your root directory to feed the images into the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "549ec682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Get the root directory of the project\n",
    "root_dir = Path.cwd().parent.parent\n",
    "\n",
    "# Get the user's path for the images folder assuming all images are stored here in .png format\n",
    "source_dir = root_dir / \"images\"\n",
    "\n",
    "# Get the user's path for the output folder, create one if it doesn't exist\n",
    "txt_output_dir = root_dir / \"results\"\n",
    "txt_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# bm_output_dir = root_dir / \"benchmarking-results\"/ \"txt-accuracy\"\n",
    "# bm_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# llm_array = [\"gpt-4o\", \"gemini-2.5-flash\", \"claude-4-sonnet\"]\n",
    "llm_array = [\"gpt-4o\"]\n",
    "\n",
    "def make_llm_dirs(llm_array, target_dir):\n",
    "    for llm in llm_array:\n",
    "        dir = target_dir / \"ocr_img2txt\"\n",
    "        dir.mkdir(parents=True, exist_ok=True)\n",
    "        dir = target_dir / \"llm_img2txt\" / llm\n",
    "        dir.mkdir(parents=True, exist_ok=True)\n",
    "        dir = target_dir / \"ocr_llm_img2txt\" / llm\n",
    "        dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "make_llm_dirs(llm_array, txt_output_dir)\n",
    "make_llm_dirs(llm_array, bm_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859c660",
   "metadata": {},
   "source": [
    "### b. Setup API keys & image encoding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a7ae833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "gpt_client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "claude_client = Anthropic(api_key=anthropic_api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3a5773",
   "metadata": {},
   "source": [
    "### c. Get image file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fed71bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all filenames in images directory into the `filenames` array with the ENTIRE filepath\n",
    "img_filepaths = []\n",
    "for path in source_dir.iterdir():\n",
    "  if path.suffix.lower() == \".png\" and path.is_file():\n",
    "    img_filepaths.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5702eec5-e52d-4b51-8907-f593204a1b76",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 2. Run pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95e34ea1-f6ae-4de7-9887-764da7178f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files from ocr-benchmarking/images folder & write to results folder\n",
    "for path in img_filepaths:\n",
    "    file_name = txt_output_dir / \"ocr_img2txt\" / path.stem\n",
    "    file_name = str(file_name) + \".txt\"\n",
    "    \n",
    "    with open(file_name, 'w') as file:\n",
    "        file.write(pytesseract.image_to_string(Image.open(str(path)))) # TODO: Change config as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df39757",
   "metadata": {},
   "source": [
    "## 3. Prepare the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "045337cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_ocr_llm = \"\"\"\n",
    "You are a text correction assistant. Your task is to clean up and correct errors from raw OCR output.\n",
    "The text may contain misrecognized characters, broken words, or incorrect formatting.\n",
    "Carefully read the provided OCR output and produce a corrected version that is grammatically accurate \n",
    "and as faithful to the original content as possible. Because this is a historical document, try to \n",
    "preserve archaic spelling or formatting where clearly intended. Only correct obvious OCR errors.\n",
    "Put the dates associated with each entry at the end of the line.\n",
    "\n",
    "Input (Raw OCR Text):\n",
    "{input}\n",
    "\"\"\"\n",
    "input = \"\"\n",
    "with open(\"/Users/muhammadkhalid/Desktop/map2025/ocr-benchmarking/results/ocr_img2txt/kbaa-p096.txt\", 'r') as file:\n",
    "    input += file.read()\n",
    "\n",
    "prompt_ocr_llm = prompt_template_ocr_llm.format(input=input).strip()\n",
    "\n",
    "prompt_llm = \"\"\"\n",
    "You are an expert historian. Your task is to transcribe the provided image into text. The image\n",
    "is a 20th century bibliographic entry. Because this is a historical document, try to preserve \n",
    "archaic spelling or formatting where clearly intended. Put the dates associated with each entry at the end of the line.\n",
    "Return the text only, nothing else.\n",
    "\"\"\"\n",
    "\n",
    "# prompt = \"\"\"\n",
    "# From the provided image, give me the first word and nothing else\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d58cb0c-aeb8-47cc-9528-26bc3a802984",
   "metadata": {},
   "source": [
    "## 4. Send to OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06535758",
   "metadata": {},
   "source": [
    "### a. OCR-LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163080e4-5134-407c-9cdd-7a89141e1632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-06-23 15:42:25 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "for path in img_filepaths:\n",
    "    base64_image = encode_image(path)\n",
    "\n",
    "    response = gpt_client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt_ocr_llm\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            ]\n",
    "    )\n",
    "\n",
    "    with open(txt_output_dir / \"ocr_llm_img2txt\" / \"gpt-4o\" / Path(path.stem + \".txt\"), 'w') as file:\n",
    "        file.write(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cafe77",
   "metadata": {},
   "source": [
    "### b. LLM call (without OCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c2eedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-06-23 15:43:15 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "for path in img_filepaths:\n",
    "    base64_image = encode_image(path)\n",
    "\n",
    "    response = gpt_client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt_llm\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            ]\n",
    "    )\n",
    "\n",
    "    with open(txt_output_dir / \"llm_img2txt\" / \"gpt-4o\" / Path(path.stem + \".txt\"), 'w') as file:\n",
    "        file.write(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d06c34",
   "metadata": {},
   "source": [
    "## 5. Send to Claude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0869c81",
   "metadata": {},
   "source": [
    "### a. OCR-LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651e17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-06-23 16:00:46 [INFO] HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 400 Bad Request\"\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages.0.content.1.image.source.base64: image exceeds 5 MB maximum: 12980092 bytes > 5242880 bytes'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m img_filepaths:\n\u001b[32m      2\u001b[39m     base64_image = encode_image(path)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     response = \u001b[43mclaude_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclaude-opus-4-20250514\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m                        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m                        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_ocr_llm\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m                        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m                        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msource\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m                            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbase64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m                            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmedia_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimage/png\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m                            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase64_image\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m                        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m                \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28mprint\u001b[39m(response)\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(txt_output_dir / \u001b[33m\"\u001b[39m\u001b[33mocr_llm_img2txt\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mclaude-4-sonnet\u001b[39m\u001b[33m\"\u001b[39m / Path(path.stem + \u001b[33m\"\u001b[39m\u001b[33m.txt\u001b[39m\u001b[33m\"\u001b[39m), \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/map2025/ocr-benchmarking/.venv/lib/python3.12/site-packages/anthropic/_utils/_utils.py:283\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    281\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/map2025/ocr-benchmarking/.venv/lib/python3.12/site-packages/anthropic/resources/messages/messages.py:978\u001b[39m, in \u001b[36mMessages.create\u001b[39m\u001b[34m(self, max_tokens, messages, model, metadata, service_tier, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    971\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[32m    972\u001b[39m     warnings.warn(\n\u001b[32m    973\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    974\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    975\u001b[39m         stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    976\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m978\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/v1/messages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop_sequences\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    991\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthinking\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    993\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    994\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    995\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    996\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsStreaming\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/map2025/ocr-benchmarking/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:1314\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1300\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1301\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1302\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1309\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1310\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1311\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1312\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1313\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/map2025/ocr-benchmarking/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:1102\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1099\u001b[39m             err.response.read()\n\u001b[32m   1101\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1102\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages.0.content.1.image.source.base64: image exceeds 5 MB maximum: 12980092 bytes > 5242880 bytes'}}"
     ]
    }
   ],
   "source": [
    "# for path in img_filepaths:\n",
    "#     base64_image = encode_image(path)\n",
    "\n",
    "#     response = claude_client.messages.create(\n",
    "#         model='claude-opus-4-20250514',\n",
    "#         temperature=0,\n",
    "#         max_tokens=10,\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"user\", \n",
    "#                 \"content\": [\n",
    "#                     {\n",
    "#                         \"type\": \"text\",\n",
    "#                         \"text\": prompt_ocr_llm\n",
    "#                     },\n",
    "#                     {\n",
    "#                         \"type\": \"image\",\n",
    "#                         \"source\": {\n",
    "#                             \"type\": \"base64\",\n",
    "#                             \"media_type\": \"image/png\",\n",
    "#                             \"data\": base64_image\n",
    "#                         }\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#             ]\n",
    "#     )\n",
    "#     print(response)\n",
    "\n",
    "#     with open(txt_output_dir / \"ocr_llm_img2txt\" / \"claude-4-sonnet\" / Path(path.stem + \".txt\"), 'w') as file:\n",
    "#         file.write(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b610ccd9",
   "metadata": {},
   "source": [
    "### b. LLM call (without OCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497c3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-06-23 15:42:25 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# for path in img_filepaths:\n",
    "#     base64_image = encode_image(path)\n",
    "\n",
    "#     response = claude_client.messages.create(\n",
    "#         model='claude-opus-4-20250514',\n",
    "#         temperature=0,\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"user\", \n",
    "#                 \"content\": [\n",
    "#                     {\n",
    "#                         \"type\": \"text\",\n",
    "#                         \"text\": prompt_llm\n",
    "#                     },\n",
    "#                     {\n",
    "#                         \"type\": \"image\",\n",
    "#                         \"source\": {\n",
    "#                             \"type\": \"base64\",\n",
    "#                             \"media_type\": \"image/png\",\n",
    "#                             \"data\": base64_image\n",
    "#                         }\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#             ]\n",
    "#     )\n",
    "\n",
    "#     with open(txt_output_dir / \"llm_img2txt\" / \"claude-4-sonnet\" / Path(path.stem + \".txt\"), 'w') as file:\n",
    "#         file.write(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e20262",
   "metadata": {},
   "source": [
    "## 5. Benchmark results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "77c21953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-06-23 16:08:27 [INFO] Script directory: /Users/muhammadkhalid/Desktop/map2025/ocr-benchmarking/src/workflow\n",
      "[file retrieval] 2025-06-23 16:08:27 [INFO] Project root: /Users/muhammadkhalid/Desktop/map2025/ocr-benchmarking\n",
      "[file retrieval] 2025-06-23 16:08:27 [INFO] Found ground-truth txt files: ['/Users/muhammadkhalid/Desktop/map2025/ocr-benchmarking/ground-truth/kbaa-p096.txt']\n",
      "[file retrieval] 2025-06-23 16:08:27 [INFO] Found file names: ['kbaa-p096']\n",
      "[file retrieval] 2025-06-23 16:08:27 [INFO] Models found: [('llm_img2txt', 'gpt-4o'), ('ocr_llm_img2txt', 'gpt-4o')]\n",
      "[file retrieval] 2025-06-23 16:08:27 [INFO] Collecting results for model: gpt-4o\n",
      "[file retrieval] 2025-06-23 16:08:27 [INFO] Collected results for model_type: llm_img2txt, model: gpt-4o\n",
      "[file retrieval] 2025-06-23 16:08:27 [INFO] Collecting results for model: gpt-4o\n",
      "[file retrieval] 2025-06-23 16:08:27 [INFO] Collected results for model_type: ocr_llm_img2txt, model: gpt-4o\n",
      "[file retrieval] 2025-06-23 16:08:27 [INFO] Computing metrics for model_type: llm_img2txt, model: gpt-4o\n",
      "[file retrieval] 2025-06-23 16:08:27 [INFO] Computing metrics for document: kbaa-p096\n",
      "[file retrieval] 2025-06-23 16:08:27 [INFO] Computing metrics for model_type: ocr_llm_img2txt, model: gpt-4o\n",
      "[file retrieval] 2025-06-23 16:08:27 [INFO] Computing metrics for document: kbaa-p096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dist_char': 43, 'cer': 0.012786202795123401, 'wer': 0.07226890756302522, 'token_sort_ratio': 99.22225545916841}\n",
      "{'dist_char': 59, 'cer': 0.01607191500953419, 'wer': 0.09090909090909091, 'token_sort_ratio': 98.84926836198323}\n",
      "{'dist_char': 24, 'cer': 0.007136485280999108, 'wer': 0.040336134453781515, 'token_sort_ratio': 99.64189794091315}\n",
      "{'dist_char': 40, 'cer': 0.010896213565785889, 'wer': 0.06493506493506493, 'token_sort_ratio': 99.07840635190699}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from benchmarking.txt_accuracy import clean_text_normalized, clean_text_nonorm, compute_metrics, build_dataframe, get_doc_names, get_all_models, get_docs\n",
    "from venv import logger\n",
    "from datetime import datetime\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Prerequisites:\n",
    "    - Ground truth text files located at `project_root/ground-truth/txt/kbaa-p#xyz.txt`\n",
    "    - LLM/OCR transcribed files located at:\n",
    "        - for LLM transcriptions: `project_root/results/llm_img2txt/<MODEL-NAME>/kbaa-p#xyz.txt`\n",
    "        - for OCR transcriptions: `project_root/results/ocr_img2txt/<MODEL-NAME>/kbaa-p#xyz.txt`\n",
    "\n",
    "    The main function will:\n",
    "    - Gather all ground truth text files\n",
    "    - For each ground truth text file and for each LLM/OCR model, gather the corresponding transcription\n",
    "    - Clean all the text files (normalized and not normalized)\n",
    "    - Compute metrics for each file and model\n",
    "    - Save results in two CSV files (one for normalized, one for non-normalized)\n",
    "        - Results are saved in `project_root/benchmarking-results/txt-accuracy`\n",
    "    \"\"\"\n",
    "\n",
    "    # =============\n",
    "    # Preliminaries\n",
    "    # =============\n",
    "\n",
    "    # args = parse_arguments()\n",
    "\n",
    "    script_dir = str(Path.cwd())\n",
    "    project_root = str(root_dir)\n",
    "    logger.info(\"Script directory: %s\", script_dir)\n",
    "    logger.info(\"Project root: %s\", project_root)\n",
    "\n",
    "    # Ground truth\n",
    "    ground_truth_dir = root_dir / \"ground-truth\"\n",
    "    doc_names = get_doc_names(ground_truth_dir)\n",
    "\n",
    "    # results/ paths\n",
    "    all_models = get_all_models(\n",
    "        os.path.join(project_root, \"results\", \"llm_img2txt\"),\n",
    "        os.path.join(project_root, \"results\", \"ocr_img2txt\"),\n",
    "        os.path.join(project_root, \"results\", \"ocr_llm_img2txt\"),\n",
    "    )\n",
    "    logger.info(f\"Models found: {all_models}\")\n",
    "\n",
    "    # ===========\n",
    "    # Gather files\n",
    "    # ===========\n",
    "\n",
    "    # -> Gather ground truths and put into dict:\n",
    "\n",
    "    ground_truths, ground_truths[\"__ALL__\"] = get_docs(ground_truth_dir, doc_names)\n",
    "    doc_lengths_normalized = {\n",
    "        doc: len(clean_text_normalized(text)) for doc, text in ground_truths.items()\n",
    "    }\n",
    "    doc_lengths_nonorm = {\n",
    "        doc: len(clean_text_nonorm(text)) for doc, text in ground_truths.items()\n",
    "    }\n",
    "    total_doc_len_normalized = len(clean_text_normalized(ground_truths[\"__ALL__\"]))\n",
    "    total_doc_len_nonorm = len(clean_text_nonorm(ground_truths[\"__ALL__\"]))\n",
    "\n",
    "    # -> Gather each transcribed document and put into dict:\n",
    "\n",
    "    # Structure: results[model][doc]\n",
    "    results = {}\n",
    "\n",
    "    for model_type, model in all_models:\n",
    "        logger.info(\"Collecting results for model: %s\", model)\n",
    "        model_path = os.path.join(project_root, \"results\", model_type, model)\n",
    "        results[model_type] = results.get(model_type, {})\n",
    "        results[model_type][model], results[model_type][model][\"__ALL__\"] = get_docs(model_path, doc_names)\n",
    "            \n",
    "        # logger.info(\"Collected results for model: %s\", list(results[model].keys()))\n",
    "        logger.info(\"Collected results for model_type: %s, model: %s\", model_type, model)\n",
    "\n",
    "    # ===============\n",
    "    # Compute metrics\n",
    "    # ===============\n",
    "\n",
    "    normalized_results_data = {}\n",
    "    nonorm_results_data = {}\n",
    "\n",
    "    for model_type, model in all_models:\n",
    "        normalized_results_data[model_type] = normalized_results_data.get(model_type, {})\n",
    "        normalized_results_data[model_type][model] = normalized_results_data[model_type].get(model, {})\n",
    "        nonorm_results_data[model_type] = nonorm_results_data.get(model_type, {})\n",
    "        nonorm_results_data[model_type][model] = nonorm_results_data[model_type].get(model, {})\n",
    "\n",
    "        logger.info(\"Computing metrics for model_type: %s, model: %s\", model_type, model)\n",
    "        for doc in doc_names:\n",
    "            logger.info(\"Computing metrics for document: %s\", doc)\n",
    "            normalized_results_data[model_type][model][doc] = compute_metrics(\n",
    "                ground_truths[doc], results[model_type][model][doc], normalized=True\n",
    "            )\n",
    "            nonorm_results_data[model_type][model][doc] = compute_metrics(\n",
    "                ground_truths[doc], results[model_type][model][doc], normalized=False\n",
    "            )\n",
    "            print(normalized_results_data[model_type][model][doc])\n",
    "            print(nonorm_results_data[model_type][model][doc])\n",
    "\n",
    "        normalized_results_data[model_type][model][\"__ALL__\"] = compute_metrics(\n",
    "            ground_truths[\"__ALL__\"], results[model_type][model][\"__ALL__\"], normalized=True\n",
    "        )\n",
    "        nonorm_results_data[model_type][model][\"__ALL__\"] = compute_metrics(\n",
    "            ground_truths[\"__ALL__\"], results[model_type][model][\"__ALL__\"], normalized=False\n",
    "        )\n",
    "\n",
    "    # Compute metrics separately for __ALL__]\n",
    "\n",
    "    # ====================\n",
    "    # Put metrics in table\n",
    "    # ====================\n",
    "\n",
    "    time = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "    results_base_dir = root_dir / \"benchmarking-results\" / \"txt-accuracy\"\n",
    "\n",
    "    # Create different results directory for each model type\n",
    "    for model_type, _ in all_models:\n",
    "        results_dir = results_base_dir / model_type\n",
    "        results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        normalized_df = build_dataframe(\n",
    "            f\"normalized_{time}\",\n",
    "            doc_names,\n",
    "            normalized_results_data[model_type],\n",
    "            doc_lengths_normalized,\n",
    "            total_doc_len_normalized,\n",
    "        )\n",
    "        nonorm_df = build_dataframe(\n",
    "            f\"nonorm_{time}\",\n",
    "            doc_names,\n",
    "            nonorm_results_data[model_type],\n",
    "            doc_lengths_nonorm,\n",
    "            total_doc_len_nonorm,\n",
    "        )\n",
    "\n",
    "        # ============\n",
    "        # Save results\n",
    "        # ============\n",
    "\n",
    "        # # Default save to project_root/benchmarking-results/txt-accuracy\n",
    "        # results_path = os.path.join(project_root, \"benchmarking-results\", \"txt-accuracy\")\n",
    "        # if not os.path.exists(results_path):\n",
    "        #     os.makedirs(results_path)\n",
    "        normalized_df.to_csv(os.path.join(str(results_dir), f\"normalized_{time}.csv\"))\n",
    "        nonorm_df.to_csv(os.path.join(str(results_dir), f\"nonorm_{time}.csv\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317a2cae",
   "metadata": {},
   "source": [
    "## Don't use the cell below, this is just for my use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad9ab0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evans robley dunglison 18461912 a sailors log recollections of forty years of naval life ny d appleton 1901 467 p whi naval officer who saw action in the civil war and spanishamerican war 1846 evans robley dunglison 18461912 an admirals log being continued recollections of naval life ny d appleton 1911 467 p nn the authors career from the close of the spanishamerican war until his retirement in 1909 1847 evans warren f autobiography of a shakermount lebanon ny the author 1869 162 p mbat the story of his conversion 1848 evarts john w b 1837 light of lifeoklahoma city the author 1909 485 p okhi itinerant printer and apostle of scientific religion 1849 everett syble byrd adventures with life an autobiography of a distinguished negro citizen boston meador 1945 182 p whi school teacher and director of physical education in kansas and oklahoma 1850 everton walter marion b 1876 autobiography in his everton knowles book logan 1942 p 147 usic utah teacher and merchant including his missions for mormons to north carolina and georgia 1851 evstifeef alexander the traitor np 1938 112 p was an account of his efforts to combat communism in the twenties by a man who fled russia 1852 ewell samuel holbrook 18191908 original poems romeo mich 1901 146 p auto p iiv miuc michigan farmer and businessman 1853 eyland seth pseud b 1839 the evolution of a life ny sw green 1884 336 p whi includes his experiences as a soldier in the union army the remainder deals with journalism in new england and business in texas the library of congress assigns the authorship to david e cronin halkett names silas e reynolds as the author 1854 eytinge rose 18381911 the memories of rose eytinge being recollections and observations of men women and events during half a century ny frederick a stokes co 1905 311 p nn theatrical reminiscences and memories of her years in egypt as the wife of the american consulgeneral 1855 ezzell samuel r 18341910 autobiographic sketch in his great legacy cinc central book concern 1883 p 292311 csmh clergyman of the disciples of christ church in missouri texas and arkansas 1856 f mt my chinese marriage ny duffield 1922 169 p mtbu the life in china of an american girl who tells of her family life farming etc 1857 fackler samuel a ups and downs of a country editor mostly downs np collins job print nd 103 p dlc in georgia alabama and florida 1858 fagan james octavius b 1859 the autobiography of an individualist boston ny houghton mifflin 1912 290 p nn author of confessions of a railroad signalman youthful adventures in brazil and south africa telegraph operator and tower signalman on new england railroads intellectual development and opinions on railroad and labor problems 1859 fairback henry b 1839 a wanderer st louis commercial prntg co 1912 63 p moku german born building contractor and banker in missouri tells also of his early days as a carpenter in illinois and a deck hand on the mississippi during the civil war he served with an illinois outfit 1860 fairbank calvin b 1816 rev calvin fairbank during slavery timeschicago r r mccabe 1890 207 p vihal by a methodist clergyman who lived in new england in his youth abolitionist 1861 fairchild david grandison b 1869 the world was my garden ny scribners 1938 494 p wu 1862\n",
      "entries 18461862 evans robley dunglison 18461912 a sailors log recollections of forty years of naval life ny d appleton 1901 467 p whi naval officer who saw action in the civil war and spanishamerican war 1846 evans robley dunglison 18461912 an admirals log being continued recollections of naval life ny d appleton 1911 467 p nn the authors career from the close of the spanishamerican war until his retirement in 1909 1847 evans warren f autobiography of a shakermount lebanon ny the author 1869 162 p mbat the story of his conversion 1848 evarts john w b 1837 light of lifeoklahoma city the author 1909 485 p okhi itinerant printer and apostle of scientific religion 1849 everett syble byrd adventures with life an autobiography of a distinguished negro citizen boston meador 1945 182 p whi school teacher and director of physical education in kansas and oklahoma 1850 everton walter marion b 1876 autobiography in his everton knowles book logan 1942 p 147 usic utah teacher and merchant including his missions for mormons to north carolina and georgia 1851 evstifeef alexander the traitor np 1938 112 p was an account of his efforts to combat communism in the twenties by a man who fled russia 1852 ewell samuel holbrook 18191908 original poems romeo mich 1901 146 p auto p iiv miuc michigan farmer and businessman 1853 eyland seth pseud b 1839 the evolution of a life ny sw green 1884 336 p whi includes his experiences as a soldier in the union army the remainder deals with journalism in new england and business in texas the library of congress assigns the authorship to david e cronin halkett names silas e reynolds as the author 1854 eytinge rose 18381911 the memories of rose eytinge being recollections and observations of men women and events during half a century ny frederick a stokes co 1905 311 p nn theatrical reminiscences and memories of her years in egypt as the wife of the american consulgeneral 1855 ezzell samuel r 18341910 autobiographic sketch in his great legacy cinc central book concern 1883 p 292311 csmh clergyman of the disciples of christ church in missouri texas and arkansas 1856 f mt my chinese marriage ny duffield 1922 169 p mtbu the life in china of an american girl who tells of her family life farming etc 1857 fackler samuel a ups and downs of a country editor mostly downs np collins job print nd 103 p dlc in georgia alabama and florida 1858 fagan james octavius b 1859 the autobiography of an individualist boston ny houghton mifflin 1912 290 p nn author of confessions of a railroad signalman youthful adventures in brazil and south africa telegraph operator and tower signalman on new england railroads intellectual development and opinions on railroad and labor problems 1859 fagots from the camp fire see depre louis j fairback henry b 1839 a wandererst louis commercial prntg co 1912 63 p moku germanborn building contractor and banker in missouri tells also of his early days as a carpenter in illinois and a deck hand on the mississippi during the civil war he served with an illinois outfit 1860 fairbank calvin b 1816 rev calvin fairbank during slavery timeschicago r r mccabe 1890 207 p vihal by a methodist clergyman who lived in new england and in the south abolitionist 1861 fairchild david grandison b 1869 the world was my garden ny scribners 1938 494 p wu 1862\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# sys.path.append(\"..\")\n",
    "# from benchmarking.txt_accuracy import clean_text_normalized\n",
    "\n",
    "# gt_dir = root_dir / \"ground-truth\"\n",
    "# ocr_dir = root_dir / \"results\" / \"ocr_img2txt\"\n",
    "# llm_dir = root_dir / \"results\" / \"llm_img2txt\" / \"gpt-4o\"\n",
    "# ocr_llm_dir = root_dir / \"results\" / \"ocr_llm_img2txt\" / \"gpt-4o\"\n",
    "\n",
    "# ocr_llm_filepaths = []\n",
    "# for path in ocr_llm_dir.iterdir():\n",
    "#   if path.is_file():\n",
    "#     if \"3\" in path.stem:\n",
    "#         continue\n",
    "#     ocr_llm_filepaths.append(path)\n",
    "\n",
    "# ocr_filepaths = []\n",
    "# for path in ocr_dir.iterdir():\n",
    "#   if path.is_file():\n",
    "#     if \"3\" in path.stem:\n",
    "#         continue\n",
    "#     ocr_filepaths.append(path)\n",
    "\n",
    "# llm_filepaths = []\n",
    "# for path in llm_dir.iterdir():\n",
    "#   if path.is_file():\n",
    "#     if \"3\" in path.stem:\n",
    "#         continue\n",
    "#     llm_filepaths.append(path)\n",
    "\n",
    "# gt_filepaths = []\n",
    "# for path in gt_dir.iterdir():\n",
    "#   if path.is_file():\n",
    "#     gt_filepaths.append(path)\n",
    "\n",
    "# # if len(ocr_filepaths) != len(gt_filepaths):\n",
    "# #     raise ValueError(\"Number of OCR files and GT files do not match\")\n",
    "\n",
    "# for ocr_llm_path, llm_path, gt_path in zip(ocr_llm_filepaths, llm_filepaths, gt_filepaths):\n",
    "#     with open(ocr_llm_path, 'r') as file:\n",
    "#         ocr_llm_text = clean_text_normalized(file.read())\n",
    "#     with open(llm_path, 'r') as file:\n",
    "#         llm_text = clean_text_normalized(file.read())\n",
    "#     with open(gt_path, 'r') as file:\n",
    "#         gt_text = clean_text_normalized(file.read())\n",
    "# print(llm_text)\n",
    "# print(gt_text)\n",
    "\n",
    "# for i in range(len(ocr_llm_text)):\n",
    "#     if ocr_llm_text[i] != gt_text[i]:\n",
    "#         print(f\"Mismatch at index {i}\")\n",
    "#         print(f\"OCR: {ocr_llm_text[i]}\")\n",
    "#         print(f\"GT: {gt_text[i]}\")\n",
    "#         break\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
