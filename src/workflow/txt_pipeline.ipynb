{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4432e892",
   "metadata": {},
   "source": [
    "# OCR-mLLM Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd231b04",
   "metadata": {},
   "source": [
    "Before running this code you will need to set up your OpenAI & Gemini API keys. Here's how I did it:\n",
    "\n",
    "1. Create a new file in your root directory called `.env` (no prefix)\n",
    "2. Store your API keys with the following names: OPENAI_API_KEY, ANTHROPIC_API_KEY, and GOOGLE_API_KEY\n",
    "3. Create a virtual environment by typing the following commands into your terminal:\n",
    "    - ```python3 -m venv .venv```\n",
    "    - ```source .venv/bin/activate```\n",
    "    - ```pip install -r requirements.txt```\n",
    "4. After running the pipeline, type ```deactivate``` in your terminal to make everything go back to normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadd7cf4",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002663b1",
   "metadata": {},
   "source": [
    "### a. Run this cell to ensure you have all the necessary directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd3540d",
   "metadata": {},
   "source": [
    "Before running the cell make sure you have an images folder in your root directory to feed the images into the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "549ec682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from json_creation import *\n",
    "from google.genai import types\n",
    "\n",
    "\n",
    "# Get the root directory of the project\n",
    "root_dir = Path.cwd().parent.parent\n",
    "\n",
    "doc_format = \"txt\"\n",
    "\n",
    "# Get the user's path for the images folder assuming all images are stored here in .png format\n",
    "source_dir = root_dir / \"data\" / \"pngs\"\n",
    "\n",
    "# Get the user's path for the output folder, create one if it doesn't exist\n",
    "output_dir = root_dir / \"results\" / doc_format\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "bm_output_dir = root_dir / \"benchmarking-results\"/ f\"{doc_format}-accuracy\"\n",
    "bm_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# llm_array = [\"gpt-4o\", \"gemini-2.5-flash\", \"claude-4-sonnet\"]\n",
    "llm_array = [\"gpt-4o\", \"gemini-2.5-flash\"]\n",
    "\n",
    "def make_llm_dirs(llm_array, target_dir, doc_format):\n",
    "    for llm in llm_array:\n",
    "        if doc_format == \"txt\":\n",
    "            dir = target_dir / f\"ocr-img2txt\" / \"pytesseract\"\n",
    "            dir.mkdir(parents=True, exist_ok=True)\n",
    "            dir = target_dir / f\"llm-img2{doc_format}\" / llm\n",
    "            dir.mkdir(parents=True, exist_ok=True)\n",
    "            dir = target_dir / f\"ocr-llm-img2{doc_format}\" / llm\n",
    "            dir.mkdir(parents=True, exist_ok=True)\n",
    "        else:\n",
    "            dir = target_dir / f\"llm-img2{doc_format}\" / llm\n",
    "            dir.mkdir(parents=True, exist_ok=True)\n",
    "            dir = target_dir / f\"llm-txt2{doc_format}\" / llm\n",
    "            dir.mkdir(parents=True, exist_ok=True)\n",
    "make_llm_dirs(llm_array, output_dir, doc_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859c660",
   "metadata": {},
   "source": [
    "### b. Setup API keys & image encoding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7ae833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from google import genai\n",
    "import base64\n",
    "#from dotenv import load_dotenv\n",
    "\n",
    "#load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "gpt_client = OpenAI(api_key=openai_api_key)\n",
    "gemini_client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "claude_client = Anthropic(api_key=anthropic_api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3a5773",
   "metadata": {},
   "source": [
    "### c. Get image file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fed71bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all filenames in images directory into the `filenames` array with the ENTIRE filepath\n",
    "img_filepaths = []\n",
    "count = 0\n",
    "for path in source_dir.iterdir():\n",
    "  if count < 10:\n",
    "    if path.suffix.lower() == \".png\" and path.is_file():\n",
    "      img_filepaths.append(path)\n",
    "      count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5702eec5-e52d-4b51-8907-f593204a1b76",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 2. Run pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c314b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows users should run this cell, inserting their path to Tesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95e34ea1-f6ae-4de7-9887-764da7178f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files from ocr-benchmarking/images folder & write to results folder\n",
    "for path in img_filepaths:\n",
    "    file_name = output_dir / \"ocr-img2txt\" / path.stem\n",
    "    file_name = str(file_name) + \".txt\"\n",
    "    \n",
    "    with open(file_name, 'w') as file:\n",
    "        file.write(pytesseract.image_to_string(Image.open(str(path)))) # TODO: Change config as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df39757",
   "metadata": {},
   "source": [
    "## 3. Prepare the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "045337cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_ocr_llm = \"\"\"\n",
    "You are a text correction assistant. Your task is to clean up and correct errors from raw OCR output.\n",
    "The text may contain misrecognized characters, broken words, or incorrect formatting.\n",
    "Carefully read the provided OCR output, compare it to the original image, and produce a corrected version that is  \n",
    "as faithful to the original content as possible. Only correct obvious OCR errors, and do not attempt to complete\n",
    "cut-off entries or predict missing information. Put each entry on a separate line.\n",
    "When an entry has an index number in square brackets, place it at the end of the entry.\n",
    "Input (Raw OCR Text):\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "prompt_llm = \"\"\"\n",
    "Your task is to transcribe this image of a historical bibliography page as faithfully as possible.\n",
    "Only transcribe typed text that appears on the page and do not attempt to predict missing information or complete cut off entries. \n",
    "Put each entry on a separate line. When an entry has an index number in square brackets, place it at the end of the entry. \n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d58cb0c-aeb8-47cc-9528-26bc3a802984",
   "metadata": {},
   "source": [
    "## 4. OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d64bb8",
   "metadata": {},
   "source": [
    "### (i) Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06535758",
   "metadata": {},
   "source": [
    "#### a. OCR-LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "163080e4-5134-407c-9cdd-7a89141e1632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 14:23:07 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 14:23:50 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 14:24:28 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 14:25:16 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 14:25:57 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 14:26:32 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 14:27:24 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 14:28:13 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 14:28:55 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 14:29:44 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "for path in img_filepaths:\n",
    "    input = \"\"\n",
    "    base64_image = encode_image(path)\n",
    "    ocr_text_path = str(output_dir / \"ocr-img2txt\" / path.stem) + \".txt\" # THIS REMAINS THE SAME b/c we're reading the OCR output\n",
    "    with open(ocr_text_path, 'r') as file:\n",
    "        input += file.read()\n",
    "    prompt_ocr_llm = prompt_template_ocr_llm.format(input=input).strip()\n",
    "\n",
    "    response = gpt_client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        temperature= 0,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt_ocr_llm\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            ]\n",
    "    )\n",
    "\n",
    "    with open(output_dir / f\"ocr-llm-img2{doc_format}\" / \"gpt-4o\" / Path(path.stem + f\".{doc_format}\"), 'w') as file:\n",
    "        file.write(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cafe77",
   "metadata": {},
   "source": [
    "#### b. LLM call (without OCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18c2eedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 14:36:06 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 14:36:42 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 14:37:30 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 14:38:15 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 14:38:55 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 14:39:44 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 14:40:29 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 14:41:10 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 14:41:56 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 14:42:42 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "for path in img_filepaths:\n",
    "    base64_image = encode_image(path)\n",
    "\n",
    "    response = gpt_client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        temperature= 0,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt_llm\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            ]\n",
    "    )\n",
    "\n",
    "    with open(output_dir / f\"llm-img2{doc_format}\" / \"gpt-4o\" / Path(path.stem + f\".{doc_format}\"), 'w') as file:\n",
    "        file.write(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5692d2",
   "metadata": {},
   "source": [
    "### (ii) JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6ae2c9",
   "metadata": {},
   "source": [
    "#### a. Image to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72f2dcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image path c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p003.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 10:55:41 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output path: c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-img2json\\gpt-4o\\kbaa-p003.json\n",
      "Image path c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p004.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 10:56:40 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output path: c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-img2json\\gpt-4o\\kbaa-p004.json\n",
      "Image path c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p005.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 10:57:48 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output path: c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-img2json\\gpt-4o\\kbaa-p005.json\n",
      "Image path c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p006.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 10:59:12 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output path: c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-img2json\\gpt-4o\\kbaa-p006.json\n",
      "Image path c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p007.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 11:00:31 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output path: c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-img2json\\gpt-4o\\kbaa-p007.json\n",
      "Image path c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p008.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 11:02:08 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output path: c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-img2json\\gpt-4o\\kbaa-p008.json\n",
      "Image path c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p009.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 11:04:08 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output path: c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-img2json\\gpt-4o\\kbaa-p009.json\n",
      "Image path c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p010.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 11:05:16 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output path: c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-img2json\\gpt-4o\\kbaa-p010.json\n",
      "Image path c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p011.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 11:06:25 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output path: c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-img2json\\gpt-4o\\kbaa-p011.json\n",
      "Image path c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p012.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 11:07:50 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output path: c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-img2json\\gpt-4o\\kbaa-p012.json\n"
     ]
    }
   ],
   "source": [
    "if doc_format == \"json\":\n",
    "    count = 0\n",
    "    for path in img_filepaths:\n",
    "        print(\"Image path\", path)\n",
    "        #if count == 1:\n",
    "            #break\n",
    "        count += 1\n",
    "        response = openai_img2json(path)\n",
    "        with open(output_dir / f\"llm-img2{doc_format}\" / \"gpt-4o\" / Path(path.stem + f\".{doc_format}\"), 'w') as file:\n",
    "            print(\"Output path:\", output_dir / f\"llm-img2{doc_format}\" / \"gpt-4o\" / Path(path.stem + f\".{doc_format}\"))\n",
    "            file.write(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1ccf05",
   "metadata": {},
   "source": [
    "#### b. Text to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44edaf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 11:12:11 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-txt2json\\gpt-4o\\kbaa-p003.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 11:12:53 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-txt2json\\gpt-4o\\kbaa-p004.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 11:13:23 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-txt2json\\gpt-4o\\kbaa-p005.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 11:13:39 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-txt2json\\gpt-4o\\kbaa-p006.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 11:14:13 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-txt2json\\gpt-4o\\kbaa-p007.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 11:14:41 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-txt2json\\gpt-4o\\kbaa-p008.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 11:15:11 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-txt2json\\gpt-4o\\kbaa-p009.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 11:15:43 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-txt2json\\gpt-4o\\kbaa-p010.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 11:15:51 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-txt2json\\gpt-4o\\kbaa-p011.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 11:16:28 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-txt2json\\gpt-4o\\kbaa-p012.json\n"
     ]
    }
   ],
   "source": [
    "if doc_format == \"json\":\n",
    "    count = 0\n",
    "    for path in img_filepaths:\n",
    "        \n",
    "        ocr_text_path = str(root_dir / \"results\" / \"txt\" / \"ocr-llm-img2txt\" / \"gpt-4o\" /path.stem) + \".txt\" # THIS REMAINS THE SAME b/c we're reading the OCR output\n",
    "        #if count == 1:\n",
    "            #break\n",
    "        count += 1\n",
    "        #response = openai_txt2json(ocr_text_path.replace(\"json\", \"txt\"))\n",
    "        response = openai_txt2json(ocr_text_path)\n",
    "        with open(output_dir / f\"llm-txt2{doc_format}\" / \"gpt-4o\" / Path(path.stem + f\".{doc_format}\"), 'w') as file:\n",
    "            print(\"Writing to\", output_dir / f\"llm-txt2{doc_format}\" / \"gpt-4o\" / Path(path.stem + f\".{doc_format}\"))\n",
    "            file.write(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25ecae5",
   "metadata": {},
   "source": [
    "## 5. Gemini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047fb167",
   "metadata": {},
   "source": [
    "### (i) Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f10c212",
   "metadata": {},
   "source": [
    "#### a. OCR-LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9e5d357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 15:02:17 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:02:18 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8_VoC2Um0I9t19fNNApfbOVpDMJLhi8ha-yUlkSA9H4-CrZrV_VvU_O2lPmw8ZxP-HAxoi5RakhRUFxQ2YCaNm99SjTc8qMtQM4Bfpa6w&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:02:21 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8_VoC2Um0I9t19fNNApfbOVpDMJLhi8ha-yUlkSA9H4-CrZrV_VvU_O2lPmw8ZxP-HAxoi5RakhRUFxQ2YCaNm99SjTc8qMtQM4Bfpa6w&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:02:21 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 15:02:36 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:02:36 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 15:02:36 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:02:37 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH89w45owhh1xOHcNbzIBLlwiXeG25LgNlphY5f5cP8hEduQrOed2UEoKo3qM1Q6UETtrnsCSbGHCnwqZDRTtyfQcj-9USk-XkH46T2DTdo8&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:02:40 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH89w45owhh1xOHcNbzIBLlwiXeG25LgNlphY5f5cP8hEduQrOed2UEoKo3qM1Q6UETtrnsCSbGHCnwqZDRTtyfQcj-9USk-XkH46T2DTdo8&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:02:40 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 15:02:57 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:02:57 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 15:02:57 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:02:58 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH89pZ7k7usbadG3UXft9lBaDymAbzbLnJlBQsNI8Q1Yl192UhIIARGNYMMxkaIfnpiGj4Ny7EyuoSYNUiFqpwVv4f8BAyiB3kveyrD60Ig&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:03:01 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH89pZ7k7usbadG3UXft9lBaDymAbzbLnJlBQsNI8Q1Yl192UhIIARGNYMMxkaIfnpiGj4Ny7EyuoSYNUiFqpwVv4f8BAyiB3kveyrD60Ig&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:03:01 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 15:03:32 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:03:32 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 15:03:33 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:03:33 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH895aHq5thYj-142uArfWaEtjLt0Ti2bA1VeSeAJ6qwQAym4jVLmhjDqOa-btKt1pdMKvBHWWzUCi1Xu0-3u5AyHHDE7v_n2ZygJotTJQQ&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:03:36 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH895aHq5thYj-142uArfWaEtjLt0Ti2bA1VeSeAJ6qwQAym4jVLmhjDqOa-btKt1pdMKvBHWWzUCi1Xu0-3u5AyHHDE7v_n2ZygJotTJQQ&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:03:36 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 15:03:59 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:03:59 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 15:03:59 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:04:00 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH89w1Zi7OHIa4apQeoUGGDRLtmNXwRr0x3uDvV-vZ38egnK0NjkG7grQukcdHgXZV0iUXrshMYoR8pQVVPt4iC2y3pkqf9fCJOkxreXlqw&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:04:02 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH89w1Zi7OHIa4apQeoUGGDRLtmNXwRr0x3uDvV-vZ38egnK0NjkG7grQukcdHgXZV0iUXrshMYoR8pQVVPt4iC2y3pkqf9fCJOkxreXlqw&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:04:02 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 15:04:23 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:04:23 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 15:04:23 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:04:24 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH88DPBa5wJYXSoH5gsq0sbNWUDbA_uCqoxlN7ZgJyAPnWdjo_VvKljBKnD-CknLYDlZdESUPYg64H9AiNpI2tAcps9nBxLBtmbEYF5B_HQ&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:04:26 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH88DPBa5wJYXSoH5gsq0sbNWUDbA_uCqoxlN7ZgJyAPnWdjo_VvKljBKnD-CknLYDlZdESUPYg64H9AiNpI2tAcps9nBxLBtmbEYF5B_HQ&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:04:26 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 15:04:49 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:04:49 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 15:04:49 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:04:49 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8-lxiucF0lfnmjBcgcREIWfVnjM8bEquhPIhijBxzWTnvtXpqo8AvX8p2U9UVQM9CwAvQ_JpaVrYOX2G-KwY3xPlZO4XxreQ6AoOMG3xJA&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:04:52 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8-lxiucF0lfnmjBcgcREIWfVnjM8bEquhPIhijBxzWTnvtXpqo8AvX8p2U9UVQM9CwAvQ_JpaVrYOX2G-KwY3xPlZO4XxreQ6AoOMG3xJA&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:04:52 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 15:05:17 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:05:17 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 15:05:17 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:05:18 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8_RbLdLjB_dPNmmhumDt_xnwg50QIc05qyN__4RJXzJ4jjqE98kMN5kfpW-XcHefW0iagj9El5uDpMgDke9xUaudRskK3FVkkdmICRKow&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:05:21 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8_RbLdLjB_dPNmmhumDt_xnwg50QIc05qyN__4RJXzJ4jjqE98kMN5kfpW-XcHefW0iagj9El5uDpMgDke9xUaudRskK3FVkkdmICRKow&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:05:21 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 15:05:49 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:05:49 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 15:05:49 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:05:49 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH89X-BNzAm9GIN_4rFG6L8Bb5fJPoqIvlBYvaJYh6hNLHD_0kitW4qGyN0S7XTQx3rNfKeNXfnnncc1m_MEv1NaQoRittCZJ5ZiNXniz&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:05:52 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH89X-BNzAm9GIN_4rFG6L8Bb5fJPoqIvlBYvaJYh6hNLHD_0kitW4qGyN0S7XTQx3rNfKeNXfnnncc1m_MEv1NaQoRittCZJ5ZiNXniz&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:05:52 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 15:06:32 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:06:32 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 15:06:32 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:06:32 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8-IhT2TDteHixOSMBVyoD37FNIXoA8afKQR_5b4xxiQoZ5BRjwQc2hbrHT4of1pPa0vDVtZKgdfQ92gGkXUtddGoRUgxDawfKwSd5WTGw&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:06:35 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8-IhT2TDteHixOSMBVyoD37FNIXoA8afKQR_5b4xxiQoZ5BRjwQc2hbrHT4of1pPa0vDVtZKgdfQ92gGkXUtddGoRUgxDawfKwSd5WTGw&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:06:35 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 15:06:54 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:06:54 [INFO] AFC remote call 1 is done.\n"
     ]
    }
   ],
   "source": [
    "for path in img_filepaths:\n",
    "    my_file = gemini_client.files.upload(file=path)\n",
    "    input = \"\"\n",
    "    ocr_text_path = str(output_dir / \"ocr-img2txt\" / path.stem) + \".txt\" # THIS REMAINS THE SAME b/c we're reading the OCR output\n",
    "    if doc_format == \"txt\":\n",
    "        with open(ocr_text_path, 'r') as file:\n",
    "            input += file.read()\n",
    "        prompt_ocr_llm = prompt_template_ocr_llm.format(input=input).strip()\n",
    "\n",
    "        response = gemini_client.models.generate_content(\n",
    "            model='gemini-2.5-flash',\n",
    "            config= types.GenerateContentConfig(\n",
    "            temperature = 0\n",
    "            ),\n",
    "            contents=[\n",
    "                prompt_ocr_llm,\n",
    "                my_file\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        with open(output_dir / f\"ocr-llm-img2{doc_format}\" / \"gemini-2.5-flash\" / Path(path.stem + f\".{doc_format}\"), 'w') as file:\n",
    "            file.write(response.text)\n",
    "    #elif doc_format == \"json\":   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d3100",
   "metadata": {},
   "source": [
    "#### b. LLM call (without OCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5d3d2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 15:09:11 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:09:13 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH88UFd5YznxNEbxsKTmzlpaAf4TIy4biEg_KmDWGFP0dIfdEtZnpHmApBUAU4wboCjGRsEVi6SQmSBuQaHAAjUy_v-Dhk8kzNUKJG9Xq0Js&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:09:16 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH88UFd5YznxNEbxsKTmzlpaAf4TIy4biEg_KmDWGFP0dIfdEtZnpHmApBUAU4wboCjGRsEVi6SQmSBuQaHAAjUy_v-Dhk8kzNUKJG9Xq0Js&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:09:16 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 15:09:27 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:09:27 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 15:09:27 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:09:28 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH89EcxUWSGKAaRMH47OCd3dosibsnOsH0q4N5vQci5m2CHjnAfj7UTu9Rk909fhaKhw3H6y5vHVBAk6AlFVqDR8cTJLTIpHPjGXVl2dOGeY&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:09:31 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH89EcxUWSGKAaRMH47OCd3dosibsnOsH0q4N5vQci5m2CHjnAfj7UTu9Rk909fhaKhw3H6y5vHVBAk6AlFVqDR8cTJLTIpHPjGXVl2dOGeY&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:09:31 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 15:09:50 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:09:50 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 15:09:50 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:09:51 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH89PQVSd9fKp4t87QyXMGVAdql5nLmpNqT4xZaJyEEBglARQ9CU111KwMtwOT6C2P5kvUOWVq5jdCEeyPCK-XKQRo8GSIge7PCB_wyQdAHI&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:09:54 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH89PQVSd9fKp4t87QyXMGVAdql5nLmpNqT4xZaJyEEBglARQ9CU111KwMtwOT6C2P5kvUOWVq5jdCEeyPCK-XKQRo8GSIge7PCB_wyQdAHI&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:09:54 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 15:10:17 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:10:17 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 15:10:17 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:10:17 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8-ih1qe8JO2HTYL8ItE94dLIh-5WsGZPdFhfIv4L8qFbMRnqlty6OO7xpU_x-9fD5TChdlwBpMxpec8krhZPiaVcV6FtBczdWrk_37NPQ&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:10:20 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8-ih1qe8JO2HTYL8ItE94dLIh-5WsGZPdFhfIv4L8qFbMRnqlty6OO7xpU_x-9fD5TChdlwBpMxpec8krhZPiaVcV6FtBczdWrk_37NPQ&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:10:20 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 15:10:40 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:10:40 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 15:10:40 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:10:42 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8_RsV1aZyZTd44U7wFvdP2HcfAS9fvm1r4Biy25kx9NMu5HKoa_lZMm9A7R0CcPSYd2BM-Joy9ymBp1hDthCxzvRVUcRzVoTTWyxKmKjw&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:10:45 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8_RsV1aZyZTd44U7wFvdP2HcfAS9fvm1r4Biy25kx9NMu5HKoa_lZMm9A7R0CcPSYd2BM-Joy9ymBp1hDthCxzvRVUcRzVoTTWyxKmKjw&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:10:45 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 15:10:57 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:10:57 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 15:10:58 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:10:58 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8-8MUmUlNFgmEK3mKoU4PBg7drDCQ2zXvfyIorVuSmf-zei5q1dRWyZOUznvs3MrzxrnZlWHkU8AdiEPvirJz96B41h-XURqZOyxLqcHg&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:11:00 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8-8MUmUlNFgmEK3mKoU4PBg7drDCQ2zXvfyIorVuSmf-zei5q1dRWyZOUznvs3MrzxrnZlWHkU8AdiEPvirJz96B41h-XURqZOyxLqcHg&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:11:00 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 15:11:12 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:11:12 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 15:11:12 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:11:13 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8_Cog8lLuqO48jAJgatT9Vixs6MrSqgRUBcLnZ8Sl54rdVLydIi-dH4ZOhrefngTwsVw7M7_khGaYZyoyNG1YF92_EvpUawarzpc0f-uQ&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:11:16 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8_Cog8lLuqO48jAJgatT9Vixs6MrSqgRUBcLnZ8Sl54rdVLydIi-dH4ZOhrefngTwsVw7M7_khGaYZyoyNG1YF92_EvpUawarzpc0f-uQ&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:11:16 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 15:11:27 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:11:27 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 15:11:27 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:11:27 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8_J0xA3qk44KjGp0E3Xxevh5yYYPQpBt2VhSFUhQXIUB635sc3lcr5It6QFFxYlzPvyJil3pK_o-9k7c1fvdDNkn_E0ZLN8qVso8bA5VA&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:11:30 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8_J0xA3qk44KjGp0E3Xxevh5yYYPQpBt2VhSFUhQXIUB635sc3lcr5It6QFFxYlzPvyJil3pK_o-9k7c1fvdDNkn_E0ZLN8qVso8bA5VA&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:11:30 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 15:11:44 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:11:44 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 15:11:44 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:11:44 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH88QgyVs1cMgh6qco7OcvxefwS-dZb9CxAGbkjbNShfYWqyP3IvXeBnJBub7H1mrWPw8qZo-4vCgPAWztkMJAwjSw3ux1w3gOHSccp-DSzw&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:11:46 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH88QgyVs1cMgh6qco7OcvxefwS-dZb9CxAGbkjbNShfYWqyP3IvXeBnJBub7H1mrWPw8qZo-4vCgPAWztkMJAwjSw3ux1w3gOHSccp-DSzw&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:11:46 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 15:12:20 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:12:20 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 15:12:20 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:12:20 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH88zHKTZJ_3RedP95vemPtBLCmbL5nMDIdr6gyksBCU6MXY0RHFjX_EWHLHSDCV6qsxnJY9YHsMZulRkW2ZjFan0Z3h-9CeJ9PBrln6xaHc&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:12:23 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH88zHKTZJ_3RedP95vemPtBLCmbL5nMDIdr6gyksBCU6MXY0RHFjX_EWHLHSDCV6qsxnJY9YHsMZulRkW2ZjFan0Z3h-9CeJ9PBrln6xaHc&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:12:23 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 15:12:37 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 15:12:37 [INFO] AFC remote call 1 is done.\n"
     ]
    }
   ],
   "source": [
    "for path in img_filepaths:\n",
    "    my_file = gemini_client.files.upload(file=path)\n",
    "\n",
    "    response = gemini_client.models.generate_content(\n",
    "        model='gemini-2.5-flash',\n",
    "        config= types.GenerateContentConfig(\n",
    "        temperature = 0\n",
    "        ),\n",
    "        contents=[\n",
    "            prompt_llm,\n",
    "            my_file\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    with open(output_dir / f\"llm-img2{doc_format}\" / \"gemini-2.5-flash\" / Path(path.stem + f\".{doc_format}\"), 'w') as file:\n",
    "        file.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1cec32",
   "metadata": {},
   "source": [
    "### (ii) JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af53393d",
   "metadata": {},
   "source": [
    "#### a. Image to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17fe4fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 11:17:25 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 11:18:19 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 11:18:19 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 11:18:20 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 11:19:09 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 11:19:09 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 11:19:09 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 11:19:55 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 11:19:55 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 11:19:55 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 11:20:30 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 11:20:30 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 11:20:31 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 11:21:09 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 11:21:09 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 11:21:10 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 11:22:09 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 11:22:09 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 11:22:10 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 11:23:03 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 11:23:03 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 11:23:03 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 11:23:54 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 11:23:54 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 11:23:55 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 11:24:36 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 11:24:36 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 11:24:36 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 11:25:23 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 11:25:23 [INFO] AFC remote call 1 is done.\n"
     ]
    }
   ],
   "source": [
    "if doc_format == \"json\":\n",
    "    count = 0\n",
    "    for path in img_filepaths:\n",
    "        #if count == 1:\n",
    "            #break\n",
    "        count += 1\n",
    "        response = gemini_img2json(path)\n",
    "        with open(output_dir / f\"llm-img2{doc_format}\" / \"gemini-2.5-flash\" / Path(path.stem + f\".{doc_format}\"), 'w') as file:\n",
    "            file.write(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b78765",
   "metadata": {},
   "source": [
    "#### b. Text to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5055dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 11:28:39 [INFO] AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 11:29:14 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 11:29:14 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 11:29:14 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 11:29:57 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 11:29:57 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 11:29:57 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 11:30:47 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 11:30:48 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 11:30:48 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 11:31:20 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 11:31:20 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 11:31:20 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 11:31:58 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 11:31:58 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 11:31:58 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 11:32:29 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 11:32:29 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 11:32:30 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 11:34:34 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 11:34:34 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 11:34:34 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 11:35:02 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 11:35:02 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 11:35:02 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 11:35:39 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 11:35:39 [INFO] AFC remote call 1 is done.\n",
      "[file retrieval] 2025-07-08 11:35:39 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-08 11:36:10 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-08 11:36:10 [INFO] AFC remote call 1 is done.\n"
     ]
    }
   ],
   "source": [
    "if doc_format == \"json\":\n",
    "    count = 0\n",
    "    for path in img_filepaths:\n",
    "        ocr_text_path = str(root_dir/ \"results\" / \"txt\" / \"ocr-llm-img2txt\" / \"gemini-2.5-flash\" / path.stem) + \".txt\" # THIS REMAINS THE SAME b/c we're reading the OCR output\n",
    "        #if count == 1:\n",
    "            #break\n",
    "        count += 1\n",
    "        response = gemini_txt2json(ocr_text_path)\n",
    "        with open(output_dir / f\"llm-txt2{doc_format}\" / \"gemini-2.5-flash\" / Path(path.stem + f\".{doc_format}\"), 'w') as file:\n",
    "            file.write(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d06c34",
   "metadata": {},
   "source": [
    "## 6. Send to Claude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0869c81",
   "metadata": {},
   "source": [
    "### a. OCR-LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651e17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in img_filepaths:\n",
    "#     base64_image = encode_image(path)\n",
    "\n",
    "#     response = claude_client.messages.create(\n",
    "#         model='claude-opus-4-20250514',\n",
    "#         temperature=0,\n",
    "#         max_tokens=10,\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"user\", \n",
    "#                 \"content\": [\n",
    "#                     {\n",
    "#                         \"type\": \"text\",\n",
    "#                         \"text\": prompt_ocr_llm\n",
    "#                     },\n",
    "#                     {\n",
    "#                         \"type\": \"image\",\n",
    "#                         \"source\": {\n",
    "#                             \"type\": \"base64\",\n",
    "#                             \"media_type\": \"image/png\",\n",
    "#                             \"data\": base64_image\n",
    "#                         }\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#             ]\n",
    "#     )\n",
    "#     print(response)\n",
    "\n",
    "#     with open(txt_output_dir / \"ocr-llm-img2txt\" / \"claude-4-sonnet\" / Path(path.stem + \".txt\"), 'w') as file:\n",
    "#         file.write(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b610ccd9",
   "metadata": {},
   "source": [
    "### b. LLM call (without OCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497c3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in img_filepaths:\n",
    "#     base64_image = encode_image(path)\n",
    "\n",
    "#     response = claude_client.messages.create(\n",
    "#         model='claude-opus-4-20250514',\n",
    "#         temperature=0,\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"user\", \n",
    "#                 \"content\": [\n",
    "#                     {\n",
    "#                         \"type\": \"text\",\n",
    "#                         \"text\": prompt_llm\n",
    "#                     },\n",
    "#                     {\n",
    "#                         \"type\": \"image\",\n",
    "#                         \"source\": {\n",
    "#                             \"type\": \"base64\",\n",
    "#                             \"media_type\": \"image/png\",\n",
    "#                             \"data\": base64_image\n",
    "#                         }\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#             ]\n",
    "#     )\n",
    "\n",
    "#     with open(txt_output_dir / \"llm-img2txt\" / \"claude-4-sonnet\" / Path(path.stem + \".txt\"), 'w') as file:\n",
    "#         file.write(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e20262",
   "metadata": {},
   "source": [
    "## 7. Benchmark results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77c21953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 15:19:24 [INFO] Script directory: c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\src\\workflow\n",
      "[file retrieval] 2025-07-08 15:19:25 [INFO] Project root: c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\n",
      "[file retrieval] 2025-07-08 15:19:59 [INFO] Found ground-truth txt files: ['c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p003.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p004.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p005.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p006.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p007.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p008.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p009.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p010.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p011.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p012.txt']\n",
      "[file retrieval] 2025-07-08 15:19:59 [INFO] Found file names: ['gt_kbaa-p003', 'gt_kbaa-p004', 'gt_kbaa-p005', 'gt_kbaa-p006', 'gt_kbaa-p007', 'gt_kbaa-p008', 'gt_kbaa-p009', 'gt_kbaa-p010', 'gt_kbaa-p011', 'gt_kbaa-p012']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\llm-img2txt\n",
      "c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\n",
      "c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-llm-img2txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-08 15:21:46 [INFO] Models found: [('llm-img2txt', 'gemini-2.5-flash'), ('ocr-llm-img2txt', 'gemini-2.5-flash'), ('llm-img2txt', 'gpt-4o'), ('ocr-llm-img2txt', 'gpt-4o'), ('ocr-img2txt', 'kbaa-p003.txt'), ('ocr-img2txt', 'kbaa-p004.txt'), ('ocr-img2txt', 'kbaa-p005.txt'), ('ocr-img2txt', 'kbaa-p006.txt'), ('ocr-img2txt', 'kbaa-p007.txt'), ('ocr-img2txt', 'kbaa-p008.txt'), ('ocr-img2txt', 'kbaa-p009.txt'), ('ocr-img2txt', 'kbaa-p010.txt'), ('ocr-img2txt', 'kbaa-p011.txt'), ('ocr-img2txt', 'kbaa-p012.txt')]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 177\u001b[39m\n\u001b[32m    173\u001b[39m         nonorm_df.to_csv(os.path.join(\u001b[38;5;28mstr\u001b[39m(results_dir), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnonorm_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 69\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     66\u001b[39m ground_truths[\u001b[33m\"\u001b[39m\u001b[33m__ALL__\u001b[39m\u001b[33m\"\u001b[39m] = all_texts\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m doc_format == \u001b[33m\"\u001b[39m\u001b[33mtxt\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     68\u001b[39m     doc_lengths_normalized = {\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m         doc: \u001b[38;5;28mlen\u001b[39m(\u001b[43mclean_text_normalized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m doc, text \u001b[38;5;129;01min\u001b[39;00m ground_truths.items()\n\u001b[32m     70\u001b[39m     }\n\u001b[32m     71\u001b[39m     doc_lengths_nonorm = {\n\u001b[32m     72\u001b[39m         doc: \u001b[38;5;28mlen\u001b[39m(clean_text_nonorm(text)) \u001b[38;5;28;01mfor\u001b[39;00m doc, text \u001b[38;5;129;01min\u001b[39;00m ground_truths.items()\n\u001b[32m     73\u001b[39m     }\n\u001b[32m     74\u001b[39m     total_doc_len_normalized = \u001b[38;5;28mlen\u001b[39m(clean_text_normalized(ground_truths[\u001b[33m\"\u001b[39m\u001b[33m__ALL__\u001b[39m\u001b[33m\"\u001b[39m]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\src\\benchmarking\\txt_accuracy.py:161\u001b[39m, in \u001b[36mclean_text_normalized\u001b[39m\u001b[34m(text, index_numbers)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# Collapse multiple spaces again\u001b[39;00m\n\u001b[32m    160\u001b[39m text = re.sub(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms+\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m, text)\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m text.strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<stringsource>:69\u001b[39m, in \u001b[36mcfunc.to_py.__Pyx_CFunc_4904d5__29_pydevd_sys_monitoring_cython_object__lParen__etc_to_py_4code_11instruction_6retval.wrap\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1117\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._return_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1252\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._stop_on_return\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1950\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._do_wait_suspend\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vriez\\anaconda3\\envs\\ocr-benchmarking\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2188\u001b[39m, in \u001b[36mPyDB.do_wait_suspend\u001b[39m\u001b[34m(self, thread, frame, event, arg, exception_type)\u001b[39m\n\u001b[32m   2185\u001b[39m             from_this_thread.append(frame_custom_thread_id)\n\u001b[32m   2187\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._threads_suspended_single_notification.notify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[32m-> \u001b[39m\u001b[32m2188\u001b[39m         keep_suspended = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2190\u001b[39m frames_list = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[32m   2193\u001b[39m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vriez\\anaconda3\\envs\\ocr-benchmarking\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2257\u001b[39m, in \u001b[36mPyDB._do_wait_suspend\u001b[39m\u001b[34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[39m\n\u001b[32m   2254\u001b[39m                 queue.put(internal_cmd)\n\u001b[32m   2255\u001b[39m                 wait_timeout = TIMEOUT_FAST\n\u001b[32m-> \u001b[39m\u001b[32m2257\u001b[39m         \u001b[43mnotify_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2258\u001b[39m         notify_event.clear()\n\u001b[32m   2260\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vriez\\anaconda3\\envs\\ocr-benchmarking\\Lib\\threading.py:659\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    657\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vriez\\anaconda3\\envs\\ocr-benchmarking\\Lib\\threading.py:363\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    365\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().\n",
    "parent))\n",
    "from benchmarking.txt_accuracy import clean_text_normalized, clean_text_nonorm, compute_metrics, build_dataframe\n",
    "from tools.file_retrieval import get_doc_names, get_docs, get_all_models\n",
    "from venv import logger\n",
    "from datetime import datetime\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Prerequisites:\n",
    "    - Ground truth text files located at `project_root/ground-truth/txt/kbaa-pxyz.txt`\n",
    "    - LLM/OCR transcribed files located at:\n",
    "        - for LLM transcriptions: `project_root/results/llm_img2txt/<MODEL-NAME>/kbaa-pxyz.txt`\n",
    "        - for OCR transcriptions: `project_root/results/ocr_img2txt/<MODEL-NAME>/kbaa-pxyz.txt`\n",
    "\n",
    "    The main function will:\n",
    "    - Gather all ground truth text files\n",
    "    - For each ground truth text file and for each LLM/OCR model, gather the corresponding transcription\n",
    "    - Clean all the text files (normalized and not normalized)\n",
    "    - Compute metrics for each file and model\n",
    "    - Save results in two CSV files (one for normalized, one for non-normalized)\n",
    "        - Results are saved in `project_root/benchmarking-results/txt-accuracy`\n",
    "    \"\"\"\n",
    "\n",
    "    # =============\n",
    "    # Preliminaries\n",
    "    # =============\n",
    "\n",
    "    # args = parse_arguments()\n",
    "\n",
    "    script_dir = str(Path.cwd())\n",
    "    project_root = str(root_dir)\n",
    "    logger.info(\"Script directory: %s\", script_dir)\n",
    "    logger.info(\"Project root: %s\", project_root)\n",
    "\n",
    "    # Ground truth\n",
    "    ground_truth_dir = root_dir / \"data\" / \"ground-truth\" / doc_format\n",
    "    doc_names = get_doc_names(ground_truth_dir, doc_format, keep_prefix=False)\n",
    "    #doc_names = ['kbaa-p038']\n",
    "\n",
    "    # results/ paths\n",
    "    if doc_format == \"txt\":\n",
    "        all_models = get_all_models(\n",
    "            doc_format,\n",
    "            os.path.join(output_dir, f\"llm-img2{doc_format}\"),\n",
    "            os.path.join(output_dir, \"ocr-img2txt\"),\n",
    "            os.path.join(output_dir, f\"ocr-llm-img2{doc_format}\"),\n",
    "        )\n",
    "    else:\n",
    "        all_models = get_all_models(\n",
    "            doc_format,\n",
    "            os.path.join(output_dir, f\"llm-img2{doc_format}\"),\n",
    "            os.path.join(output_dir, f\"llm-txt2{doc_format}\"),\n",
    "        )\n",
    "    logger.info(f\"Models found: {all_models}\")\n",
    "\n",
    "    # ===========\n",
    "    # Gather files\n",
    "    # ===========\n",
    "\n",
    "    # -> Gather ground truths and put into dict:\n",
    "    ground_truths, all_texts = get_docs(ground_truth_dir, doc_names, doc_format, name_has_prefix=True)\n",
    "    ground_truths[\"__ALL__\"] = all_texts\n",
    "    if doc_format == \"txt\":\n",
    "        doc_lengths_normalized = {\n",
    "            doc: len(clean_text_normalized(text)) for doc, text in ground_truths.items()\n",
    "        }\n",
    "        doc_lengths_nonorm = {\n",
    "            doc: len(clean_text_nonorm(text)) for doc, text in ground_truths.items()\n",
    "        }\n",
    "        total_doc_len_normalized = len(clean_text_normalized(ground_truths[\"__ALL__\"]))\n",
    "        total_doc_len_nonorm = len(clean_text_nonorm(ground_truths[\"__ALL__\"]))\n",
    "    elif doc_format == \"json\":\n",
    "        doc_lengths_normalized, doc_lengths_nonorm, total_doc_len_normalized, total_doc_len_nonorm = {}, {}, 0, 0\n",
    "        for doc, json_data in ground_truths.items():\n",
    "\n",
    "            # Loop over each entry in json object array\n",
    "            for entry in json_data[\"entries\"]:\n",
    "\n",
    "                # Loop over each field's value in the entry\n",
    "                for text in entry.values():\n",
    "                    doc_lengths_normalized[doc] = doc_lengths_normalized.get(doc, 0) + len(entry)\n",
    "                    doc_lengths_nonorm[doc] = doc_lengths_nonorm.get(doc, 0) + len(entry)\n",
    "            \n",
    "            # Add up the totals as we go along with doc_lengths_normalized etc.\n",
    "            total_doc_len_normalized += doc_lengths_normalized[doc]\n",
    "            total_doc_len_nonorm += doc_lengths_nonorm[doc]\n",
    "\n",
    "    # -> Gather each transcribed document and put into dict:\n",
    "\n",
    "    # Structure: results[model][doc]\n",
    "    results = {}\n",
    "\n",
    "    for model_type, model in all_models:\n",
    "        logger.info(\"Collecting results for model: %s\", model)\n",
    "        model_path = os.path.join(output_dir, model_type, model)\n",
    "        results[model_type] = results.get(model_type, {})\n",
    "        results[model_type][model], results[model_type][model][\"__ALL__\"] = get_docs(model_path, doc_names, doc_format, name_has_prefix=False)\n",
    "        logger.info(\"Collected results for model_type: %s, model: %s\", model_type, model)\n",
    "\n",
    "    # ===============\n",
    "    # Compute metrics\n",
    "    # ===============\n",
    "\n",
    "    normalized_results_data = {}\n",
    "    nonorm_results_data = {}\n",
    "\n",
    "    for model_type, model in all_models:\n",
    "        normalized_results_data[model_type] = normalized_results_data.get(model_type, {})\n",
    "        normalized_results_data[model_type][model] = normalized_results_data[model_type].get(model, {})\n",
    "        nonorm_results_data[model_type] = nonorm_results_data.get(model_type, {})\n",
    "        nonorm_results_data[model_type][model] = nonorm_results_data[model_type].get(model, {})\n",
    "\n",
    "        logger.info(\"Computing metrics for model_type: %s, model: %s\", model_type, model)\n",
    "        for doc in doc_names:\n",
    "            logger.info(\"Computing metrics for document: %s\", doc)\n",
    "            normalized_results_data[model_type][model][doc] = compute_metrics(\n",
    "                ground_truths[doc], results[model_type][model][doc], doc_format, normalized=True\n",
    "            )\n",
    "            nonorm_results_data[model_type][model][doc] = compute_metrics(\n",
    "                ground_truths[doc], results[model_type][model][doc], doc_format, normalized=False\n",
    "            )\n",
    "\n",
    "        normalized_results_data[model_type][model][\"__ALL__\"] = compute_metrics(\n",
    "            ground_truths[\"__ALL__\"], results[model_type][model][\"__ALL__\"], doc_format, normalized=True\n",
    "        )\n",
    "        nonorm_results_data[model_type][model][\"__ALL__\"] = compute_metrics(\n",
    "            ground_truths[\"__ALL__\"], results[model_type][model][\"__ALL__\"], doc_format, normalized=False\n",
    "        )\n",
    "\n",
    "    # Compute metrics separately for __ALL__]\n",
    "\n",
    "    # ====================\n",
    "    # Put metrics in table\n",
    "    # ====================\n",
    "\n",
    "    time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    results_base_dir = root_dir / \"benchmarking-results\" / f\"{doc_format}-accuracy\"\n",
    "\n",
    "    # Create different results directory for each model type\n",
    "    for model_type, _ in all_models:\n",
    "        results_dir = results_base_dir / model_type\n",
    "        results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        normalized_df = build_dataframe(\n",
    "            f\"normalized_{time}\",\n",
    "            doc_names,\n",
    "            normalized_results_data[model_type],\n",
    "            doc_lengths_normalized,\n",
    "            total_doc_len_normalized,\n",
    "        )\n",
    "        nonorm_df = build_dataframe(\n",
    "            f\"nonorm_{time}\",\n",
    "            doc_names,\n",
    "            nonorm_results_data[model_type],\n",
    "            doc_lengths_nonorm,\n",
    "            total_doc_len_nonorm,\n",
    "        )\n",
    "\n",
    "        # ============\n",
    "        # Save results\n",
    "        # ============\n",
    "\n",
    "        # # Default save to project_root/benchmarking-results/txt-accuracy\n",
    "        # results_path = os.path.join(project_root, \"benchmarking-results\", \"txt-accuracy\")\n",
    "        # if not os.path.exists(results_path):\n",
    "        #     os.makedirs(results_path)\n",
    "        normalized_df.to_csv(os.path.join(str(results_dir), f\"normalized_{time}.csv\"))\n",
    "        nonorm_df.to_csv(os.path.join(str(results_dir), f\"nonorm_{time}.csv\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
