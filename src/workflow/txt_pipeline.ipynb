{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4432e892",
   "metadata": {},
   "source": [
    "# OCR-mLLM Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd231b04",
   "metadata": {},
   "source": [
    "Before running this code you will need to set up your OpenAI & Gemini API keys. Here's how I did it:\n",
    "\n",
    "1. Create a new file in your root directory called `.env` (no prefix)\n",
    "2. Store your API keys with the following names: OPENAI_API_KEY, ANTHROPIC_API_KEY, and GOOGLE_API_KEY\n",
    "3. Create a virtual environment by typing the following commands into your terminal:\n",
    "    - ```python3 -m venv .venv```\n",
    "    - ```source .venv/bin/activate```\n",
    "    - ```pip install -r requirements.txt```\n",
    "4. After running the pipeline, type ```deactivate``` in your terminal to make everything go back to normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadd7cf4",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002663b1",
   "metadata": {},
   "source": [
    "### a. Run this cell to ensure you have all the necessary directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd3540d",
   "metadata": {},
   "source": [
    "Before running the cell make sure you have an images folder in your root directory to feed the images into the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "549ec682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import asyncio\n",
    "from venv import logger\n",
    "from json_creation import *\n",
    "from google.genai import types\n",
    "sys.path.append('../')\n",
    "\n",
    "# Get the root directory of the project\n",
    "root_dir = Path.cwd().parent.parent\n",
    "\n",
    "sys.path.append(Path(str(root_dir / \"tools\")))\n",
    "from tools.file_retrieval import *\n",
    "                \n",
    "# Get the user's path for the images folder assuming all images are stored here in .png format\n",
    "source_dir = root_dir / \"data\" / \"pngs\"\n",
    "txt_source_dir = root_dir / \"results\" / \"txt\" / \"ocr-llm-img2txt\"\n",
    "\n",
    "# Get the user's path for the output folder, create one if it doesn't exist\n",
    "txt_output_dir = root_dir / \"results\" / \"txt\"\n",
    "txt_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "json_output_dir = root_dir / \"results\" / \"json\"\n",
    "json_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "bm_txt_output_dir = root_dir / \"benchmarking-results\"/ f\"txt-accuracy\"\n",
    "bm_txt_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "bm_json_output_dir = root_dir / \"benchmarking-results\"/ f\"json-accuracy\"\n",
    "bm_json_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# llm_array = [\"gpt-4o\", \"gemini-2.5-flash\", \"claude-4-sonnet\"]\n",
    "llms = {\"openai\": \"gpt-4o\", \"google\": \"gemini-2.5-flash\"}\n",
    "# llms = {\"openai\": \"gpt-4o\", \"google\": \"gemini-2.5-flash\", \"alibaba\": \"qwen2.5-vl-72b-instruct\", \"meta\": \"llama-4-maverick\"}\n",
    "\n",
    "def make_llm_dirs(llms, target_dir, doc_format):\n",
    "    for llm in llms.values():\n",
    "        if doc_format == \"txt\":\n",
    "            dir = target_dir / f\"ocr-img2txt\" / \"pytesseract\"\n",
    "            dir.mkdir(parents=True, exist_ok=True)\n",
    "            dir = target_dir / f\"llm-img2txt\" / llm\n",
    "            dir.mkdir(parents=True, exist_ok=True)\n",
    "            dir = target_dir / f\"ocr-llm-img2txt\" / llm\n",
    "            dir.mkdir(parents=True, exist_ok=True)\n",
    "        else:\n",
    "            dir = target_dir / f\"llm-img2json\" / llm\n",
    "            dir.mkdir(parents=True, exist_ok=True)\n",
    "            dir = target_dir / f\"llm-txt2json\" / llm\n",
    "            dir.mkdir(parents=True, exist_ok=True)\n",
    "make_llm_dirs(llms, txt_output_dir, \"txt\")\n",
    "make_llm_dirs(llms, json_output_dir, \"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859c660",
   "metadata": {},
   "source": [
    "### b. Setup API keys & image encoding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fb7ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ae833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from google import genai\n",
    "import base64\n",
    "from json_creation import *\n",
    "from txt_creation import *\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "gpt_client = OpenAI(api_key=openai_api_key)\n",
    "gemini_client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "claude_client = Anthropic(api_key=anthropic_api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3a5773",
   "metadata": {},
   "source": [
    "### c. Get image file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed71bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all filenames in images directory into the `filenames` array with the ENTIRE filepath\n",
    "img_filepaths = []\n",
    "ocr_output_filepaths = []\n",
    "\n",
    "for path in source_dir.iterdir():\n",
    "    if path.suffix.lower() == \".png\" and path.is_file():\n",
    "      img_filepaths.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5702eec5-e52d-4b51-8907-f593204a1b76",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 2. Run pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c314b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows users should run this cell, inserting their path to Tesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e34ea1-f6ae-4de7-9887-764da7178f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files from ocr-benchmarking/images folder & write to results folder\n",
    "for path in img_filepaths:\n",
    "    file_name = txt_output_dir / \"ocr-img2txt\" / \"pytesseract\" / path.stem\n",
    "    file_name = str(file_name) + \".txt\"\n",
    "    \n",
    "    with open(file_name, 'w') as file:\n",
    "        file.write(pytesseract.image_to_string(Image.open(str(path)))) # TODO: Change config as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df39757",
   "metadata": {},
   "source": [
    "## 3. Prepare the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "045337cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_ocr_llm = \"\"\"\n",
    "You are a text correction assistant. Your task is to clean up and correct errors from raw OCR output.\n",
    "The text may contain misrecognized characters, broken words, or incorrect formatting.\n",
    "Carefully read the provided OCR output, compare it to the original image, and produce a corrected version that is  \n",
    "as faithful to the original content as possible. Only correct obvious OCR errors, and do not attempt to complete\n",
    "cut-off entries or predict missing information. Put each entry on a separate line.\n",
    "When an entry has an index number in square brackets, place it at the end of the entry.\n",
    "Input (Raw OCR Text):\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "prompt_llm = \"\"\"\n",
    "Your task is to transcribe this image of a historical bibliography page as faithfully as possible.\n",
    "Only transcribe typed text that appears on the page and do not attempt to predict missing information or complete cut off entries. \n",
    "Put each entry on a separate line. When an entry has an index number in square brackets, place it at the end of the entry. \n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d58cb0c-aeb8-47cc-9528-26bc3a802984",
   "metadata": {},
   "source": [
    "## 4. OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d64bb8",
   "metadata": {},
   "source": [
    "### (i) Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06535758",
   "metadata": {},
   "source": [
    "#### a. OCR-LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163080e4-5134-407c-9cdd-7a89141e1632",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in img_filepaths:\n",
    "    input = \"\"\n",
    "    base64_image = encode_image(path)\n",
    "    ocr_text_path = str(txt_output_dir / \"ocr-img2txt\" / \"pytesseract\" / path.stem) + \".txt\" # THIS REMAINS THE SAME b/c we're reading the OCR output\n",
    "    with open(ocr_text_path, 'r') as file:\n",
    "        input += file.read()\n",
    "    prompt_ocr_llm = prompt_template_ocr_llm.format(input=input).strip()\n",
    "\n",
    "    response = gpt_client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        temperature= 0,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt_ocr_llm\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            ]\n",
    "    )\n",
    "\n",
    "    with open(txt_output_dir / f\"ocr-llm-img2txt\" / \"gpt-4o\" / Path(path.stem + f\".txt\"), 'w') as file:\n",
    "        file.write(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cafe77",
   "metadata": {},
   "source": [
    "#### b. LLM call (without OCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c2eedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in img_filepaths:\n",
    "    base64_image = encode_image(path)\n",
    "\n",
    "    response = gpt_client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        temperature= 0,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt_llm\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            ]\n",
    "    )\n",
    "\n",
    "    with open(txt_output_dir / f\"llm-img2txt\" / \"gpt-4o\" / Path(path.stem + f\".txt\"), 'w') as file:\n",
    "        file.write(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aa37e9",
   "metadata": {},
   "source": [
    "#### c. OCR-LLM (Async)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4021c121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p003.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p003.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p004.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p004.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p005.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p005.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p006.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p006.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p007.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p007.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p008.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p008.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p009.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p009.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p010.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p010.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p011.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p011.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p012.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p012.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p038.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p038.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p039.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p039.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p043.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p043.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p048.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p048.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p049.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p049.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p058.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p058.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p059.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p059.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p060.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p060.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p061.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p061.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p062.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p062.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p063.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p063.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p064.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p064.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p065.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p065.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p066.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p066.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p067.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p067.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p068.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p068.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p069.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p069.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p070.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p070.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p071.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p071.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p072.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p072.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p073.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p073.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p096.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p096.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p100.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p100.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p101.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p101.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p106.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p106.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p107.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p107.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p113.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p113.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p114.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p114.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p115.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p115.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p119.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p119.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p121.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p121.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p124.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p124.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p151.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p151.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p003.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p003.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p004.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p004.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p005.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p005.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p006.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p006.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p007.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p007.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p008.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p008.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p009.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p009.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p010.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p010.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p011.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p011.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p012.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p012.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p038.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p038.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p039.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p039.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p043.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p043.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p048.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p048.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p049.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p049.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p058.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p058.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p059.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p059.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p060.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p060.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p061.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p061.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p062.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p062.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p063.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p063.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p064.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p064.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p065.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p065.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p066.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p066.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p067.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p067.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p068.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p068.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p069.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p069.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p070.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p070.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p071.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p071.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p072.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p072.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p073.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p073.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p096.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p096.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p100.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p100.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p101.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p101.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p106.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p106.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p107.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p107.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p113.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p113.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p114.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p114.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p115.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p115.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p119.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p119.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p121.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p121.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p124.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p124.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p151.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p151.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 11:19:55 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:19:58 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:19:58 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:20:07 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 502 Bad Gateway\"\n",
      "[file retrieval] 2025-07-16 11:20:07 [INFO] Retrying request to /chat/completions in 0.408098 seconds\n",
      "[file retrieval] 2025-07-16 11:20:17 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:20:32 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:20:42 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:20:43 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:20:54 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:21:19 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:21:23 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:21:26 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:21:34 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:21:58 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:22:02 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:22:03 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:22:16 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:22:17 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:22:17 [INFO] Retrying request to /chat/completions in 3.730000 seconds\n",
      "[file retrieval] 2025-07-16 11:22:22 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:22:22 [INFO] Retrying request to /chat/completions in 2.516000 seconds\n",
      "[file retrieval] 2025-07-16 11:22:35 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:22:39 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:22:41 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:22:41 [INFO] Retrying request to /chat/completions in 3.698000 seconds\n",
      "[file retrieval] 2025-07-16 11:22:46 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:22:46 [INFO] Retrying request to /chat/completions in 3.698000 seconds\n",
      "[file retrieval] 2025-07-16 11:22:51 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 2.66s after error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-N8S8KUq02KYXhJXKPXPfRjJq on tokens per min (TPM): Limit 30000, Used 29108, Requested 1849. Please try again in 1.913s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 11:22:52 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:22:54 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:22:54 [INFO] Retrying request to /chat/completions in 2.076000 seconds\n",
      "[file retrieval] 2025-07-16 11:22:55 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:22:56 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:22:56 [INFO] Retrying request to /chat/completions in 3.682000 seconds\n",
      "[file retrieval] 2025-07-16 11:22:57 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:22:57 [INFO] Retrying request to /chat/completions in 3.446000 seconds\n",
      "[file retrieval] 2025-07-16 11:22:58 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:22:58 [INFO] Retrying request to /chat/completions in 2.264000 seconds\n",
      "[file retrieval] 2025-07-16 11:23:02 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:23:02 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:23:02 [INFO] Retrying request to /chat/completions in 3.682000 seconds\n",
      "[file retrieval] 2025-07-16 11:23:02 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:23:02 [INFO] Retrying request to /chat/completions in 3.698000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 2.58s after error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-N8S8KUq02KYXhJXKPXPfRjJq on tokens per min (TPM): Limit 30000, Used 30000, Requested 1840. Please try again in 3.68s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 11:23:06 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:23:06 [INFO] Retrying request to /chat/completions in 2.830000 seconds\n",
      "[file retrieval] 2025-07-16 11:23:07 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:23:07 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 2.80s after error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-N8S8KUq02KYXhJXKPXPfRjJq on tokens per min (TPM): Limit 30000, Used 29080, Requested 1841. Please try again in 1.842s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Retrying in 4.79s after error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-N8S8KUq02KYXhJXKPXPfRjJq on tokens per min (TPM): Limit 30000, Used 29027, Requested 1849. Please try again in 1.752s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 11:23:10 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:23:10 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:23:10 [INFO] Retrying request to /chat/completions in 1.772000 seconds\n",
      "[file retrieval] 2025-07-16 11:23:12 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:23:12 [INFO] Retrying request to /chat/completions in 0.076000 seconds\n",
      "[file retrieval] 2025-07-16 11:23:14 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:23:14 [INFO] Retrying request to /chat/completions in 1.954000 seconds\n",
      "[file retrieval] 2025-07-16 11:23:14 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:23:14 [INFO] Retrying request to /chat/completions in 3.682000 seconds\n",
      "[file retrieval] 2025-07-16 11:23:17 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 2.64s after error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-N8S8KUq02KYXhJXKPXPfRjJq on tokens per min (TPM): Limit 30000, Used 29463, Requested 1842. Please try again in 2.61s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 11:23:20 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:23:20 [INFO] Retrying request to /chat/completions in 3.682000 seconds\n",
      "[file retrieval] 2025-07-16 11:23:21 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:23:21 [INFO] Retrying request to /chat/completions in 3.684000 seconds\n",
      "[file retrieval] 2025-07-16 11:23:26 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:23:26 [INFO] Retrying request to /chat/completions in 2.898000 seconds\n",
      "[file retrieval] 2025-07-16 11:23:51 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:23:51 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:23:53 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 11:23:53 [INFO] Retrying request to /chat/completions in 1.925000 seconds\n",
      "[file retrieval] 2025-07-16 11:24:07 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:24:08 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:24:24 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:24:33 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:24:51 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:25:07 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:25:15 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:25:21 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:25:40 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:25:49 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:25:56 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:25:56 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:26:20 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:26:28 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:26:48 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:26:48 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:27:03 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:27:11 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:27:26 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:27:29 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Fetch ocr output files\n",
    "ocr_output_dir = txt_output_dir/\"ocr-img2txt\"/\"pytesseract\"\n",
    "ocr_output_filepaths = get_paths(ocr_output_dir, \"txt\")\n",
    "\n",
    "# Run the async processes\n",
    "await process_double_async(img_filepaths, ocr_output_filepaths, txt_output_dir/\"ocr-llm-img2txt\", openai_img_txt2txt_async, llms['openai'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267fdde9",
   "metadata": {},
   "source": [
    "#### d. LLM (Async)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0544747",
   "metadata": {},
   "outputs": [],
   "source": [
    "await process_single_async(img_filepaths, txt_output_dir/\"llm-img2txt\", openai_img2txt_async, llms['openai'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5692d2",
   "metadata": {},
   "source": [
    "### (ii) JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd528634",
   "metadata": {},
   "source": [
    "#### a. Image to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f2dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in img_filepaths:\n",
    "    response = openai_img2json(path)\n",
    "    with open(json_output_dir / f\"llm-img2json\" / \"gpt-4o\" / Path(path.stem + \".json\"), 'w') as file:\n",
    "        print(\"Output path:\", json_output_dir / f\"llm-img2json\" / \"gpt-4o\" / Path(path.stem + \".json\"))\n",
    "        file.write(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1ccf05",
   "metadata": {},
   "source": [
    "#### b. Text to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44edaf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = txt_source_dir / llms['openai'] # where to look for ocr-llm-img2txt output\n",
    "\n",
    "# Get the text paths from ocr-llm-img2txt/gpt-4o directory\n",
    "txt_filepaths = get_paths(dir, \"txt\")\n",
    "\n",
    "for path in txt_filepaths:\n",
    "    ocr_text_path = str(root_dir / \"results\" / \"txt\" / \"ocr-img2txt\" / \"pytesseract\" /path.stem) + \".txt\" # THIS REMAINS THE SAME b/c we're reading the OCR output\n",
    "    response = openai_txt2json(ocr_text_path)\n",
    "    with open(json_output_dir / f\"llm-txt2json\" / \"gpt-4o\" / Path(path.stem + \".json\"), 'w') as file:\n",
    "        print(\"Writing to\", json_output_dir / \"llm-txt2json\" / \"gpt-4o\" / Path(path.stem + \".json\"))\n",
    "        file.write(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7ed85e",
   "metadata": {},
   "source": [
    "#### c. Image to JSON (Async)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdfa470",
   "metadata": {},
   "outputs": [],
   "source": [
    "await process_json_async(img_filepaths, json_output_dir/\"llm-img2json\", openai_img2json_async, llms['openai'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6ae2c9",
   "metadata": {},
   "source": [
    "#### d. Text to JSON (Async)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e7b5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 17:07:28 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:07:35 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:07:36 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:07:44 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:07:50 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:07:53 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:07:54 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:08:10 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:08:19 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:08:21 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:08:31 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:08:47 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:08:48 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:08:56 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:09:10 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:09:13 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:09:14 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:09:15 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:15 [INFO] Retrying request to /chat/completions in 1.866000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:17 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:17 [INFO] Retrying request to /chat/completions in 1.866000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:19 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:19 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:19 [INFO] Retrying request to /chat/completions in 1.866000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:21 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:21 [INFO] Retrying request to /chat/completions in 1.650000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:28 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:09:28 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:28 [INFO] Retrying request to /chat/completions in 1.862000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:28 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:09:29 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:29 [INFO] Retrying request to /chat/completions in 1.832000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:30 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:30 [INFO] Retrying request to /chat/completions in 1.862000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:31 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:31 [INFO] Retrying request to /chat/completions in 1.832000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:31 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:09:31 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:31 [INFO] Retrying request to /chat/completions in 1.852000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:32 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:32 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:32 [INFO] Retrying request to /chat/completions in 1.862000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:33 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:33 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:33 [INFO] Retrying request to /chat/completions in 1.832000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:33 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:33 [INFO] Retrying request to /chat/completions in 1.852000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:34 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:34 [INFO] Retrying request to /chat/completions in 1.862000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:35 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:35 [INFO] Retrying request to /chat/completions in 1.832000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:35 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:35 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:35 [INFO] Retrying request to /chat/completions in 1.852000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:36 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:36 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:36 [INFO] Retrying request to /chat/completions in 1.862000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:37 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:37 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:37 [INFO] Retrying request to /chat/completions in 1.832000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:37 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:37 [INFO] Retrying request to /chat/completions in 1.852000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:38 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:09:38 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:38 [INFO] Retrying request to /chat/completions in 1.850000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:38 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:38 [INFO] Retrying request to /chat/completions in 1.862000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:39 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:39 [INFO] Retrying request to /chat/completions in 1.832000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:39 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:39 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:39 [INFO] Retrying request to /chat/completions in 1.852000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:40 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:40 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:40 [INFO] Retrying request to /chat/completions in 1.850000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 2.38s after error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-N8S8KUq02KYXhJXKPXPfRjJq on tokens per min (TPM): Limit 30000, Used 30000, Requested 931. Please try again in 1.862s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 17:09:41 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 2.49s after error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-N8S8KUq02KYXhJXKPXPfRjJq on tokens per min (TPM): Limit 30000, Used 30000, Requested 916. Please try again in 1.832s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 17:09:41 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:41 [INFO] Retrying request to /chat/completions in 1.852000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:42 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:42 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:42 [INFO] Retrying request to /chat/completions in 1.850000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:43 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:43 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:43 [INFO] Retrying request to /chat/completions in 1.832000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 2.88s after error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-N8S8KUq02KYXhJXKPXPfRjJq on tokens per min (TPM): Limit 30000, Used 30000, Requested 926. Please try again in 1.852s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 17:09:44 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:44 [INFO] Retrying request to /chat/completions in 1.850000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:45 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:45 [INFO] Retrying request to /chat/completions in 1.832000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:46 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:46 [INFO] Retrying request to /chat/completions in 1.862000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:46 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:46 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:46 [INFO] Retrying request to /chat/completions in 1.850000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:46 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:46 [INFO] Retrying request to /chat/completions in 1.852000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:47 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:47 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:47 [INFO] Retrying request to /chat/completions in 1.832000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:48 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:48 [INFO] Retrying request to /chat/completions in 1.862000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:48 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:48 [INFO] Retrying request to /chat/completions in 1.850000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:48 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:48 [INFO] Retrying request to /chat/completions in 1.852000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:49 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:49 [INFO] Retrying request to /chat/completions in 1.832000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:50 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:50 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:50 [INFO] Retrying request to /chat/completions in 1.862000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:50 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 2.38s after error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-N8S8KUq02KYXhJXKPXPfRjJq on tokens per min (TPM): Limit 30000, Used 30000, Requested 925. Please try again in 1.85s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 17:09:50 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:50 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:50 [INFO] Retrying request to /chat/completions in 1.852000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:51 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:51 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:51 [INFO] Retrying request to /chat/completions in 1.832000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:52 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:52 [INFO] Retrying request to /chat/completions in 1.862000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:52 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:52 [INFO] Retrying request to /chat/completions in 1.852000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:53 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:53 [INFO] Retrying request to /chat/completions in 1.670000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:53 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:53 [INFO] Retrying request to /chat/completions in 1.090000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:54 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:54 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:54 [INFO] Retrying request to /chat/completions in 0.582000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:54 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:55 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:55 [INFO] Retrying request to /chat/completions in 1.638000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:56 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:56 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:56 [INFO] Retrying request to /chat/completions in 1.850000 seconds\n",
      "[file retrieval] 2025-07-16 17:09:58 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:09:58 [INFO] Retrying request to /chat/completions in 1.850000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:00 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:01 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:01 [INFO] Retrying request to /chat/completions in 1.850000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:03 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:03 [INFO] Retrying request to /chat/completions in 1.850000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:04 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 4.09s after error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-N8S8KUq02KYXhJXKPXPfRjJq on tokens per min (TPM): Limit 30000, Used 29737, Requested 925. Please try again in 1.324s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 17:10:09 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:10:09 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:09 [INFO] Retrying request to /chat/completions in 1.852000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:10 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:10:10 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:10 [INFO] Retrying request to /chat/completions in 1.896000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:11 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:11 [INFO] Retrying request to /chat/completions in 1.852000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:12 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:10:12 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:12 [INFO] Retrying request to /chat/completions in 1.896000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:12 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:12 [INFO] Retrying request to /chat/completions in 1.818000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:13 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:13 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:13 [INFO] Retrying request to /chat/completions in 1.852000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:14 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:14 [INFO] Retrying request to /chat/completions in 1.818000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:14 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:15 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:15 [INFO] Retrying request to /chat/completions in 1.896000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:15 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:15 [INFO] Retrying request to /chat/completions in 1.852000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:16 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:16 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:16 [INFO] Retrying request to /chat/completions in 1.818000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:17 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:17 [INFO] Retrying request to /chat/completions in 1.896000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:17 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:17 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:17 [INFO] Retrying request to /chat/completions in 1.852000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:18 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:18 [INFO] Retrying request to /chat/completions in 1.818000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:19 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:19 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:19 [INFO] Retrying request to /chat/completions in 1.896000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:19 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:19 [INFO] Retrying request to /chat/completions in 1.852000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:20 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:20 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:20 [INFO] Retrying request to /chat/completions in 1.818000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:21 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:21 [INFO] Retrying request to /chat/completions in 1.896000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:21 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 2.03s after error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-N8S8KUq02KYXhJXKPXPfRjJq on tokens per min (TPM): Limit 30000, Used 30000, Requested 926. Please try again in 1.852s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 17:10:22 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:22 [INFO] Retrying request to /chat/completions in 1.818000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:23 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 2.64s after error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-N8S8KUq02KYXhJXKPXPfRjJq on tokens per min (TPM): Limit 30000, Used 29413, Requested 948. Please try again in 722ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 17:10:24 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:24 [INFO] Retrying request to /chat/completions in 0.434000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:24 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 2.45s after error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-N8S8KUq02KYXhJXKPXPfRjJq on tokens per min (TPM): Limit 30000, Used 29117, Requested 909. Please try again in 52ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 17:10:24 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:10:25 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:25 [INFO] Retrying request to /chat/completions in 1.878000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:26 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:26 [INFO] Retrying request to /chat/completions in 1.896000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:27 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:27 [INFO] Retrying request to /chat/completions in 1.878000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:27 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:27 [INFO] Retrying request to /chat/completions in 1.818000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:28 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:28 [INFO] Retrying request to /chat/completions in 1.896000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:29 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:29 [INFO] Retrying request to /chat/completions in 1.818000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:29 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:29 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:29 [INFO] Retrying request to /chat/completions in 1.820000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:30 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:30 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:30 [INFO] Retrying request to /chat/completions in 0.372000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:32 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:32 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:32 [INFO] Retrying request to /chat/completions in 1.818000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:34 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:34 [INFO] Retrying request to /chat/completions in 0.780000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:40 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:10:48 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:10:48 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:48 [INFO] Retrying request to /chat/completions in 1.822000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:49 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:10:49 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:49 [INFO] Retrying request to /chat/completions in 1.868000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:50 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:50 [INFO] Retrying request to /chat/completions in 1.822000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:51 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:10:51 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:51 [INFO] Retrying request to /chat/completions in 1.972000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:51 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:51 [INFO] Retrying request to /chat/completions in 1.868000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:52 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:52 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:52 [INFO] Retrying request to /chat/completions in 1.822000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:53 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:53 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:53 [INFO] Retrying request to /chat/completions in 1.868000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:53 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:53 [INFO] Retrying request to /chat/completions in 1.972000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:54 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:54 [INFO] Retrying request to /chat/completions in 1.822000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:55 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:55 [INFO] Retrying request to /chat/completions in 1.868000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:55 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:55 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:55 [INFO] Retrying request to /chat/completions in 1.972000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:56 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:56 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:56 [INFO] Retrying request to /chat/completions in 1.822000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:57 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:57 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:57 [INFO] Retrying request to /chat/completions in 1.868000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:57 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:57 [INFO] Retrying request to /chat/completions in 1.972000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:58 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:58 [INFO] Retrying request to /chat/completions in 1.822000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:59 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:59 [INFO] Retrying request to /chat/completions in 1.868000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:59 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:59 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:10:59 [INFO] Retrying request to /chat/completions in 1.972000 seconds\n",
      "[file retrieval] 2025-07-16 17:10:59 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:11:00 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:00 [INFO] Retrying request to /chat/completions in 1.920000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:00 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 2.81s after error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-N8S8KUq02KYXhJXKPXPfRjJq on tokens per min (TPM): Limit 30000, Used 30000, Requested 911. Please try again in 1.822s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 17:11:01 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 2.42s after error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-N8S8KUq02KYXhJXKPXPfRjJq on tokens per min (TPM): Limit 30000, Used 30000, Requested 934. Please try again in 1.868s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 17:11:01 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:01 [INFO] Retrying request to /chat/completions in 1.972000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:02 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:02 [INFO] Retrying request to /chat/completions in 1.920000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:03 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:03 [INFO] Retrying request to /chat/completions in 1.822000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:03 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:03 [INFO] Retrying request to /chat/completions in 1.868000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:04 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 2.42s after error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-N8S8KUq02KYXhJXKPXPfRjJq on tokens per min (TPM): Limit 30000, Used 30000, Requested 986. Please try again in 1.972s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 17:11:04 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:04 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:04 [INFO] Retrying request to /chat/completions in 1.920000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:05 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:05 [INFO] Retrying request to /chat/completions in 1.822000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:05 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:05 [INFO] Retrying request to /chat/completions in 1.868000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:06 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:06 [INFO] Retrying request to /chat/completions in 1.920000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:06 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:06 [INFO] Retrying request to /chat/completions in 1.972000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:07 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:07 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:07 [INFO] Retrying request to /chat/completions in 1.822000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:08 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:08 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:08 [INFO] Retrying request to /chat/completions in 1.868000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:08 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:08 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:08 [INFO] Retrying request to /chat/completions in 1.920000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:08 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:08 [INFO] Retrying request to /chat/completions in 1.972000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:09 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:09 [INFO] Retrying request to /chat/completions in 1.822000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:10 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:10 [INFO] Retrying request to /chat/completions in 1.868000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:10 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:10 [INFO] Retrying request to /chat/completions in 1.920000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:10 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:10 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:10 [INFO] Retrying request to /chat/completions in 1.972000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:11 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:11 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:11 [INFO] Retrying request to /chat/completions in 1.778000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:12 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:12 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:12 [INFO] Retrying request to /chat/completions in 1.140000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:12 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 2.49s after error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-N8S8KUq02KYXhJXKPXPfRjJq on tokens per min (TPM): Limit 30000, Used 29387, Requested 960. Please try again in 694ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 17:11:13 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:13 [INFO] Retrying request to /chat/completions in 0.478000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:15 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:15 [INFO] Retrying request to /chat/completions in 1.920000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:17 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:17 [INFO] Retrying request to /chat/completions in 1.644000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:19 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:19 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:19 [INFO] Retrying request to /chat/completions in 1.920000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:21 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:21 [INFO] Retrying request to /chat/completions in 1.920000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:23 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:23 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:23 [INFO] Retrying request to /chat/completions in 1.198000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:28 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:11:29 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:29 [INFO] Retrying request to /chat/completions in 1.916000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:32 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:11:33 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:33 [INFO] Retrying request to /chat/completions in 1.814000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:34 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:11:34 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:34 [INFO] Retrying request to /chat/completions in 1.883000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:35 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:35 [INFO] Retrying request to /chat/completions in 1.814000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:36 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:36 [INFO] Retrying request to /chat/completions in 1.883000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:37 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:37 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:37 [INFO] Retrying request to /chat/completions in 1.814000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:38 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:38 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:38 [INFO] Retrying request to /chat/completions in 1.883000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:39 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:39 [INFO] Retrying request to /chat/completions in 1.814000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:40 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:40 [INFO] Retrying request to /chat/completions in 1.883000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:41 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:41 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:41 [INFO] Retrying request to /chat/completions in 1.814000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:42 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:42 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:42 [INFO] Retrying request to /chat/completions in 1.744000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:43 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:43 [INFO] Retrying request to /chat/completions in 1.466000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:46 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:11:47 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:47 [INFO] Retrying request to /chat/completions in 1.772000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:48 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:11:48 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:48 [INFO] Retrying request to /chat/completions in 1.879000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:48 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:48 [INFO] Retrying request to /chat/completions in 1.772000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:50 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:50 [INFO] Retrying request to /chat/completions in 1.879000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:50 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:50 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:50 [INFO] Retrying request to /chat/completions in 1.772000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:52 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:52 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:52 [INFO] Retrying request to /chat/completions in 1.772000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:52 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:52 [INFO] Retrying request to /chat/completions in 1.879000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:54 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:54 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:54 [INFO] Retrying request to /chat/completions in 1.772000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:54 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:54 [INFO] Retrying request to /chat/completions in 1.879000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:56 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:56 [INFO] Retrying request to /chat/completions in 1.772000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:56 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:56 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:56 [INFO] Retrying request to /chat/completions in 1.879000 seconds\n",
      "[file retrieval] 2025-07-16 17:11:58 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 2.01s after error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-N8S8KUq02KYXhJXKPXPfRjJq on tokens per min (TPM): Limit 30000, Used 29692, Requested 886. Please try again in 1.156s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 17:11:58 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:11:58 [INFO] Retrying request to /chat/completions in 0.990000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:00 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:00 [INFO] Retrying request to /chat/completions in 0.820000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:07 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:12:07 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:07 [INFO] Retrying request to /chat/completions in 1.882000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:09 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:12:09 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:09 [INFO] Retrying request to /chat/completions in 1.882000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:10 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:10 [INFO] Retrying request to /chat/completions in 1.878000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:11 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:12 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:12 [INFO] Retrying request to /chat/completions in 1.882000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:12 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:12 [INFO] Retrying request to /chat/completions in 1.878000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:14 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:14 [INFO] Retrying request to /chat/completions in 1.882000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:14 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:14 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:14 [INFO] Retrying request to /chat/completions in 1.878000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:16 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:16 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:16 [INFO] Retrying request to /chat/completions in 1.878000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:16 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:16 [INFO] Retrying request to /chat/completions in 1.882000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:18 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:18 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:18 [INFO] Retrying request to /chat/completions in 1.882000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:18 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:18 [INFO] Retrying request to /chat/completions in 1.878000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:20 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 2.22s after error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-N8S8KUq02KYXhJXKPXPfRjJq on tokens per min (TPM): Limit 30000, Used 29084, Requested 941. Please try again in 50ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 17:12:22 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:12:22 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:22 [INFO] Retrying request to /chat/completions in 1.882000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:22 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:22 [INFO] Retrying request to /chat/completions in 1.834000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:24 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:24 [INFO] Retrying request to /chat/completions in 1.882000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:24 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:24 [INFO] Retrying request to /chat/completions in 1.834000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:26 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:26 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:26 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:26 [INFO] Retrying request to /chat/completions in 0.804000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:26 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:26 [INFO] Retrying request to /chat/completions in 0.826000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:31 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:12:32 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:32 [INFO] Retrying request to /chat/completions in 1.790000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:34 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:34 [INFO] Retrying request to /chat/completions in 1.790000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:35 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:36 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "[file retrieval] 2025-07-16 17:12:36 [INFO] Retrying request to /chat/completions in 0.720000 seconds\n",
      "[file retrieval] 2025-07-16 17:12:48 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:12:51 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:12:54 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 17:13:08 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "dir = txt_source_dir / llms['openai'] # where to look for ocr-llm-img2txt output\n",
    "# Get the text paths from ocr-llm-img2txt/gpt-4o directory\n",
    "txt_filepaths = get_paths(dir, \"txt\")\n",
    "\n",
    "# Call the main function that concurrently runs relevant async function\n",
    "await process_json_async(txt_filepaths, json_output_dir/\"llm-txt2json\", openai_txt2json_async, llms['openai'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25ecae5",
   "metadata": {},
   "source": [
    "## 5. Gemini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047fb167",
   "metadata": {},
   "source": [
    "### (i) Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f10c212",
   "metadata": {},
   "source": [
    "#### a. OCR-LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e5d357",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in img_filepaths:\n",
    "    my_file = gemini_client.files.upload(file=path)\n",
    "    input = \"\"\n",
    "    ocr_text_path = str(txt_output_dir / \"ocr-img2txt\" / \"pytesseract\" / path.stem) + \".txt\" # THIS REMAINS THE SAME b/c we're reading the OCR output\n",
    "    with open(ocr_text_path, 'r') as file:\n",
    "        input += file.read()\n",
    "    prompt_ocr_llm = prompt_template_ocr_llm.format(input=input).strip()\n",
    "\n",
    "    response = gemini_client.models.generate_content(\n",
    "        model='gemini-2.5-flash',\n",
    "        config= types.GenerateContentConfig(\n",
    "        temperature = 0\n",
    "        ),\n",
    "        contents=[\n",
    "            prompt_ocr_llm,\n",
    "            my_file\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    with open(txt_output_dir / f\"ocr-llm-img2txt\" / \"gemini-2.5-flash\" / Path(path.stem + f\".txt\"), 'w') as file:\n",
    "        file.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d3100",
   "metadata": {},
   "source": [
    "#### b. LLM call (without OCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d3d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in img_filepaths:\n",
    "    my_file = gemini_client.files.upload(file=path)\n",
    "\n",
    "    response = gemini_client.models.generate_content(\n",
    "        model='gemini-2.5-flash',\n",
    "        config= types.GenerateContentConfig(\n",
    "        temperature = 0\n",
    "        ),\n",
    "        contents=[\n",
    "            prompt_llm,\n",
    "            my_file\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    with open(txt_output_dir / f\"llm-img2txt\" / \"gemini-2.5-flash\" / Path(path.stem + f\".txt\"), 'w') as file:\n",
    "        file.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b29d8b3",
   "metadata": {},
   "source": [
    "#### c. LLM call (Async)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17594637",
   "metadata": {},
   "outputs": [],
   "source": [
    "await process_single_async(img_filepaths, txt_output_dir/\"llm-img2txt\", gemini_img2txt_async, llms['google'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5af92",
   "metadata": {},
   "source": [
    "#### d. OCR-LLM (Async)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "930b5cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 11:10:49 [INFO] AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p003.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p003.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p004.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p004.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p005.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p005.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p006.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p006.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p007.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p007.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p008.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p008.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p009.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p009.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p010.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p010.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p011.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p011.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p012.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p012.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p038.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p038.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p039.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p039.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p043.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p043.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p048.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p048.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p049.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p049.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p058.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p058.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p059.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p059.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p060.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p060.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p061.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p061.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p062.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p062.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p063.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p063.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p064.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p064.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p065.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p065.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p066.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p066.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p067.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p067.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p068.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p068.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p069.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p069.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p070.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p070.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p071.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p071.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p072.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p072.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p073.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p073.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p096.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p096.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p100.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p100.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p101.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p101.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p106.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p106.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p107.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p107.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p113.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p113.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p114.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p114.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p115.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p115.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p119.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p119.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p121.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p121.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p124.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p124.txt\n",
      "Matched image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p151.png' with text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p151.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p003.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p003.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p004.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p004.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p005.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p005.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p006.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p006.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p007.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p007.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p008.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p008.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p009.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p009.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p010.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p010.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p011.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p011.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p012.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p012.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p038.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p038.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p039.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p039.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p043.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p043.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p048.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p048.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p049.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p049.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p058.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p058.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p059.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p059.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p060.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p060.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p061.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p061.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p062.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p062.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p063.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p063.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p064.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p064.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p065.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p065.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p066.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p066.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p067.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p067.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p068.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p068.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p069.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p069.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p070.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p070.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p071.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p071.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p072.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p072.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p073.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p073.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p096.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p096.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p100.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p100.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p101.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p101.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p106.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p106.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p107.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p107.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p113.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p113.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p114.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p114.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p115.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p115.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p119.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p119.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p121.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p121.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p124.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p124.txt\n",
      "Added task with image file 'c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\data\\pngs\\kbaa-p151.png' and text file c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\txt\\ocr-img2txt\\pytesseract\\kbaa-p151.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 11:10:57 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:11:04 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:11:11 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:11:37 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:11:37 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:11:43 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:11:43 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:11:49 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:11:49 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:11:57 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:11:57 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:12:11 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:12:11 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:12:18 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:12:18 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:12:28 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:12:28 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:12:37 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:12:37 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:12:49 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:12:49 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:12:55 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:12:55 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:13:01 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:13:01 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:13:10 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:13:10 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:13:28 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:13:28 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:13:33 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:13:33 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:13:39 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:13:39 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:13:40 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:13:46 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:14:06 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:14:06 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:14:11 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:14:11 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:14:16 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:14:16 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:14:20 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:14:20 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:14:36 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:14:36 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:14:49 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:14:49 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:14:53 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:14:53 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:14:53 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:14:58 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:15:06 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:15:06 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:15:27 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:15:27 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:15:31 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:15:31 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:15:36 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:15:36 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:15:36 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:15:44 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:15:57 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:15:57 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:16:10 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:16:10 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:16:18 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:16:18 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:16:26 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:16:26 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:16:34 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:16:34 [INFO] AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying in 2.84s after error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 11:16:43 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:17:09 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:17:09 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:17:16 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:17:16 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:17:25 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:17:25 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:17:26 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:17:34 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:17:49 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:17:49 [INFO] AFC is enabled with max remote calls: 10.\n",
      "[file retrieval] 2025-07-16 11:17:59 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:18:01 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:18:02 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[file retrieval] 2025-07-16 11:18:17 [INFO] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Fetch ocr output files\n",
    "ocr_output_dir = txt_output_dir/\"ocr-img2txt\"/\"pytesseract\"\n",
    "ocr_output_filepaths = get_paths(ocr_output_dir, \"txt\")\n",
    "\n",
    "# Run the async processes\n",
    "await process_double_async(img_filepaths, ocr_output_filepaths, txt_output_dir/\"ocr-llm-img2txt\", gemini_img_txt2txt_async, llms['google'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1cec32",
   "metadata": {},
   "source": [
    "### (ii) JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af53393d",
   "metadata": {},
   "source": [
    "#### a. Image to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fe4fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in img_filepaths:\n",
    "    response = gemini_img2json(path)\n",
    "    with open(json_output_dir / f\"llm-img2json\" / \"gemini-2.5-flash\" / Path(path.stem + f\".json\"), 'w') as file:\n",
    "        file.write(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b78765",
   "metadata": {},
   "source": [
    "#### b. Text to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5055dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for path in img_filepaths:\n",
    "    ocr_text_path = str(root_dir/ \"results\" / \"txt\" / \"ocr-llm-img2txt\" / \"gemini-2.5-flash\" / path.stem) + \".txt\" # THIS REMAINS THE SAME b/c we're reading the OCR output\n",
    "    response = gemini_txt2json(ocr_text_path)\n",
    "    with open(json_output_dir / f\"llm-txt2json\" / \"gemini-2.5-flash\" / Path(path.stem + f\".json\"), 'w') as file:\n",
    "        file.write(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e600840",
   "metadata": {},
   "source": [
    "#### c. Image to JSON (Async)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b03c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "await process_json_async(img_filepaths, json_output_dir/\"llm-img2json\", gemini_img2json_async, llms['google'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4d6b4d",
   "metadata": {},
   "source": [
    "#### d. Text to JSON (Async)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42c3dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir = txt_source_dir / llms['google'] # where to look for ocr-llm-img2txt output\n",
    "\n",
    "# Get the text paths from ocr-llm-img2txt/gpt-4o directory\n",
    "txt_filepaths = get_paths(dir, \"txt\")\n",
    "\n",
    "# Call the main function that concurrently runs relevant async function\n",
    "await process_json_async(txt_filepaths, json_output_dir/\"llm-txt2json\", gemini_txt2json_async, llms['google'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d06c34",
   "metadata": {},
   "source": [
    "## 6. Send to Claude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0869c81",
   "metadata": {},
   "source": [
    "### a. OCR-LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651e17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in img_filepaths:\n",
    "#     base64_image = encode_image(path)\n",
    "\n",
    "#     response = claude_client.messages.create(\n",
    "#         model='claude-opus-4-20250514',\n",
    "#         temperature=0,\n",
    "#         max_tokens=10,\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"user\", \n",
    "#                 \"content\": [\n",
    "#                     {\n",
    "#                         \"type\": \"text\",\n",
    "#                         \"text\": prompt_ocr_llm\n",
    "#                     },\n",
    "#                     {\n",
    "#                         \"type\": \"image\",\n",
    "#                         \"source\": {\n",
    "#                             \"type\": \"base64\",\n",
    "#                             \"media_type\": \"image/png\",\n",
    "#                             \"data\": base64_image\n",
    "#                         }\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#             ]\n",
    "#     )\n",
    "#     print(response)\n",
    "\n",
    "#     with open(txt_output_dir / \"ocr-llm-img2txt\" / \"claude-4-sonnet\" / Path(path.stem + \".txt\"), 'w') as file:\n",
    "#         file.write(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b610ccd9",
   "metadata": {},
   "source": [
    "### b. LLM call (without OCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497c3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in img_filepaths:\n",
    "#     base64_image = encode_image(path)\n",
    "\n",
    "#     response = claude_client.messages.create(\n",
    "#         model='claude-opus-4-20250514',\n",
    "#         temperature=0,\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"user\", \n",
    "#                 \"content\": [\n",
    "#                     {\n",
    "#                         \"type\": \"text\",\n",
    "#                         \"text\": prompt_llm\n",
    "#                     },\n",
    "#                     {\n",
    "#                         \"type\": \"image\",\n",
    "#                         \"source\": {\n",
    "#                             \"type\": \"base64\",\n",
    "#                             \"media_type\": \"image/png\",\n",
    "#                             \"data\": base64_image\n",
    "#                         }\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#             ]\n",
    "#     )\n",
    "\n",
    "#     with open(txt_output_dir / \"llm-img2txt\" / \"claude-4-sonnet\" / Path(path.stem + \".txt\"), 'w') as file:\n",
    "#         file.write(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ab1803",
   "metadata": {},
   "source": [
    "## 7. Qwen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deafc07",
   "metadata": {},
   "source": [
    "### (i) Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653e82a0",
   "metadata": {},
   "source": [
    "#### a. LLM (Async)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a02565",
   "metadata": {},
   "outputs": [],
   "source": [
    "await process_single_async(img_filepaths, txt_output_dir/\"llm-img2txt\", openrouter_img2txt_async, llms['alibaba'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018e5702",
   "metadata": {},
   "source": [
    "#### b. OCR-LLM (Async)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4685bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch ocr output files\n",
    "ocr_output_dir = txt_output_dir/\"ocr-img2txt\"/\"pytesseract\"\n",
    "ocr_output_filepaths = get_paths(ocr_output_dir, \"txt\")\n",
    "\n",
    "# Run the async processes\n",
    "await process_double_async(img_filepaths, ocr_output_filepaths, txt_output_dir/\"ocr-llm-img2txt\", openrouter_img_txt2txt_async, llms['alibaba'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7b900",
   "metadata": {},
   "source": [
    "### (ii) JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8507b7d7",
   "metadata": {},
   "source": [
    "## 8. Llama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb18536",
   "metadata": {},
   "source": [
    "### (i) Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a677cf24",
   "metadata": {},
   "source": [
    "#### a. LLM (Async)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9e82e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "await process_single_async(img_filepaths, txt_output_dir/\"llm-img2txt\", openrouter_img2txt_async, llms['meta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b56efb8",
   "metadata": {},
   "source": [
    "#### b. OCR-LLM (Async)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7e5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch ocr output files\n",
    "ocr_output_dir = txt_output_dir/\"ocr-img2txt\"/\"pytesseract\"\n",
    "ocr_output_filepaths = get_paths(ocr_output_dir, \"txt\")\n",
    "\n",
    "# Run the async processes\n",
    "await process_double_async(img_filepaths, ocr_output_filepaths, txt_output_dir/\"ocr-llm-img2txt\", openrouter_img_txt2txt_async, llms['meta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff927177",
   "metadata": {},
   "source": [
    "### (ii) JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e20262",
   "metadata": {},
   "source": [
    "## 9. Benchmark results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f3596a",
   "metadata": {},
   "source": [
    "a. Text accuracy benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77c21953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 11:46:49 [INFO] Script directory: c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\src\\workflow\n",
      "[file retrieval] 2025-07-16 11:46:49 [INFO] Project root: c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\n",
      "[file retrieval] 2025-07-16 11:46:49 [INFO] Found ground-truth txt files: ['c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p003.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p004.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p005.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p006.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p007.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p008.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p009.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p010.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p011.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p012.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p038.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p039.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p043.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p048.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p049.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p058.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p059.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p060.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p061.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p062.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p063.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p064.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p065.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p066.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p067.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p068.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p069.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p070.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p071.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p072.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p073.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p096.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p100.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p101.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p106.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p107.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p113.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p114.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p115.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p119.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p121.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p124.txt', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\txt\\\\gt_kbaa-p151.txt']\n",
      "[file retrieval] 2025-07-16 11:46:49 [INFO] Found file names: ['gt_kbaa-p003', 'gt_kbaa-p004', 'gt_kbaa-p005', 'gt_kbaa-p006', 'gt_kbaa-p007', 'gt_kbaa-p008', 'gt_kbaa-p009', 'gt_kbaa-p010', 'gt_kbaa-p011', 'gt_kbaa-p012', 'gt_kbaa-p038', 'gt_kbaa-p039', 'gt_kbaa-p043', 'gt_kbaa-p048', 'gt_kbaa-p049', 'gt_kbaa-p058', 'gt_kbaa-p059', 'gt_kbaa-p060', 'gt_kbaa-p061', 'gt_kbaa-p062', 'gt_kbaa-p063', 'gt_kbaa-p064', 'gt_kbaa-p065', 'gt_kbaa-p066', 'gt_kbaa-p067', 'gt_kbaa-p068', 'gt_kbaa-p069', 'gt_kbaa-p070', 'gt_kbaa-p071', 'gt_kbaa-p072', 'gt_kbaa-p073', 'gt_kbaa-p096', 'gt_kbaa-p100', 'gt_kbaa-p101', 'gt_kbaa-p106', 'gt_kbaa-p107', 'gt_kbaa-p113', 'gt_kbaa-p114', 'gt_kbaa-p115', 'gt_kbaa-p119', 'gt_kbaa-p121', 'gt_kbaa-p124', 'gt_kbaa-p151']\n",
      "[file retrieval] 2025-07-16 11:46:49 [INFO] Models found: [('llm-img2txt', 'gemini-2.5-flash'), ('ocr-llm-img2txt', 'gemini-2.5-flash'), ('llm-img2txt', 'gpt-4o'), ('ocr-llm-img2txt', 'gpt-4o'), ('ocr-img2txt', 'pytesseract')]\n",
      "[file retrieval] 2025-07-16 11:46:49 [INFO] Collecting results for model: gemini-2.5-flash\n",
      "[file retrieval] 2025-07-16 11:46:49 [INFO] Collected results for model_type: llm-img2txt, model: gemini-2.5-flash\n",
      "[file retrieval] 2025-07-16 11:46:49 [INFO] Collecting results for model: gemini-2.5-flash\n",
      "[file retrieval] 2025-07-16 11:46:50 [INFO] Collected results for model_type: ocr-llm-img2txt, model: gemini-2.5-flash\n",
      "[file retrieval] 2025-07-16 11:46:50 [INFO] Collecting results for model: gpt-4o\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Collected results for model_type: llm-img2txt, model: gpt-4o\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Collecting results for model: gpt-4o\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Collected results for model_type: ocr-llm-img2txt, model: gpt-4o\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Collecting results for model: pytesseract\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Collected results for model_type: ocr-img2txt, model: pytesseract\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for model_type: llm-img2txt, model: gemini-2.5-flash\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p003\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p004\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p005\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p006\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p007\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p008\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p009\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p010\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p011\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p012\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p038\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p039\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p043\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p048\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p049\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p058\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p059\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p060\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p061\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p062\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p063\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p064\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p065\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p066\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p067\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p068\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p069\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p070\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p071\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p072\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p073\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p096\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p100\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p101\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p106\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p107\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p113\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p114\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p115\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p119\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p121\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p124\n",
      "[file retrieval] 2025-07-16 11:46:51 [INFO] Computing metrics for document: kbaa-p151\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for model_type: ocr-llm-img2txt, model: gemini-2.5-flash\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p003\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p004\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p005\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p006\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p007\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p008\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p009\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p010\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p011\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p012\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p038\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p039\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p043\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p048\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p049\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p058\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p059\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p060\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p061\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p062\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p063\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p064\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p065\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p066\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p067\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p068\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p069\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p070\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p071\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p072\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p073\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p096\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p100\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p101\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p106\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p107\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p113\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p114\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p115\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p119\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p121\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p124\n",
      "[file retrieval] 2025-07-16 11:46:55 [INFO] Computing metrics for document: kbaa-p151\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for model_type: llm-img2txt, model: gpt-4o\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p003\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p004\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p005\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p006\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p007\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p008\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p009\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p010\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p011\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p012\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p038\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p039\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p043\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p048\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p049\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p058\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p059\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p060\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p061\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p062\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p063\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p064\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p065\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p066\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p067\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p068\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p069\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p070\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p071\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p072\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p073\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p096\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p100\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p101\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p106\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p107\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p113\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p114\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p115\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p119\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p121\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p124\n",
      "[file retrieval] 2025-07-16 11:46:59 [INFO] Computing metrics for document: kbaa-p151\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for model_type: ocr-llm-img2txt, model: gpt-4o\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p003\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p004\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p005\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p006\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p007\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p008\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p009\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p010\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p011\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p012\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p038\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p039\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p043\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p048\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p049\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p058\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p059\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p060\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p061\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p062\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p063\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p064\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p065\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p066\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p067\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p068\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p069\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p070\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p071\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p072\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p073\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p096\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p100\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p101\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p106\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p107\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p113\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p114\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p115\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p119\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p121\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p124\n",
      "[file retrieval] 2025-07-16 11:47:03 [INFO] Computing metrics for document: kbaa-p151\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for model_type: ocr-img2txt, model: pytesseract\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p003\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p004\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p005\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p006\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p007\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p008\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p009\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p010\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p011\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p012\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p038\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p039\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p043\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p048\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p049\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p058\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p059\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p060\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p061\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p062\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p063\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p064\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p065\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p066\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p067\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p068\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p069\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p070\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p071\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p072\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p073\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p096\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p100\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p101\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p106\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p107\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p113\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p114\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p115\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p119\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p121\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p124\n",
      "[file retrieval] 2025-07-16 11:47:07 [INFO] Computing metrics for document: kbaa-p151\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().\n",
    "parent))\n",
    "from benchmarking.txt_accuracy import clean_text_normalized, clean_text_nonorm, compute_metrics, build_dataframe\n",
    "from tools.file_retrieval import get_doc_names, get_docs, get_all_models\n",
    "from datetime import datetime\n",
    "from venv import logger\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Prerequisites:\n",
    "    - Ground truth text files located at `project_root/ground-truth/txt/kbaa-pxyz.txt`\n",
    "    - LLM/OCR transcribed files located at:\n",
    "        - for LLM transcriptions: `project_root/results/llm_img2txt/<MODEL-NAME>/kbaa-pxyz.txt`\n",
    "        - for OCR transcriptions: `project_root/results/ocr_img2txt/<MODEL-NAME>/kbaa-pxyz.txt`\n",
    "\n",
    "    The main function will:\n",
    "    - Gather all ground truth text files\n",
    "    - For each ground truth text file and for each LLM/OCR model, gather the corresponding transcription\n",
    "    - Clean all the text files (normalized and not normalized)\n",
    "    - Compute metrics for each file and model\n",
    "    - Save results in two CSV files (one for normalized, one for non-normalized)\n",
    "        - Results are saved in `project_root/benchmarking-results/txt-accuracy`\n",
    "    \"\"\"\n",
    "\n",
    "    # =============\n",
    "    # Preliminaries\n",
    "    # =============\n",
    "\n",
    "    # args = parse_arguments()\n",
    "\n",
    "    script_dir = str(Path.cwd())\n",
    "    project_root = str(root_dir)\n",
    "    logger.info(\"Script directory: %s\", script_dir)\n",
    "    logger.info(\"Project root: %s\", project_root)\n",
    "\n",
    "    # Ground truth\n",
    "    ground_truth_dir = root_dir / \"data\" / \"ground-truth\" / \"txt\"\n",
    "    doc_names = get_doc_names(ground_truth_dir, \"txt\", keep_prefix=False)\n",
    "\n",
    "    # results/ paths\n",
    "    all_models = get_all_models(\n",
    "        \"txt\",\n",
    "        os.path.join(txt_output_dir, f\"llm-img2txt\"),\n",
    "        os.path.join(txt_output_dir, \"ocr-img2txt\"),\n",
    "        os.path.join(txt_output_dir, f\"ocr-llm-img2txt\"),\n",
    "    )\n",
    "\n",
    "    #all_models = get_all_models(\n",
    "        #\"json\",\n",
    "        #os.path.join(json_output_dir, f\"llm-img2json\"),\n",
    "        #os.path.join(json_output_dir, f\"llm-txt2json\"),\n",
    "    #)\n",
    "    logger.info(f\"Models found: {all_models}\")\n",
    "\n",
    "    # ===========\n",
    "    # Gather files\n",
    "    # ===========\n",
    "\n",
    "    # -> Gather ground truths and put into dict:\n",
    "    ground_truths, all_texts = get_docs(ground_truth_dir, doc_names, \"txt\", name_has_prefix=True)\n",
    "    ground_truths[\"__ALL__\"] = all_texts\n",
    "\n",
    "    doc_lengths_normalized = {\n",
    "        doc: len(clean_text_normalized(text)) for doc, text in ground_truths.items()\n",
    "    }\n",
    "    doc_lengths_nonorm = {\n",
    "        doc: len(clean_text_nonorm(text)) for doc, text in ground_truths.items()\n",
    "    }\n",
    "    total_doc_len_normalized = len(clean_text_normalized(ground_truths[\"__ALL__\"]))\n",
    "    total_doc_len_nonorm = len(clean_text_nonorm(ground_truths[\"__ALL__\"]))\n",
    "\n",
    "    #doc_lengths_normalized, doc_lengths_nonorm, total_doc_len_normalized, total_doc_len_nonorm = {}, {}, 0, 0\n",
    "    #for doc, json_data in ground_truths.items():\n",
    "\n",
    "        # Loop over each entry in json object array\n",
    "        #for entry in json_data[\"entries\"]:\n",
    "\n",
    "            # Loop over each field's value in the entry\n",
    "            #for text in entry.values():\n",
    "                #doc_lengths_normalized[doc] = doc_lengths_normalized.get(doc, 0) + len(entry)\n",
    "                #doc_lengths_nonorm[doc] = doc_lengths_nonorm.get(doc, 0) + len(entry)\n",
    "        \n",
    "        # Add up the totals as we go along with doc_lengths_normalized etc.\n",
    "        #total_doc_len_normalized += doc_lengths_normalized[doc]\n",
    "        #total_doc_len_nonorm += doc_lengths_nonorm[doc]\n",
    "\n",
    "    # -> Gather each transcribed document and put into dict:\n",
    "\n",
    "    # Structure: results[model][doc]\n",
    "    results = {}\n",
    "\n",
    "    for model_type, model in all_models:\n",
    "        logger.info(\"Collecting results for model: %s\", model)\n",
    "        model_path = os.path.join(txt_output_dir, model_type, model)\n",
    "        results[model_type] = results.get(model_type, {})\n",
    "        results[model_type][model], results[model_type][model][\"__ALL__\"] = get_docs(model_path, doc_names, \"txt\", name_has_prefix=False)\n",
    "        logger.info(\"Collected results for model_type: %s, model: %s\", model_type, model)\n",
    "\n",
    "    # ===============\n",
    "    # Compute metrics\n",
    "    # ===============\n",
    "\n",
    "    normalized_results_data = {}\n",
    "    nonorm_results_data = {}\n",
    "\n",
    "    for model_type, model in all_models:\n",
    "        normalized_results_data[model_type] = normalized_results_data.get(model_type, {})\n",
    "        normalized_results_data[model_type][model] = normalized_results_data[model_type].get(model, {})\n",
    "        nonorm_results_data[model_type] = nonorm_results_data.get(model_type, {})\n",
    "        nonorm_results_data[model_type][model] = nonorm_results_data[model_type].get(model, {})\n",
    "\n",
    "        logger.info(\"Computing metrics for model_type: %s, model: %s\", model_type, model)\n",
    "        for doc in doc_names:\n",
    "            logger.info(\"Computing metrics for document: %s\", doc)\n",
    "            normalized_results_data[model_type][model][doc] = compute_metrics(\n",
    "                ground_truths[doc], results[model_type][model][doc], \"txt\", normalized=True\n",
    "            )\n",
    "            nonorm_results_data[model_type][model][doc] = compute_metrics(\n",
    "                ground_truths[doc], results[model_type][model][doc], \"txt\", normalized=False\n",
    "            )\n",
    "\n",
    "        normalized_results_data[model_type][model][\"__ALL__\"] = compute_metrics(\n",
    "            ground_truths[\"__ALL__\"], results[model_type][model][\"__ALL__\"], \"txt\", normalized=True\n",
    "        )\n",
    "        nonorm_results_data[model_type][model][\"__ALL__\"] = compute_metrics(\n",
    "            ground_truths[\"__ALL__\"], results[model_type][model][\"__ALL__\"], \"txt\", normalized=False\n",
    "        )\n",
    "\n",
    "    # Compute metrics separately for __ALL__]\n",
    "\n",
    "    # ====================\n",
    "    # Put metrics in table\n",
    "    # ====================\n",
    "\n",
    "    time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    results_base_dir = root_dir / \"benchmarking-results\" / f\"txt-accuracy\"\n",
    "\n",
    "    # Create different results directory for each model type\n",
    "    for model_type, _ in all_models:\n",
    "        results_dir = results_base_dir / model_type\n",
    "        results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        normalized_df = build_dataframe(\n",
    "            f\"normalized_{time}\",\n",
    "            doc_names,\n",
    "            normalized_results_data[model_type],\n",
    "            doc_lengths_normalized,\n",
    "            total_doc_len_normalized,\n",
    "        )\n",
    "        nonorm_df = build_dataframe(\n",
    "            f\"nonorm_{time}\",\n",
    "            doc_names,\n",
    "            nonorm_results_data[model_type],\n",
    "            doc_lengths_nonorm,\n",
    "            total_doc_len_nonorm,\n",
    "        )\n",
    "\n",
    "        # ============\n",
    "        # Save results\n",
    "        # ============\n",
    "\n",
    "        # # Default save to project_root/benchmarking-results/txt-accuracy\n",
    "        # results_path = os.path.join(project_root, \"benchmarking-results\", \"txt-accuracy\")\n",
    "        # if not os.path.exists(results_path):\n",
    "        #     os.makedirs(results_path)\n",
    "        normalized_df.to_csv(os.path.join(str(results_dir), f\"normalized_{time}.csv\"))\n",
    "        nonorm_df.to_csv(os.path.join(str(results_dir), f\"nonorm_{time}.csv\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c620e",
   "metadata": {},
   "source": [
    "b. JSON benchmarking accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d409d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 17:15:08 [INFO] Project root: c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\n",
      "[file retrieval] 2025-07-16 17:15:08 [INFO] Found ground-truth txt files: ['c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p003.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p004.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p005.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p006.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p007.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p008.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p009.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p010.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p011.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p012.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p038.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p039.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p043.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p048.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p049.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p058.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p059.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p060.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p061.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p062.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p063.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p064.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p065.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p066.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p067.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p068.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p069.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p070.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p071.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p072.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p073.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p096.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p100.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p101.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p106.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p107.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p113.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p114.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p115.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p119.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p121.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p124.json', 'c:\\\\Users\\\\vriez\\\\OneDrive\\\\Desktop\\\\Summer MAP\\\\ocr-benchmarking-1\\\\data\\\\ground-truth\\\\json\\\\gt_kbaa-p151.json']\n",
      "[file retrieval] 2025-07-16 17:15:08 [INFO] Found file names: ['gt_kbaa-p003', 'gt_kbaa-p004', 'gt_kbaa-p005', 'gt_kbaa-p006', 'gt_kbaa-p007', 'gt_kbaa-p008', 'gt_kbaa-p009', 'gt_kbaa-p010', 'gt_kbaa-p011', 'gt_kbaa-p012', 'gt_kbaa-p038', 'gt_kbaa-p039', 'gt_kbaa-p043', 'gt_kbaa-p048', 'gt_kbaa-p049', 'gt_kbaa-p058', 'gt_kbaa-p059', 'gt_kbaa-p060', 'gt_kbaa-p061', 'gt_kbaa-p062', 'gt_kbaa-p063', 'gt_kbaa-p064', 'gt_kbaa-p065', 'gt_kbaa-p066', 'gt_kbaa-p067', 'gt_kbaa-p068', 'gt_kbaa-p069', 'gt_kbaa-p070', 'gt_kbaa-p071', 'gt_kbaa-p072', 'gt_kbaa-p073', 'gt_kbaa-p096', 'gt_kbaa-p100', 'gt_kbaa-p101', 'gt_kbaa-p106', 'gt_kbaa-p107', 'gt_kbaa-p113', 'gt_kbaa-p114', 'gt_kbaa-p115', 'gt_kbaa-p119', 'gt_kbaa-p121', 'gt_kbaa-p124', 'gt_kbaa-p151']\n",
      "[file retrieval] 2025-07-16 17:15:08 [INFO] Models found: [('llm-img2json', 'gemini-2.5-flash'), ('llm-txt2json', 'gemini-2.5-flash'), ('llm-img2json', 'gpt-4o'), ('llm-txt2json', 'gpt-4o')]\n",
      "[file retrieval] 2025-07-16 17:15:11 [INFO] Collected ground truth results: ['kbaa-p003', 'kbaa-p004', 'kbaa-p005', 'kbaa-p006', 'kbaa-p007', 'kbaa-p008', 'kbaa-p009', 'kbaa-p010', 'kbaa-p011', 'kbaa-p012', 'kbaa-p038', 'kbaa-p039', 'kbaa-p043', 'kbaa-p048', 'kbaa-p049', 'kbaa-p058', 'kbaa-p059', 'kbaa-p060', 'kbaa-p061', 'kbaa-p062', 'kbaa-p063', 'kbaa-p064', 'kbaa-p065', 'kbaa-p066', 'kbaa-p067', 'kbaa-p068', 'kbaa-p069', 'kbaa-p070', 'kbaa-p071', 'kbaa-p072', 'kbaa-p073', 'kbaa-p096', 'kbaa-p100', 'kbaa-p101', 'kbaa-p106', 'kbaa-p107', 'kbaa-p113', 'kbaa-p114', 'kbaa-p115', 'kbaa-p119', 'kbaa-p121', 'kbaa-p124', 'kbaa-p151']\n",
      "[file retrieval] 2025-07-16 17:15:11 [INFO] Converted ground truths to dataframes\n",
      "[file retrieval] 2025-07-16 17:15:11 [INFO] Collecting results for model: llm-img2json/gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-img2json\\gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 17:15:13 [INFO] Collected results for model: ['kbaa-p003', 'kbaa-p004', 'kbaa-p005', 'kbaa-p006', 'kbaa-p007', 'kbaa-p008', 'kbaa-p009', 'kbaa-p010', 'kbaa-p011', 'kbaa-p012', 'kbaa-p038', 'kbaa-p039', 'kbaa-p043', 'kbaa-p048', 'kbaa-p049', 'kbaa-p058', 'kbaa-p059', 'kbaa-p060', 'kbaa-p061', 'kbaa-p062', 'kbaa-p063', 'kbaa-p064', 'kbaa-p065', 'kbaa-p066', 'kbaa-p067', 'kbaa-p068', 'kbaa-p069', 'kbaa-p070', 'kbaa-p071', 'kbaa-p072', 'kbaa-p073', 'kbaa-p096', 'kbaa-p100', 'kbaa-p101', 'kbaa-p106', 'kbaa-p107', 'kbaa-p113', 'kbaa-p114', 'kbaa-p115', 'kbaa-p119', 'kbaa-p121', 'kbaa-p124', 'kbaa-p151']\n",
      "[file retrieval] 2025-07-16 17:15:13 [INFO] Converted results to dataframes\n",
      "[file retrieval] 2025-07-16 17:15:13 [INFO] Collecting results for model: llm-txt2json/gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-txt2json\\gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 17:15:15 [INFO] Collected results for model: ['kbaa-p003', 'kbaa-p004', 'kbaa-p005', 'kbaa-p006', 'kbaa-p007', 'kbaa-p008', 'kbaa-p009', 'kbaa-p010', 'kbaa-p011', 'kbaa-p012', 'kbaa-p038', 'kbaa-p039', 'kbaa-p043', 'kbaa-p048', 'kbaa-p049', 'kbaa-p058', 'kbaa-p059', 'kbaa-p060', 'kbaa-p061', 'kbaa-p062', 'kbaa-p063', 'kbaa-p064', 'kbaa-p065', 'kbaa-p066', 'kbaa-p067', 'kbaa-p068', 'kbaa-p069', 'kbaa-p070', 'kbaa-p071', 'kbaa-p072', 'kbaa-p073', 'kbaa-p096', 'kbaa-p100', 'kbaa-p101', 'kbaa-p106', 'kbaa-p107', 'kbaa-p113', 'kbaa-p114', 'kbaa-p115', 'kbaa-p119', 'kbaa-p121', 'kbaa-p124', 'kbaa-p151']\n",
      "[file retrieval] 2025-07-16 17:15:15 [INFO] Converted results to dataframes\n",
      "[file retrieval] 2025-07-16 17:15:15 [INFO] Collecting results for model: llm-img2json/gpt-4o\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-img2json\\gpt-4o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 17:15:17 [INFO] Collected results for model: ['kbaa-p003', 'kbaa-p004', 'kbaa-p005', 'kbaa-p006', 'kbaa-p007', 'kbaa-p008', 'kbaa-p009', 'kbaa-p010', 'kbaa-p011', 'kbaa-p012', 'kbaa-p038', 'kbaa-p039', 'kbaa-p043', 'kbaa-p048', 'kbaa-p049', 'kbaa-p058', 'kbaa-p059', 'kbaa-p060', 'kbaa-p061', 'kbaa-p062', 'kbaa-p063', 'kbaa-p064', 'kbaa-p065', 'kbaa-p066', 'kbaa-p067', 'kbaa-p068', 'kbaa-p069', 'kbaa-p070', 'kbaa-p071', 'kbaa-p072', 'kbaa-p073', 'kbaa-p096', 'kbaa-p100', 'kbaa-p101', 'kbaa-p106', 'kbaa-p107', 'kbaa-p113', 'kbaa-p114', 'kbaa-p115', 'kbaa-p119', 'kbaa-p121', 'kbaa-p124', 'kbaa-p151']\n",
      "[file retrieval] 2025-07-16 17:15:17 [INFO] Converted results to dataframes\n",
      "[file retrieval] 2025-07-16 17:15:17 [INFO] Collecting results for model: llm-txt2json/gpt-4o\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vriez\\OneDrive\\Desktop\\Summer MAP\\ocr-benchmarking-1\\results\\json\\llm-txt2json\\gpt-4o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[file retrieval] 2025-07-16 17:15:20 [INFO] Collected results for model: ['kbaa-p003', 'kbaa-p004', 'kbaa-p005', 'kbaa-p006', 'kbaa-p007', 'kbaa-p008', 'kbaa-p009', 'kbaa-p010', 'kbaa-p011', 'kbaa-p012', 'kbaa-p038', 'kbaa-p039', 'kbaa-p043', 'kbaa-p048', 'kbaa-p049', 'kbaa-p058', 'kbaa-p059', 'kbaa-p060', 'kbaa-p061', 'kbaa-p062', 'kbaa-p063', 'kbaa-p064', 'kbaa-p065', 'kbaa-p066', 'kbaa-p067', 'kbaa-p068', 'kbaa-p069', 'kbaa-p070', 'kbaa-p071', 'kbaa-p072', 'kbaa-p073', 'kbaa-p096', 'kbaa-p100', 'kbaa-p101', 'kbaa-p106', 'kbaa-p107', 'kbaa-p113', 'kbaa-p114', 'kbaa-p115', 'kbaa-p119', 'kbaa-p121', 'kbaa-p124', 'kbaa-p151']\n",
      "[file retrieval] 2025-07-16 17:15:20 [INFO] Converted results to dataframes\n",
      "[file retrieval] 2025-07-16 17:15:20 [INFO] Computing metrics for model: gemini-2.5-flash\n",
      "[file retrieval] 2025-07-16 17:15:20 [INFO] Computing metrics for document: kbaa-p003\n",
      "[file retrieval] 2025-07-16 17:15:20 [INFO] Computing metrics for document: kbaa-p004\n",
      "[file retrieval] 2025-07-16 17:15:20 [INFO] Computing metrics for document: kbaa-p005\n",
      "[file retrieval] 2025-07-16 17:15:20 [INFO] Computing metrics for document: kbaa-p006\n",
      "[file retrieval] 2025-07-16 17:15:20 [INFO] Computing metrics for document: kbaa-p007\n",
      "[file retrieval] 2025-07-16 17:15:21 [INFO] Computing metrics for document: kbaa-p008\n",
      "[file retrieval] 2025-07-16 17:15:21 [INFO] Computing metrics for document: kbaa-p009\n",
      "[file retrieval] 2025-07-16 17:15:21 [INFO] Computing metrics for document: kbaa-p010\n",
      "[file retrieval] 2025-07-16 17:15:21 [INFO] Computing metrics for document: kbaa-p011\n",
      "[file retrieval] 2025-07-16 17:15:21 [INFO] Computing metrics for document: kbaa-p012\n",
      "[file retrieval] 2025-07-16 17:15:21 [INFO] Computing metrics for document: kbaa-p038\n",
      "[file retrieval] 2025-07-16 17:15:21 [INFO] Computing metrics for document: kbaa-p039\n",
      "[file retrieval] 2025-07-16 17:15:21 [INFO] Computing metrics for document: kbaa-p043\n",
      "[file retrieval] 2025-07-16 17:15:22 [INFO] Computing metrics for document: kbaa-p048\n",
      "[file retrieval] 2025-07-16 17:15:22 [INFO] Computing metrics for document: kbaa-p049\n",
      "[file retrieval] 2025-07-16 17:15:22 [INFO] Computing metrics for document: kbaa-p058\n",
      "[file retrieval] 2025-07-16 17:15:22 [INFO] Computing metrics for document: kbaa-p059\n",
      "[file retrieval] 2025-07-16 17:15:22 [INFO] Computing metrics for document: kbaa-p060\n",
      "[file retrieval] 2025-07-16 17:15:22 [INFO] Computing metrics for document: kbaa-p061\n",
      "[file retrieval] 2025-07-16 17:15:22 [INFO] Computing metrics for document: kbaa-p062\n",
      "[file retrieval] 2025-07-16 17:15:22 [INFO] Computing metrics for document: kbaa-p063\n",
      "[file retrieval] 2025-07-16 17:15:22 [INFO] Computing metrics for document: kbaa-p064\n",
      "[file retrieval] 2025-07-16 17:15:22 [INFO] Computing metrics for document: kbaa-p065\n",
      "[file retrieval] 2025-07-16 17:15:23 [INFO] Computing metrics for document: kbaa-p066\n",
      "[file retrieval] 2025-07-16 17:15:23 [INFO] Computing metrics for document: kbaa-p067\n",
      "[file retrieval] 2025-07-16 17:15:23 [INFO] Computing metrics for document: kbaa-p068\n",
      "[file retrieval] 2025-07-16 17:15:23 [INFO] Computing metrics for document: kbaa-p069\n",
      "[file retrieval] 2025-07-16 17:15:23 [INFO] Computing metrics for document: kbaa-p070\n",
      "[file retrieval] 2025-07-16 17:15:23 [INFO] Computing metrics for document: kbaa-p071\n",
      "[file retrieval] 2025-07-16 17:15:23 [INFO] Computing metrics for document: kbaa-p072\n",
      "[file retrieval] 2025-07-16 17:15:23 [INFO] Computing metrics for document: kbaa-p073\n",
      "[file retrieval] 2025-07-16 17:15:23 [INFO] Computing metrics for document: kbaa-p096\n",
      "[file retrieval] 2025-07-16 17:15:23 [INFO] Computing metrics for document: kbaa-p100\n",
      "[file retrieval] 2025-07-16 17:15:23 [INFO] Computing metrics for document: kbaa-p101\n",
      "[file retrieval] 2025-07-16 17:15:24 [INFO] Computing metrics for document: kbaa-p106\n",
      "[file retrieval] 2025-07-16 17:15:24 [INFO] Computing metrics for document: kbaa-p107\n",
      "[file retrieval] 2025-07-16 17:15:24 [INFO] Computing metrics for document: kbaa-p113\n",
      "[file retrieval] 2025-07-16 17:15:24 [INFO] Computing metrics for document: kbaa-p114\n",
      "[file retrieval] 2025-07-16 17:15:24 [INFO] Computing metrics for document: kbaa-p115\n",
      "[file retrieval] 2025-07-16 17:15:24 [INFO] Computing metrics for document: kbaa-p119\n",
      "[file retrieval] 2025-07-16 17:15:24 [INFO] Computing metrics for document: kbaa-p121\n",
      "[file retrieval] 2025-07-16 17:15:24 [INFO] Computing metrics for document: kbaa-p124\n",
      "[file retrieval] 2025-07-16 17:15:25 [INFO] Computing metrics for document: kbaa-p151\n",
      "[file retrieval] 2025-07-16 17:15:25 [INFO] Computing metrics for model: gemini-2.5-flash\n",
      "[file retrieval] 2025-07-16 17:15:25 [INFO] Computing metrics for document: kbaa-p003\n",
      "[file retrieval] 2025-07-16 17:15:25 [INFO] Computing metrics for document: kbaa-p004\n",
      "[file retrieval] 2025-07-16 17:15:25 [INFO] Computing metrics for document: kbaa-p005\n",
      "[file retrieval] 2025-07-16 17:15:25 [INFO] Computing metrics for document: kbaa-p006\n",
      "[file retrieval] 2025-07-16 17:15:25 [INFO] Computing metrics for document: kbaa-p007\n",
      "[file retrieval] 2025-07-16 17:15:25 [INFO] Computing metrics for document: kbaa-p008\n",
      "[file retrieval] 2025-07-16 17:15:25 [INFO] Computing metrics for document: kbaa-p009\n",
      "[file retrieval] 2025-07-16 17:15:25 [INFO] Computing metrics for document: kbaa-p010\n",
      "[file retrieval] 2025-07-16 17:15:26 [INFO] Computing metrics for document: kbaa-p011\n",
      "[file retrieval] 2025-07-16 17:15:26 [INFO] Computing metrics for document: kbaa-p012\n",
      "[file retrieval] 2025-07-16 17:15:26 [INFO] Computing metrics for document: kbaa-p038\n",
      "[file retrieval] 2025-07-16 17:15:26 [INFO] Computing metrics for document: kbaa-p039\n",
      "[file retrieval] 2025-07-16 17:15:26 [INFO] Computing metrics for document: kbaa-p043\n",
      "[file retrieval] 2025-07-16 17:15:26 [INFO] Computing metrics for document: kbaa-p048\n",
      "[file retrieval] 2025-07-16 17:15:26 [INFO] Computing metrics for document: kbaa-p049\n",
      "[file retrieval] 2025-07-16 17:15:26 [INFO] Computing metrics for document: kbaa-p058\n",
      "[file retrieval] 2025-07-16 17:15:26 [INFO] Computing metrics for document: kbaa-p059\n",
      "[file retrieval] 2025-07-16 17:15:26 [INFO] Computing metrics for document: kbaa-p060\n",
      "[file retrieval] 2025-07-16 17:15:27 [INFO] Computing metrics for document: kbaa-p061\n",
      "[file retrieval] 2025-07-16 17:15:27 [INFO] Computing metrics for document: kbaa-p062\n",
      "[file retrieval] 2025-07-16 17:15:27 [INFO] Computing metrics for document: kbaa-p063\n",
      "[file retrieval] 2025-07-16 17:15:27 [INFO] Computing metrics for document: kbaa-p064\n",
      "[file retrieval] 2025-07-16 17:15:27 [INFO] Computing metrics for document: kbaa-p065\n",
      "[file retrieval] 2025-07-16 17:15:27 [INFO] Computing metrics for document: kbaa-p066\n",
      "[file retrieval] 2025-07-16 17:15:27 [INFO] Computing metrics for document: kbaa-p067\n",
      "[file retrieval] 2025-07-16 17:15:27 [INFO] Computing metrics for document: kbaa-p068\n",
      "[file retrieval] 2025-07-16 17:15:27 [INFO] Computing metrics for document: kbaa-p069\n",
      "[file retrieval] 2025-07-16 17:15:28 [INFO] Computing metrics for document: kbaa-p070\n",
      "[file retrieval] 2025-07-16 17:15:28 [INFO] Computing metrics for document: kbaa-p071\n",
      "[file retrieval] 2025-07-16 17:15:28 [INFO] Computing metrics for document: kbaa-p072\n",
      "[file retrieval] 2025-07-16 17:15:28 [INFO] Computing metrics for document: kbaa-p073\n",
      "[file retrieval] 2025-07-16 17:15:28 [INFO] Computing metrics for document: kbaa-p096\n",
      "[file retrieval] 2025-07-16 17:15:28 [INFO] Computing metrics for document: kbaa-p100\n",
      "[file retrieval] 2025-07-16 17:15:28 [INFO] Computing metrics for document: kbaa-p101\n",
      "[file retrieval] 2025-07-16 17:15:28 [INFO] Computing metrics for document: kbaa-p106\n",
      "[file retrieval] 2025-07-16 17:15:28 [INFO] Computing metrics for document: kbaa-p107\n",
      "[file retrieval] 2025-07-16 17:15:28 [INFO] Computing metrics for document: kbaa-p113\n",
      "[file retrieval] 2025-07-16 17:15:28 [INFO] Computing metrics for document: kbaa-p114\n",
      "[file retrieval] 2025-07-16 17:15:29 [INFO] Computing metrics for document: kbaa-p115\n",
      "[file retrieval] 2025-07-16 17:15:29 [INFO] Computing metrics for document: kbaa-p119\n",
      "[file retrieval] 2025-07-16 17:15:29 [INFO] Computing metrics for document: kbaa-p121\n",
      "[file retrieval] 2025-07-16 17:15:29 [INFO] Computing metrics for document: kbaa-p124\n",
      "[file retrieval] 2025-07-16 17:15:29 [INFO] Computing metrics for document: kbaa-p151\n",
      "[file retrieval] 2025-07-16 17:15:29 [INFO] Computing metrics for model: gpt-4o\n",
      "[file retrieval] 2025-07-16 17:15:29 [INFO] Computing metrics for document: kbaa-p003\n",
      "[file retrieval] 2025-07-16 17:15:29 [INFO] Computing metrics for document: kbaa-p004\n",
      "[file retrieval] 2025-07-16 17:15:29 [INFO] Computing metrics for document: kbaa-p005\n",
      "[file retrieval] 2025-07-16 17:15:29 [INFO] Computing metrics for document: kbaa-p006\n",
      "[file retrieval] 2025-07-16 17:15:30 [INFO] Computing metrics for document: kbaa-p007\n",
      "[file retrieval] 2025-07-16 17:15:30 [INFO] Computing metrics for document: kbaa-p008\n",
      "[file retrieval] 2025-07-16 17:15:30 [INFO] Computing metrics for document: kbaa-p009\n",
      "[file retrieval] 2025-07-16 17:15:30 [INFO] Computing metrics for document: kbaa-p010\n",
      "[file retrieval] 2025-07-16 17:15:30 [INFO] Computing metrics for document: kbaa-p011\n",
      "[file retrieval] 2025-07-16 17:15:30 [INFO] Computing metrics for document: kbaa-p012\n",
      "[file retrieval] 2025-07-16 17:15:30 [INFO] Computing metrics for document: kbaa-p038\n",
      "[file retrieval] 2025-07-16 17:15:30 [INFO] Computing metrics for document: kbaa-p039\n",
      "[file retrieval] 2025-07-16 17:15:30 [INFO] Computing metrics for document: kbaa-p043\n",
      "[file retrieval] 2025-07-16 17:15:30 [INFO] Computing metrics for document: kbaa-p048\n",
      "[file retrieval] 2025-07-16 17:15:30 [INFO] Computing metrics for document: kbaa-p049\n",
      "[file retrieval] 2025-07-16 17:15:30 [INFO] Computing metrics for document: kbaa-p058\n",
      "[file retrieval] 2025-07-16 17:15:30 [INFO] Computing metrics for document: kbaa-p059\n",
      "[file retrieval] 2025-07-16 17:15:31 [INFO] Computing metrics for document: kbaa-p060\n",
      "[file retrieval] 2025-07-16 17:15:31 [INFO] Computing metrics for document: kbaa-p061\n",
      "[file retrieval] 2025-07-16 17:15:31 [INFO] Computing metrics for document: kbaa-p062\n",
      "[file retrieval] 2025-07-16 17:15:31 [INFO] Computing metrics for document: kbaa-p063\n",
      "[file retrieval] 2025-07-16 17:15:31 [INFO] Computing metrics for document: kbaa-p064\n",
      "[file retrieval] 2025-07-16 17:15:31 [INFO] Computing metrics for document: kbaa-p065\n",
      "[file retrieval] 2025-07-16 17:15:31 [INFO] Computing metrics for document: kbaa-p066\n",
      "[file retrieval] 2025-07-16 17:15:31 [INFO] Computing metrics for document: kbaa-p067\n",
      "[file retrieval] 2025-07-16 17:15:31 [INFO] Computing metrics for document: kbaa-p068\n",
      "[file retrieval] 2025-07-16 17:15:31 [INFO] Computing metrics for document: kbaa-p069\n",
      "[file retrieval] 2025-07-16 17:15:31 [INFO] Computing metrics for document: kbaa-p070\n",
      "[file retrieval] 2025-07-16 17:15:31 [INFO] Computing metrics for document: kbaa-p071\n",
      "[file retrieval] 2025-07-16 17:15:32 [INFO] Computing metrics for document: kbaa-p072\n",
      "[file retrieval] 2025-07-16 17:15:32 [INFO] Computing metrics for document: kbaa-p073\n",
      "[file retrieval] 2025-07-16 17:15:32 [INFO] Computing metrics for document: kbaa-p096\n",
      "[file retrieval] 2025-07-16 17:15:32 [INFO] Computing metrics for document: kbaa-p100\n",
      "[file retrieval] 2025-07-16 17:15:32 [INFO] Computing metrics for document: kbaa-p101\n",
      "[file retrieval] 2025-07-16 17:15:32 [INFO] Computing metrics for document: kbaa-p106\n",
      "[file retrieval] 2025-07-16 17:15:32 [INFO] Computing metrics for document: kbaa-p107\n",
      "[file retrieval] 2025-07-16 17:15:32 [INFO] Computing metrics for document: kbaa-p113\n",
      "[file retrieval] 2025-07-16 17:15:32 [INFO] Computing metrics for document: kbaa-p114\n",
      "[file retrieval] 2025-07-16 17:15:32 [INFO] Computing metrics for document: kbaa-p115\n",
      "[file retrieval] 2025-07-16 17:15:32 [INFO] Computing metrics for document: kbaa-p119\n",
      "[file retrieval] 2025-07-16 17:15:33 [INFO] Computing metrics for document: kbaa-p121\n",
      "[file retrieval] 2025-07-16 17:15:33 [INFO] Computing metrics for document: kbaa-p124\n",
      "[file retrieval] 2025-07-16 17:15:33 [INFO] Computing metrics for document: kbaa-p151\n",
      "[file retrieval] 2025-07-16 17:15:33 [INFO] Computing metrics for model: gpt-4o\n",
      "[file retrieval] 2025-07-16 17:15:33 [INFO] Computing metrics for document: kbaa-p003\n",
      "[file retrieval] 2025-07-16 17:15:33 [INFO] Computing metrics for document: kbaa-p004\n",
      "[file retrieval] 2025-07-16 17:15:33 [INFO] Computing metrics for document: kbaa-p005\n",
      "[file retrieval] 2025-07-16 17:15:33 [INFO] Computing metrics for document: kbaa-p006\n",
      "[file retrieval] 2025-07-16 17:15:33 [INFO] Computing metrics for document: kbaa-p007\n",
      "[file retrieval] 2025-07-16 17:15:33 [INFO] Computing metrics for document: kbaa-p008\n",
      "[file retrieval] 2025-07-16 17:15:33 [INFO] Computing metrics for document: kbaa-p009\n",
      "[file retrieval] 2025-07-16 17:15:33 [INFO] Computing metrics for document: kbaa-p010\n",
      "[file retrieval] 2025-07-16 17:15:33 [INFO] Computing metrics for document: kbaa-p011\n",
      "[file retrieval] 2025-07-16 17:15:34 [INFO] Computing metrics for document: kbaa-p012\n",
      "[file retrieval] 2025-07-16 17:15:34 [INFO] Computing metrics for document: kbaa-p038\n",
      "[file retrieval] 2025-07-16 17:15:34 [INFO] Computing metrics for document: kbaa-p039\n",
      "[file retrieval] 2025-07-16 17:15:34 [INFO] Computing metrics for document: kbaa-p043\n",
      "[file retrieval] 2025-07-16 17:15:34 [INFO] Computing metrics for document: kbaa-p048\n",
      "[file retrieval] 2025-07-16 17:15:34 [INFO] Computing metrics for document: kbaa-p049\n",
      "[file retrieval] 2025-07-16 17:15:34 [INFO] Computing metrics for document: kbaa-p058\n",
      "[file retrieval] 2025-07-16 17:15:34 [INFO] Computing metrics for document: kbaa-p059\n",
      "[file retrieval] 2025-07-16 17:15:34 [INFO] Computing metrics for document: kbaa-p060\n",
      "[file retrieval] 2025-07-16 17:15:34 [INFO] Computing metrics for document: kbaa-p061\n",
      "[file retrieval] 2025-07-16 17:15:34 [INFO] Computing metrics for document: kbaa-p062\n",
      "[file retrieval] 2025-07-16 17:15:34 [INFO] Computing metrics for document: kbaa-p063\n",
      "[file retrieval] 2025-07-16 17:15:35 [INFO] Computing metrics for document: kbaa-p064\n",
      "[file retrieval] 2025-07-16 17:15:35 [INFO] Computing metrics for document: kbaa-p065\n",
      "[file retrieval] 2025-07-16 17:15:35 [INFO] Computing metrics for document: kbaa-p066\n",
      "[file retrieval] 2025-07-16 17:15:35 [INFO] Computing metrics for document: kbaa-p067\n",
      "[file retrieval] 2025-07-16 17:15:35 [INFO] Computing metrics for document: kbaa-p068\n",
      "[file retrieval] 2025-07-16 17:15:35 [INFO] Computing metrics for document: kbaa-p069\n",
      "[file retrieval] 2025-07-16 17:15:35 [INFO] Computing metrics for document: kbaa-p070\n",
      "[file retrieval] 2025-07-16 17:15:35 [INFO] Computing metrics for document: kbaa-p071\n",
      "[file retrieval] 2025-07-16 17:15:35 [INFO] Computing metrics for document: kbaa-p072\n",
      "[file retrieval] 2025-07-16 17:15:35 [INFO] Computing metrics for document: kbaa-p073\n",
      "[file retrieval] 2025-07-16 17:15:35 [INFO] Computing metrics for document: kbaa-p096\n",
      "[file retrieval] 2025-07-16 17:15:35 [INFO] Computing metrics for document: kbaa-p100\n",
      "[file retrieval] 2025-07-16 17:15:36 [INFO] Computing metrics for document: kbaa-p101\n",
      "[file retrieval] 2025-07-16 17:15:36 [INFO] Computing metrics for document: kbaa-p106\n",
      "[file retrieval] 2025-07-16 17:15:36 [INFO] Computing metrics for document: kbaa-p107\n",
      "[file retrieval] 2025-07-16 17:15:36 [INFO] Computing metrics for document: kbaa-p113\n",
      "[file retrieval] 2025-07-16 17:15:36 [INFO] Computing metrics for document: kbaa-p114\n",
      "[file retrieval] 2025-07-16 17:15:36 [INFO] Computing metrics for document: kbaa-p115\n",
      "[file retrieval] 2025-07-16 17:15:36 [INFO] Computing metrics for document: kbaa-p119\n",
      "[file retrieval] 2025-07-16 17:15:36 [INFO] Computing metrics for document: kbaa-p121\n",
      "[file retrieval] 2025-07-16 17:15:36 [INFO] Computing metrics for document: kbaa-p124\n",
      "[file retrieval] 2025-07-16 17:15:37 [INFO] Computing metrics for document: kbaa-p151\n",
      "[file retrieval] 2025-07-16 17:15:37 [INFO] Building dataframe \"llm-img2json_normalized_2025-07-16_17-15-37\" with documents ['kbaa-p003', 'kbaa-p004', 'kbaa-p005', 'kbaa-p006', 'kbaa-p007', 'kbaa-p008', 'kbaa-p009', 'kbaa-p010', 'kbaa-p011', 'kbaa-p012', 'kbaa-p038', 'kbaa-p039', 'kbaa-p043', 'kbaa-p048', 'kbaa-p049', 'kbaa-p058', 'kbaa-p059', 'kbaa-p060', 'kbaa-p061', 'kbaa-p062', 'kbaa-p063', 'kbaa-p064', 'kbaa-p065', 'kbaa-p066', 'kbaa-p067', 'kbaa-p068', 'kbaa-p069', 'kbaa-p070', 'kbaa-p071', 'kbaa-p072', 'kbaa-p073', 'kbaa-p096', 'kbaa-p100', 'kbaa-p101', 'kbaa-p106', 'kbaa-p107', 'kbaa-p113', 'kbaa-p114', 'kbaa-p115', 'kbaa-p119', 'kbaa-p121', 'kbaa-p124', 'kbaa-p151']\n",
      "[file retrieval] 2025-07-16 17:15:37 [INFO] Building dataframe \"llm-img2json_nonorm_2025-07-16_17-15-37\" with documents ['kbaa-p003', 'kbaa-p004', 'kbaa-p005', 'kbaa-p006', 'kbaa-p007', 'kbaa-p008', 'kbaa-p009', 'kbaa-p010', 'kbaa-p011', 'kbaa-p012', 'kbaa-p038', 'kbaa-p039', 'kbaa-p043', 'kbaa-p048', 'kbaa-p049', 'kbaa-p058', 'kbaa-p059', 'kbaa-p060', 'kbaa-p061', 'kbaa-p062', 'kbaa-p063', 'kbaa-p064', 'kbaa-p065', 'kbaa-p066', 'kbaa-p067', 'kbaa-p068', 'kbaa-p069', 'kbaa-p070', 'kbaa-p071', 'kbaa-p072', 'kbaa-p073', 'kbaa-p096', 'kbaa-p100', 'kbaa-p101', 'kbaa-p106', 'kbaa-p107', 'kbaa-p113', 'kbaa-p114', 'kbaa-p115', 'kbaa-p119', 'kbaa-p121', 'kbaa-p124', 'kbaa-p151']\n",
      "[file retrieval] 2025-07-16 17:15:38 [INFO] Building dataframe \"llm-img2json_fuzzy_2025-07-16_17-15-37\" with documents ['kbaa-p003', 'kbaa-p004', 'kbaa-p005', 'kbaa-p006', 'kbaa-p007', 'kbaa-p008', 'kbaa-p009', 'kbaa-p010', 'kbaa-p011', 'kbaa-p012', 'kbaa-p038', 'kbaa-p039', 'kbaa-p043', 'kbaa-p048', 'kbaa-p049', 'kbaa-p058', 'kbaa-p059', 'kbaa-p060', 'kbaa-p061', 'kbaa-p062', 'kbaa-p063', 'kbaa-p064', 'kbaa-p065', 'kbaa-p066', 'kbaa-p067', 'kbaa-p068', 'kbaa-p069', 'kbaa-p070', 'kbaa-p071', 'kbaa-p072', 'kbaa-p073', 'kbaa-p096', 'kbaa-p100', 'kbaa-p101', 'kbaa-p106', 'kbaa-p107', 'kbaa-p113', 'kbaa-p114', 'kbaa-p115', 'kbaa-p119', 'kbaa-p121', 'kbaa-p124', 'kbaa-p151']\n",
      "[file retrieval] 2025-07-16 17:15:38 [INFO] Building dataframe \"llm-txt2json_normalized_2025-07-16_17-15-37\" with documents ['kbaa-p003', 'kbaa-p004', 'kbaa-p005', 'kbaa-p006', 'kbaa-p007', 'kbaa-p008', 'kbaa-p009', 'kbaa-p010', 'kbaa-p011', 'kbaa-p012', 'kbaa-p038', 'kbaa-p039', 'kbaa-p043', 'kbaa-p048', 'kbaa-p049', 'kbaa-p058', 'kbaa-p059', 'kbaa-p060', 'kbaa-p061', 'kbaa-p062', 'kbaa-p063', 'kbaa-p064', 'kbaa-p065', 'kbaa-p066', 'kbaa-p067', 'kbaa-p068', 'kbaa-p069', 'kbaa-p070', 'kbaa-p071', 'kbaa-p072', 'kbaa-p073', 'kbaa-p096', 'kbaa-p100', 'kbaa-p101', 'kbaa-p106', 'kbaa-p107', 'kbaa-p113', 'kbaa-p114', 'kbaa-p115', 'kbaa-p119', 'kbaa-p121', 'kbaa-p124', 'kbaa-p151']\n",
      "[file retrieval] 2025-07-16 17:15:38 [INFO] Building dataframe \"llm-txt2json_nonorm_2025-07-16_17-15-37\" with documents ['kbaa-p003', 'kbaa-p004', 'kbaa-p005', 'kbaa-p006', 'kbaa-p007', 'kbaa-p008', 'kbaa-p009', 'kbaa-p010', 'kbaa-p011', 'kbaa-p012', 'kbaa-p038', 'kbaa-p039', 'kbaa-p043', 'kbaa-p048', 'kbaa-p049', 'kbaa-p058', 'kbaa-p059', 'kbaa-p060', 'kbaa-p061', 'kbaa-p062', 'kbaa-p063', 'kbaa-p064', 'kbaa-p065', 'kbaa-p066', 'kbaa-p067', 'kbaa-p068', 'kbaa-p069', 'kbaa-p070', 'kbaa-p071', 'kbaa-p072', 'kbaa-p073', 'kbaa-p096', 'kbaa-p100', 'kbaa-p101', 'kbaa-p106', 'kbaa-p107', 'kbaa-p113', 'kbaa-p114', 'kbaa-p115', 'kbaa-p119', 'kbaa-p121', 'kbaa-p124', 'kbaa-p151']\n",
      "[file retrieval] 2025-07-16 17:15:39 [INFO] Building dataframe \"llm-txt2json_fuzzy_2025-07-16_17-15-37\" with documents ['kbaa-p003', 'kbaa-p004', 'kbaa-p005', 'kbaa-p006', 'kbaa-p007', 'kbaa-p008', 'kbaa-p009', 'kbaa-p010', 'kbaa-p011', 'kbaa-p012', 'kbaa-p038', 'kbaa-p039', 'kbaa-p043', 'kbaa-p048', 'kbaa-p049', 'kbaa-p058', 'kbaa-p059', 'kbaa-p060', 'kbaa-p061', 'kbaa-p062', 'kbaa-p063', 'kbaa-p064', 'kbaa-p065', 'kbaa-p066', 'kbaa-p067', 'kbaa-p068', 'kbaa-p069', 'kbaa-p070', 'kbaa-p071', 'kbaa-p072', 'kbaa-p073', 'kbaa-p096', 'kbaa-p100', 'kbaa-p101', 'kbaa-p106', 'kbaa-p107', 'kbaa-p113', 'kbaa-p114', 'kbaa-p115', 'kbaa-p119', 'kbaa-p121', 'kbaa-p124', 'kbaa-p151']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().\n",
    "parent))\n",
    "from benchmarking.json_accuracy import filter_expected_columns, build_dataframe, compare_dataframes_normalized, compare_dataframes_exact, compare_dataframes_fuzzy\n",
    "from tools.file_retrieval import get_doc_names, get_docs, get_all_models\n",
    "from venv import logger\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Prerequisites:\n",
    "    - Ground truth JSON files located at `project_root/ground-truth/json/gt_kbaa-pXYZ.json`\n",
    "    - LLM/OCR transcribed JSON files located at:\n",
    "        - for ground truth text to JSON via LLM:\n",
    "            - `project_root/results/gt-txt2json/<MODEL-NAME>/<MODEL-NAME>_img_kbaa-pXYZ.json`\n",
    "        - for OCR text to JSON via LLM:\n",
    "            - `project_root/results/ocr-txt2json/<MODEL-NAME>/<MODEL-NAME>_img_kbaa-pXYZ.json`\n",
    "        - for image to JSON via LLM:\n",
    "            - `project_root/results/llm-img2json/<MODEL-NAME>/<MODEL-NAME>_img_kbaa-pXYZ.json`\n",
    "        - for text to JSON via LLM:\n",
    "            - `project_root/results/llm-txt2json/<MODEL-NAME>/<MODEL-NAME>_img_kbaa-pXYZ.json`\n",
    "\n",
    "    The main function will:\n",
    "    - Gather all ground truth JSON files\n",
    "    - For each ground truth JSON file and for each LLM/OCR model, open the JSON file's entries object as a Pandas dataframe\n",
    "    - Clean all the JSON files (either basic cleaning and normalization)\n",
    "    - Compute metrics for each file and model\n",
    "    - Save results in two CSV files (one for normalized, one for non-normalized)\n",
    "        - Results are saved in `project_root/benchmarking-results/txt-accuracy`\n",
    "    \"\"\"\n",
    "\n",
    "    # =============\n",
    "    # Preliminaries\n",
    "    # =============\n",
    "\n",
    "    #logger.info(\"Script directory: %s\", script_dir)\n",
    "    logger.info(\"Project root: %s\", root_dir)\n",
    "\n",
    "    # Ground truth\n",
    "    ground_truth_dir = os.path.join(root_dir, \"data\", \"ground-truth\", \"json\")\n",
    "    doc_names = get_doc_names(ground_truth_dir, \"json\", keep_prefix=False)\n",
    "\n",
    "    # results/ paths\n",
    "    all_models = get_all_models( \"json\",\n",
    "        #os.path.join(root_dir, \"results\", \"gt-txt2json\"),\n",
    "        #os.path.join(root_dir, \"results\", \"ocr-txt2json\"),\n",
    "        os.path.join(root_dir, \"results\", \"json\", \"llm-img2json\"),\n",
    "        os.path.join(root_dir, \"results\", \"json\", \"llm-txt2json\")\n",
    "    )\n",
    "    logger.info(f\"Models found: {all_models}\")\n",
    "\n",
    "    # ===========\n",
    "    # Gather files\n",
    "    # ===========\n",
    "\n",
    "    # -> Gather ground truths and put into dict:\n",
    "\n",
    "    ground_truths_json, _ = get_docs(\n",
    "        ground_truth_dir, doc_names, \"json\", name_has_prefix=True\n",
    "    )\n",
    "\n",
    "    logger.info(\"Collected ground truth results: %s\", list(ground_truths_json.keys()))\n",
    "\n",
    "    # Convert JSON to dataframe\n",
    "\n",
    "    ground_truths_df = {\n",
    "        doc_name: filter_expected_columns(pd.DataFrame(doc_json['entries'])) for doc_name, doc_json in ground_truths_json.items()\n",
    "    }\n",
    "\n",
    "    logger.info(\"Converted ground truths to dataframes\")\n",
    "\n",
    "    # -> Gather each transcribed document and put into dict:\n",
    "\n",
    "    # Structure: results[(model_type, model)][doc]\n",
    "    results_json = {} # Stores collected outputs as JSON\n",
    "    results_df = {} # Stores collected outputs as dataframes\n",
    "\n",
    "    for model_type, model in all_models:\n",
    "        logger.info(\"Collecting results for model: %s/%s\", model_type, model)\n",
    "\n",
    "        model_path = os.path.join(root_dir, \"results\", \"json\", model_type, model)\n",
    "        print(model_path)\n",
    "        results_json[(model_type, model)], _ = get_docs(\n",
    "            model_path, doc_names, \"json\", name_has_prefix=True\n",
    "        )\n",
    "\n",
    "        logger.info(\"Collected results for model: %s\", list(results_json[(model_type, model)].keys()))\n",
    "\n",
    "        results_df[(model_type, model)] = {\n",
    "            doc_name: filter_expected_columns(pd.DataFrame(doc_json['entries'])) for doc_name, doc_json in results_json[(model_type, model)].items()\n",
    "        }\n",
    "\n",
    "        logger.info(\"Converted results to dataframes\")\n",
    "\n",
    "\n",
    "    # ===============\n",
    "    # Compute metrics\n",
    "    # ===============\n",
    "\n",
    "    normalized_results_data = {}\n",
    "    nonorm_results_data = {}\n",
    "    fuzzy_results_data = {}\n",
    "\n",
    "    for model_type, model in all_models:\n",
    "        normalized_results_data[model_type] = normalized_results_data.get(model_type, {})\n",
    "        normalized_results_data[model_type][model] = normalized_results_data[model_type].get(model, {})\n",
    "\n",
    "        nonorm_results_data[model_type] = nonorm_results_data.get(model_type, {})\n",
    "        nonorm_results_data[model_type][model] = nonorm_results_data[model_type].get(model, {})\n",
    "\n",
    "        fuzzy_results_data[model_type] = fuzzy_results_data.get(model_type, {})\n",
    "        fuzzy_results_data[model_type][model] = fuzzy_results_data[model_type].get(model, {})\n",
    "        \n",
    "        logger.info(\"Computing metrics for model: %s\", model)\n",
    "\n",
    "        for doc in doc_names:\n",
    "            logger.info(\"Computing metrics for document: %s\", doc)\n",
    "\n",
    "            normalized_results_data[model_type][model][doc] = compare_dataframes_normalized(\n",
    "                ground_truths_df[doc], results_df[(model_type, model)][doc]\n",
    "            )\n",
    "            nonorm_results_data[model_type][model][doc] = compare_dataframes_exact(\n",
    "                ground_truths_df[doc], results_df[(model_type, model)][doc]\n",
    "            )\n",
    "            fuzzy_results_data[model_type][model][doc] = compare_dataframes_fuzzy(\n",
    "                ground_truths_df[doc], results_df[(model_type, model)][doc]\n",
    "            )\n",
    "\n",
    "\n",
    "    # =====================================\n",
    "    # Put metrics in table and save results\n",
    "    # =====================================\n",
    "\n",
    "    time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    # Iterate over model types:\n",
    "    for model_type in normalized_results_data.keys():\n",
    "        normalized_df = build_dataframe(f\"{model_type}_normalized_{time}\", doc_names, normalized_results_data[model_type])\n",
    "        nonorm_df = build_dataframe(f\"{model_type}_nonorm_{time}\", doc_names, nonorm_results_data[model_type])\n",
    "        fuzzy_df = build_dataframe(f\"{model_type}_fuzzy_{time}\", doc_names, fuzzy_results_data[model_type])\n",
    "\n",
    "        results_path = os.path.join(root_dir, \"benchmarking-results\", \"json-accuracy\", model_type)\n",
    "        if not os.path.exists(results_path):\n",
    "            os.makedirs(results_path)\n",
    "\n",
    "        normalized_df.to_csv(os.path.join(results_path, f\"{model_type}_normalized_{time}.csv\"))\n",
    "        nonorm_df.to_csv(os.path.join(results_path, f\"{model_type}_nonorm_{time}.csv\"))\n",
    "        fuzzy_df.to_csv(os.path.join(results_path, f\"{model_type}_fuzzy_{time}.csv\"))\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr-benchmarking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
