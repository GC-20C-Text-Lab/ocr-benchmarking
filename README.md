# ocr-benchmarking

Testing methods for digitizing print bibliography as structured data

# ğŸš€ Installation

Set up your API keys in `config/.env`:

```
OPENAI_API_KEY=your_key_here
GOOGLE_API_KEY=your_key_here
TRANSKRIBUS_USERNAME=your_username
TRANSKRIBUS_PASSWORD=your_password
```

# ğŸ“ Directory Structure

The directory structure is adapted from [Greif et al.](#-credits)

```
.
â”œâ”€â”€ benchmarking-results/ # Benchmarking results
â”‚   â””â”€â”€ txt-accuracy/     # Image-to-text accuracy
â”œâ”€â”€ config/                # Configuration files
â”‚   â”œâ”€â”€ environment.yml   # Conda environment specification
â”‚   â””â”€â”€ .env              # API keys and credentials
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ tiffs/            # Input PDFs (type-1.pdf to type-10.pdf)
â”‚   â”œâ”€â”€ ground-truth/     # Ground truth files
â”‚   â”‚   â””â”€â”€ txt/          
â”‚   â””â”€â”€ pngs/             # Intermediate image files as single PNGs
â”œâ”€â”€ results/              # Output directory for all models
â”‚   â”œâ”€â”€ llm-img2csv/      # CSV files from images using multimodal LLMs
â”‚   â”‚   â””â”€â”€ <MODEL>/      # One folder per model
â”‚   â”œâ”€â”€ llm-txt2csv/      # CSV files from transcribed text using multimodal LLMs
â”‚   â”‚   â””â”€â”€ <MODEL>/
â”‚   â”œâ”€â”€ llm-img2txt/      # Text transcribed from images using multimodal LLMs
â”‚   â”‚   â””â”€â”€ <MODEL>/
â”‚   â”œâ”€â”€ ocr-img2txt/      # Text transcribed from images using OCR software
â”‚   â”‚   â””â”€â”€ <MODEL>/
â”œâ”€â”€ src/                  # Source code
â”‚   â”œâ”€â”€ benchmarking/     # Benchmarking tools
â”‚   â”œâ”€â”€ llm-img2csv/      # Image to CSV converters using multimodal LLMs
â”‚   â”œâ”€â”€ llm-txt2csv/      # Text to CSV converters
â”‚   â”œâ”€â”€ llm-img2txt/      # Image to text converters using multimodal LLMs
â”‚   â”œâ”€â”€ ocr-img2txt/      # OCR processors
â”‚   â””â”€â”€ scripts/          # Utility scripts
â””â”€â”€ logs/                 # Log files
```

# ğŸ”§ Usage

Before usage, ensure that the `data` and `results` directories are populated with the correct files.

```bash
# Perform text accuracy analysis using ground truth and transcribed text files
python src/benchmarking/txt_accuracy.py
```

Note: use Anaconda and install all necessary packages before running commands.

## Input Data Format

The pipeline expects:
- TIFF files in `/tiffs`. Named `kbaa-p#ABC.tif`, where `ABC` is the three-digit page number (with leading zeros if necessary)
- Ground truth text files in `data/ground-truth/txt`. Named `kbaa-p#ABC.txt`
  - See formatting guidelines for ground truth text files in the [Ground Truth Guidelines](./ground-truth-guidelines.md)

# ğŸ“Š Benchmarking

# ğŸ“‹ Credits

Greif et al., [Multimodal LLMs for OCR, OCR-Post-Correction, and Named Entity Recognition in Historical Documents](https://github.com/niclasgriesshaber/llm_historical_dataset_benchmarking)